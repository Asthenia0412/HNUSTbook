## 1.Seata-TCC-银行转账场景

> 在分布式系统中，银行转账使用 **TCC（Try-Confirm-Cancel）** 模式时，涉及到多个服务的协作。每个服务需要对其相关资源进行事务管理，以确保转账的一致性与可靠性。不同服务之间的数据结构和表设计至关重要，尤其是如何记录每个阶段的状态、事务的关联等。
>
> 以下是银行转账中涉及的 **TCC** 模式下，不同服务的表结构设计，假设有以下服务：
> 1. **账户服务**：负责账户资金的冻结、解冻、扣款和恢复。
> 2. **支付服务**：负责资金的实际转账操作。
> 3. **通知服务**：负责通知用户转账结果。
>
> ### 1. 账户服务：冻结与解冻账户资金
>
> 账户服务的核心功能是管理账户的资金状态，尤其是在 **Try** 阶段冻结资金，在 **Confirm** 阶段扣款，在 **Cancel** 阶段解冻资金。
>
> #### 表结构设计：`account_transactions`
>
> | 字段名           | 类型            | 描述                                                 |
> | ---------------- | --------------- | ---------------------------------------------------- |
> | `transaction_id` | `VARCHAR(64)`   | 事务ID，唯一标识一次银行转账事务                     |
> | `account_id`     | `VARCHAR(64)`   | 账户ID，标识该资金归属于哪个账户                     |
> | `amount`         | `DECIMAL(20,2)` | 事务金额，表示冻结或扣除的金额                       |
> | `status`         | `ENUM`          | 事务状态（`PENDING`，`COMMITTED`，`CANCELLED`）      |
> | `freeze_status`  | `BOOLEAN`       | 冻结状态，标识是否已冻结资金                         |
> | `created_at`     | `TIMESTAMP`     | 创建时间，标记事务的初始时间                         |
> | `updated_at`     | `TIMESTAMP`     | 更新时间，标记事务状态变更的时间                     |
> | `service_name`   | `VARCHAR(64)`   | 服务名称，标记是哪个服务在处理此操作（如支付服务等） |
> | `action`         | `ENUM`          | 当前操作类型（`TRY`，`CONFIRM`，`CANCEL`）           |
>
> - **Try 阶段**：在账户服务中，当请求冻结资金时，会插入一条记录，并将状态设置为 `PENDING`，并且 `freeze_status` 设置为 `TRUE`，表示资金已被冻结。
> - **Confirm 阶段**：如果转账成功，账户服务会将 `status` 更新为 `COMMITTED`，表示资金已经成功扣除。
> - **Cancel 阶段**：如果转账失败，账户服务将 `status` 更新为 `CANCELLED`，并解冻资金，`freeze_status` 更新为 `FALSE`。
>
> #### 示例记录：
>
> | transaction_id | account_id | amount  | status    | freeze_status | created_at          | updated_at          | service_name | action  |
> | -------------- | ---------- | ------- | --------- | ------------- | ------------------- | ------------------- | ------------ | ------- |
> | txn_123456     | acc_001    | 1000.00 | PENDING   | TRUE          | 2024-12-02 10:00:00 | 2024-12-02 10:10:00 | Payment      | TRY     |
> | txn_123456     | acc_001    | 1000.00 | COMMITTED | TRUE          | 2024-12-02 10:00:00 | 2024-12-02 10:30:00 | Payment      | CONFIRM |
>
> ---
>
> ### 2. 支付服务：处理资金转账操作
>
> 支付服务的核心任务是执行资金的实际转账操作，它需要协调多个服务之间的事务，确保资金的流动。支付服务需要记录每笔转账的 **Try**、**Confirm** 和 **Cancel** 阶段的执行情况。
>
> #### 表结构设计：`payment_transactions`
>
> | 字段名            | 类型            | 描述                                            |
> | ----------------- | --------------- | ----------------------------------------------- |
> | `transaction_id`  | `VARCHAR(64)`   | 事务ID，唯一标识一次银行转账事务                |
> | `from_account_id` | `VARCHAR(64)`   | 付款账户ID，标识资金来源账户                    |
> | `to_account_id`   | `VARCHAR(64)`   | 收款账户ID，标识资金目标账户                    |
> | `amount`          | `DECIMAL(20,2)` | 转账金额                                        |
> | `status`          | `ENUM`          | 事务状态（`PENDING`，`COMMITTED`，`CANCELLED`） |
> | `created_at`      | `TIMESTAMP`     | 创建时间                                        |
> | `updated_at`      | `TIMESTAMP`     | 更新时间                                        |
> | `action`          | `ENUM`          | 当前操作类型（`TRY`，`CONFIRM`，`CANCEL`）      |
> | `payment_method`  | `VARCHAR(64)`   | 支付方式（如银行转账、信用卡等）                |
>
> - **Try 阶段**：支付服务记录转账的初始请求，将状态设置为 `PENDING`，并执行转账验证操作。
> - **Confirm 阶段**：在资金冻结确认后，支付服务完成实际的资金转移，将状态设置为 `COMMITTED`。
> - **Cancel 阶段**：在转账过程中出现异常时，支付服务会将状态更新为 `CANCELLED`，并撤销相关操作。
>
> #### 示例记录：
>
> | transaction_id | from_account_id | to_account_id | amount  | status    | created_at          | updated_at          | action  |
> | -------------- | --------------- | ------------- | ------- | --------- | ------------------- | ------------------- | ------- |
> | txn_123456     | acc_001         | acc_002       | 1000.00 | PENDING   | 2024-12-02 10:00:00 | 2024-12-02 10:10:00 | TRY     |
> | txn_123456     | acc_001         | acc_002       | 1000.00 | COMMITTED | 2024-12-02 10:00:00 | 2024-12-02 10:30:00 | CONFIRM |
>
> ---
>
> ### 3. 通知服务：发送转账通知
>
> 通知服务的职责是根据转账的不同状态（成功、失败等），向用户发送相应的通知。
>
> #### 表结构设计：`notifications`
>
> | 字段名            | 类型          | 描述                               |
> | ----------------- | ------------- | ---------------------------------- |
> | `notification_id` | `VARCHAR(64)` | 通知ID，唯一标识一次通知           |
> | `transaction_id`  | `VARCHAR(64)` | 事务ID，关联支付事务               |
> | `user_id`         | `VARCHAR(64)` | 用户ID，标识哪个用户需要接收通知   |
> | `message`         | `TEXT`        | 通知内容，描述转账成功或失败的情况 |
> | `status`          | `ENUM`        | 通知状态（`SENT`，`FAILED`）       |
> | `created_at`      | `TIMESTAMP`   | 创建时间                           |
> | `updated_at`      | `TIMESTAMP`   | 更新时间                           |
>
> - **Try 阶段**：通知服务一般不会在 **Try** 阶段介入，但可以根据情况发送预通知。
> - **Confirm 阶段**：当转账完成时，通知服务会向用户发送成功通知，`status` 为 `SENT`。
> - **Cancel 阶段**：如果转账取消，通知服务会向用户发送失败通知，`status` 为 `FAILED`。
>
> #### 示例记录：
>
> | notification_id | transaction_id | user_id  | message                      | status | created_at          | updated_at          |
> | --------------- | -------------- | -------- | ---------------------------- | ------ | ------------------- | ------------------- |
> | notif_123456    | txn_123456     | user_001 | "转账成功，已完成1000元支付" | SENT   | 2024-12-02 10:30:00 | 2024-12-02 10:30:00 |
> | notif_123457    | txn_123456     | user_001 | "转账失败，1000元支付未完成" | FAILED | 2024-12-02 10:30:00 | 2024-12-02 10:30:00 |
>
> ---
>
> ### 总结
>
> 在银行转账过程中使用 **TCC** 模式时，各个服务（账户服务、支付服务和通知服务）都需要设计相应的表结构来记录事务状态、操作类型（`TRY`、`CONFIRM`、`CANCEL`）以及资源的冻结、解冻、扣款等操作。通过这些表结构，系统能够在分布式环境下保持数据一致性，并确保跨服务的事务协调。

> 以下是使用SpringCloud、Mybatis-Plus、Lombok和Seata实现TCC银行转账场景的相关代码。由于Seata相关的代码主要集中在服务实现类中，以下将提供每个服务的实现类以及Seata的TCC拦截器配置。
> ### 1. 账户服务实现（AccountService）
> ```java
> import io.seata.rm.tcc.api.BusinessActionContext;
> import io.seata.rm.tcc.api.TwoPhaseBusinessAction;
> import org.springframework.beans.factory.annotation.Autowired;
> import org.springframework.stereotype.Service;
> import org.springframework.transaction.annotation.Transactional;
> @Service
> public class AccountServiceImpl implements AccountService {
>     @Autowired
>     private AccountTransactionMapper accountTransactionMapper;
>     @Override
>     @TwoPhaseBusinessAction(name = "accountServiceTry", commitMethod = "accountServiceConfirm", rollbackMethod = "accountServiceCancel")
>     public void tryFreeze(BusinessActionContext context, AccountTransaction transaction) {
>         // 冻结资金逻辑
>         accountTransactionMapper.insert(transaction);
>     }
>     @Override
>     @Transactional
>     public void accountServiceConfirm(BusinessActionContext context) {
>         // 确认转账逻辑
>         String transactionId = context.getActionContext("transactionId").toString();
>         accountTransactionMapper.updateStatusById(transactionId, "COMMITTED");
>     }
>     @Override
>     @Transactional
>     public void accountServiceCancel(BusinessActionContext context) {
>         // 取消转账逻辑
>         String transactionId = context.getActionContext("transactionId").toString();
>         accountTransactionMapper.updateStatusById(transactionId, "CANCELLED");
>     }
> }
> ```
> ### 2. 支付服务实现（PaymentService）
> ```java
> import io.seata.rm.tcc.api.BusinessActionContext;
> import io.seata.rm.tcc.api.TwoPhaseBusinessAction;
> import org.springframework.beans.factory.annotation.Autowired;
> import org.springframework.stereotype.Service;
> import org.springframework.transaction.annotation.Transactional;
> @Service
> public class PaymentServiceImpl implements PaymentService {
>     @Autowired
>     private PaymentTransactionMapper paymentTransactionMapper;
>     @Override
>     @TwoPhaseBusinessAction(name = "paymentServiceTry", commitMethod = "paymentServiceConfirm", rollbackMethod = "paymentServiceCancel")
>     public void tryTransfer(BusinessActionContext context, PaymentTransaction transaction) {
>         // 尝试转账逻辑
>         paymentTransactionMapper.insert(transaction);
>     }
>     @Override
>     @Transactional
>     public void paymentServiceConfirm(BusinessActionContext context) {
>         // 确认转账逻辑
>         String transactionId = context.getActionContext("transactionId").toString();
>         paymentTransactionMapper.updateStatusById(transactionId, "COMMITTED");
>     }
>     @Override
>     @Transactional
>     public void paymentServiceCancel(BusinessActionContext context) {
>         // 取消转账逻辑
>         String transactionId = context.getActionContext("transactionId").toString();
>         paymentTransactionMapper.updateStatusById(transactionId, "CANCELLED");
>     }
> }
> ```
> ### 3. 通知服务实现（NotificationService）
> ```java
> import io.seata.rm.tcc.api.BusinessActionContext;
> import io.seata.rm.tcc.api.TwoPhaseBusinessAction;
> import org.springframework.beans.factory.annotation.Autowired;
> import org.springframework.stereotype.Service;
> import org.springframework.transaction.annotation.Transactional;
> @Service
> public class NotificationServiceImpl implements NotificationService {
>     @Autowired
>     private NotificationMapper notificationMapper;
>     @Override
>     @TwoPhaseBusinessAction(name = "notificationServiceTry", commitMethod = "notificationServiceConfirm", rollbackMethod = "notificationServiceCancel")
>     public void sendNotification(BusinessActionContext context, Notification notification) {
>         // 发送通知逻辑
>         notificationMapper.insert(notification);
>     }
>     @Override
>     @Transactional
>     public void notificationServiceConfirm(BusinessActionContext context) {
>         // 确认通知发送逻辑
>         String notificationId = context.getActionContext("notificationId").toString();
>         notificationMapper.updateStatusById(notificationId, "SENT");
>     }
>     @Override
>     @Transactional
>     public void notificationServiceCancel(BusinessActionContext context) {
>         // 取消通知发送逻辑
>         String notificationId = context.getActionContext("notificationId").toString();
>         notificationMapper.updateStatusById(notificationId, "FAILED");
>     }
> }
> ```
> ### 4. Seata TCC拦截器配置
> 在Spring Boot的配置类中，你需要注册TCC拦截器：
> ```java
> import io.seata.spring.annotation.GlobalTransactionScanner;
> import org.springframework.context.annotation.Bean;
> import org.springframework.context.annotation.Configuration;
> @Configuration
> public class SeataTccConfig {
>     @Bean
>     public GlobalTransactionScanner globalTransactionScanner() {
>         return new GlobalTransactionScanner("your-application-id", "your-tx-service-group");
>     }
> }
> ```
> 确保你的服务类上有`@Service`注解，并且`@Transactional`注解用于标注事务方法。`@TwoPhaseBusinessAction`注解用于标记TCC事务的方法。
> 请注意，以上代码仅为示例，并未包含具体的数据库操作逻辑。在实际应用中

## 2.MySQL单库-读写分离集群-分库分表集群-分片算法

> 在数据库系统设计中，随着数据量的不断增长和业务需求的多样化，单一的数据库架构往往无法满足高可用、高性能、高扩展等需求。因此，通常采用多种集群架构和中间件来提升系统的能力。你提到的三种常见模式（单库模式、读写分离集群模式、分库分表集群模式）是数据库架构设计中的关键组成部分，下面是对这些模式的完善和扩展说明。
>
> ### 1. **单库模式**
> 单库模式是最基础的数据库架构模式，通常适用于数据量较小、并发量较低的系统。在该模式下，所有的数据存储都集中在一个 MySQL 数据库实例中，所有的读写操作都由这个单一数据库来处理。优点是架构简单，易于管理；但缺点也很明显，随着数据量和并发量的增加，单个数据库实例会面临性能瓶颈，无法应对大规模的流量和数据存储需求。
>
> **适用场景：**
> - 数据量较小，负载较轻。
> - 系统复杂度较低，开发人员希望架构简单。
>
> **缺点：**
> - 随着数据量增大，性能瓶颈逐渐显现。
> - 不具备高可用性，一旦数据库故障，系统可能无法恢复。
>
> ### 2. **读写分离集群模式**
> 为了解决单库模式带来的性能瓶颈问题，通常采用读写分离集群模式。该模式的核心思想是将数据库的读操作和写操作分开，由不同的数据库节点来处理。具体来说，系统通过在主数据库（Master）和从数据库（Slave）之间进行数据同步来实现读写分离。主库负责写入操作，而从库负责读取操作，减轻了主库的负担，从而提升了系统的性能和可扩展性。
>
> **原理：**
> - **主从复制：** MySQL 通过 `binlog`（二进制日志）将主库的更新操作同步到从库。主库一般用于写操作，从库用于读操作。
> - **中间件：** 为了实现读写分离，通常会引入中间件（如 **Mycat**、**ShardingSphere** 等）来根据不同的业务场景将请求路由到主库或从库。
> - **高可用性：** 采用 **MHA**（MySQL高可用性架构）或 **Orchestrator** 等中间件来实现故障自动切换。若主库发生故障，可以自动将某个从库提升为新的主库，从而保证系统的高可用性。
>
> **优点：**
> - 减轻了主库的负担，提高了读操作的吞吐量。
> - 通过主从同步机制，能够实现数据冗余，提高数据的可靠性。
> - 使用中间件可以灵活地将请求路由到不同的数据库，提升了系统的可扩展性。
>
> **缺点：**
> - 写操作依赖于主库，如果主库宕机，可能会导致写操作的延迟或丢失。
> - 数据同步的延迟可能导致从库的数据略有滞后，影响读取的准确性。
>
> **适用场景：**
> - 读多写少的应用场景，如电商、新闻网站等。
> - 数据量和流量逐渐增大，但单库仍能承受的情况。
>
> ### 3. **分库分表（分片）集群模式**
> 当系统的负载进一步加大时，单一的数据库无法承载如此庞大的数据量，这时就需要采用分库分表（即分片）架构来水平扩展。分库分表通过将数据分布到多个物理数据库实例中，打破了单个数据库的限制，从而支持大规模的数据存储和高并发的读写操作。
>
> **分片的核心概念：**
> - **分库：** 将数据分布到多个数据库实例中，每个数据库负责一部分数据。通过拆分大表，避免单库的存储限制和性能瓶颈。
> - **分表：** 将大表进一步划分为多个小表，减少单个表的数据量，提高查询效率。
> - **分片键（Shard Key）：** 根据特定的字段（如用户ID、订单ID等）进行分片，确保数据的均匀分布和查询效率。
>
> **分片算法：**
> 1. **范围法：** 根据分片键的值范围将数据划分到不同的库和表中。例如，根据 ID 的大小进行区间划分。范围法易于扩展和理解，适用于大部分场景，但可能导致数据分布不均匀，某些区间的负载可能过高。
>    
>    **例子：**
>    - 分片键：`user_id`
>    - 范围：`user_id < 1000` 分到 `shard1`，`1000 <= user_id < 2000` 分到 `shard2` 等。
>
> 2. **哈希法：** 根据分片键对数据进行哈希计算（如取模），将数据均匀地分配到不同的库和表中。哈希法的优点是数据分布均匀，但扩展性较差，因为扩展时可能需要大量的数据迁移。
>
>    **例子：**
>    - 分片键：`user_id`
>    - 哈希：`user_id % 3`，分别映射到 `shard1`、`shard2`、`shard3`。
>
> 3. **一致性哈希：** 一致性哈希是哈希算法的一种变种，主要用于解决分库扩容时数据迁移的难题。它通过哈希环的方式分配数据，在新增或减少分片时，只有少量的数据需要迁移，从而提高了扩展性。
>
> **优点：**
> - 通过水平拆分，极大地扩展了数据库的存储容量和处理能力。
> - 数据存储分散，降低了单点故障的风险。
> - 在高并发的场景下，能够实现高吞吐量的读写操作。
>
> **缺点：**
> - 数据跨库、跨表查询复杂，查询性能和开发难度增加。
> - 分片方案设计不当可能导致数据不均匀分布，影响负载均衡。
> - 扩展过程中可能需要迁移大量数据，影响系统稳定性。
>
> **适用场景：**
> - 数据量极大，无法通过单一数据库进行存储和处理的场景。
> - 需要高并发、高吞吐量处理的系统，如大型电商、社交平台等。
>
> ### 4. **主流模式：读写分离 + 分库分表的组合运用**
> 在实际应用中，读写分离和分库分表通常会结合使用，构成一个更加复杂的集群架构。具体来说：
> - **分库分表**解决了单一数据库实例的性能瓶颈和扩展性问题，通过将数据分布到多个数据库节点中，可以承载更大的数据量。
> - **读写分离**通过将读操作分发到从库，减轻主库的负担，从而提高系统的整体性能。
>
> **结合方式：**
> - 在每个分片（分库）内，使用读写分离架构，主库负责写操作，从库负责读操作。
> - 通过中间件（如 **ShardingSphere** 或 **Mycat**），负责将请求路由到正确的分片和对应的读写分离节点。
>
> **优点：**
> - 系统可扩展性强，能够应对大规模数据和高并发读写的需求。
> - 通过分片和读写分离的结合，既保证了数据存储的扩展性，又提高了系统的读写性能。
>
> **缺点：**
> - 架构复杂度较高，需要精心设计分片策略、数据路由策略和容错机制。
> - 开发和维护的成本增加。
>
> **适用场景：**
> - 数据量庞大，且系统需要处理大量的读请求的高并发系统，如大型电商平台、社交网站、金融系统等。
>
> ### 总结
> 随着业务的不断发展，数据库架构也需要不断地调整和优化。不同的架构模式适用于不同的场景：
> - **单库模式**适用于简单、小规模的应用。
> - **读写分离模式**适用于读多写少的场景，能有效提升读取性能。
> - **分库分表模式**适用于数据量极大、需要水平扩展的系统。
> - **读写分离 + 分库分表组合模式**适用于高并发、大数据量的复杂应用，既保证了扩展性，又提升了性能。
>
> 选择合适的架构模式需要综合考虑业务需求、系统规模、可维护性以及未来的扩展需求。

> 配置 **MHA（MySQL High Availability）** 主要涉及以下几个步骤，包括安装 MHA 相关组件、配置 MySQL 主从复制、配置 MHA 管理器、以及测试高可用性配置。下面是详细的配置过程。
>
> ### 1. **准备 MySQL 环境**
> 首先，确保你已经有一个 MySQL 环境，并且至少有两个 MySQL 实例（一个主库和一个从库）。MHA 的核心依赖于 MySQL 的主从复制。
>
> #### 1.1 安装 MySQL
>
> 在每台服务器上安装 MySQL。假设你有两台服务器：
> - **主库服务器**：`master-host`
> - **从库服务器**：`slave1-host`，`slave2-host`
>
> 安装 MySQL 的版本建议与 MHA 兼容，通常是 5.6 或 5.7。安装过程根据操作系统不同而有所区别。
>
> ### 2. **配置 MySQL 主从复制**
> #### 2.1 主库配置
> 在主库上进行以下配置：
>
> 1. 编辑 `my.cnf` 配置文件，启用二进制日志（`binlog`）和服务器 ID（`server-id`）。
>
> ```ini
> [mysqld]
> server-id = 1
> log-bin = mysql-bin
> binlog-format = row
> ```
>
> 2. 重启 MySQL 服务，使配置生效。
>
> ```bash
> systemctl restart mysql
> ```
>
> 3. 创建复制用户并授予权限：
>
> ```sql
> CREATE USER 'replica_user'@'%' IDENTIFIED BY 'password';
> GRANT REPLICATION SLAVE ON *.* TO 'replica_user'@'%';
> FLUSH PRIVILEGES;
> ```
>
> #### 2.2 从库配置
> 在从库上进行以下配置：
>
> 1. 编辑 `my.cnf` 配置文件，设置唯一的 `server-id`，并启用复制。
>
> ```ini
> [mysqld]
> server-id = 2  # 对于每台从库，确保 ID 唯一
> ```
>
> 2. 重启 MySQL 服务。
>
> ```bash
> systemctl restart mysql
> ```
>
> 3. 配置从库连接到主库：
>
> ```sql
> CHANGE MASTER TO 
>   MASTER_HOST = 'master-host', 
>   MASTER_USER = 'replica_user', 
>   MASTER_PASSWORD = 'password', 
>   MASTER_LOG_FILE = 'mysql-bin.000001',  -- 从主库的二进制日志文件名
>   MASTER_LOG_POS = 154;                  -- 从主库获取日志位置
> START SLAVE;
> ```
>
> 4. 检查从库是否同步：
>
> ```sql
> SHOW SLAVE STATUS\G
> ```
>
> 确保 `Slave_IO_Running` 和 `Slave_SQL_Running` 都是 `Yes`，表示从库正常同步主库。
>
> ### 3. **安装 MHA 组件**
> MHA 需要在管理节点（MHA Manager）和数据库节点（MySQL 实例）上安装相关软件。
>
> #### 3.1 安装 MHA Manager
> MHA Manager 是负责监控 MySQL 主库状态、执行故障转移等操作的核心组件。你需要在管理服务器上安装 MHA Manager。
>
> 1. 安装依赖：
>
> ```bash
> sudo apt-get install perl libdbi-perl libmysqlclient-dev libssh2-1-dev
> ```
>
> 2. 下载并安装 MHA：
>
> ```bash
> wget https://github.com/yoshinori-ikegami/mha4mysql-manager/releases/download/v0.57/mha4mysql-manager-0.57.tar.gz
> tar -xzvf mha4mysql-manager-0.57.tar.gz
> cd mha4mysql-manager-0.57
> perl Makefile.PL
> make
> sudo make install
> ```
>
> #### 3.2 配置 MHA Manager
> MHA Manager 配置文件通常位于 `/etc/mha.cnf`。你需要设置以下内容：
>
> ```ini
> [server default]
> # MHA Manager 配置的全局设置
> manager_user=root
> manager_password=yourpassword
> ssh_user=root
> # 配置 MHA Manager 服务器列表
> master_ip_failover_script=/usr/local/bin/master_ip_failover
> # 配置 MySQL 节点
> [server1]
> hostname=master-host
> port=3306
> candidate_master=1
> # 配置从库
> [server2]
> hostname=slave1-host
> port=3306
> candidate_master=1
> # 其他从库配置
> [server3]
> hostname=slave2-host
> port=3306
> candidate_master=0
> ```
>
> - `manager_user` 和 `manager_password`：用于 MHA 管理工具连接到 MySQL 的用户名和密码。
> - `master_ip_failover_script`：定义故障转移时的 IP 切换脚本路径（通常使用 `master_ip_failover` 脚本）。
> - `hostname` 和 `port`：列出所有 MySQL 服务器的信息。
> - `candidate_master=1`：标记该服务器为故障转移的候选主库。
>
> #### 3.3 配置 SSH 和密钥
> MHA Manager 需要通过 SSH 连接到所有 MySQL 节点。你需要确保 MHA Manager 机器能够无密码登录到所有 MySQL 节点。
>
> 1. 生成 SSH 密钥：
>
> ```bash
> ssh-keygen -t rsa
> ```
>
> 2. 将公钥拷贝到所有 MySQL 节点：
>
> ```bash
> ssh-copy-id user@master-host
> ssh-copy-id user@slave1-host
> ssh-copy-id user@slave2-host
> ```
>
> ### 4. **启动 MHA**
> 启动 MHA Manager 后，它将开始监控 MySQL 集群，并根据需要进行故障转移。
>
> 1. 启动 MHA Manager：
>
> ```bash
> masterha_manager --conf=/etc/mha.cnf --ignore_last_failover
> ```
>
> 2. 查看故障转移状态：
>
> ```bash
> masterha_check_repl --conf=/etc/mha.cnf
> ```
>
> 该命令将检查 MySQL 集群的复制状态，确保所有节点都同步并且可以正常工作。
>
> ### 5. **测试 MHA 故障转移**
> 为了测试 MHA 是否工作正常，你可以手动停止主库 MySQL 服务，查看是否能够自动切换到从库。
>
> 1. 停止主库：
>
> ```bash
> systemctl stop mysql
> ```
>
> 2. 查看 MHA 是否执行故障转移，主库会自动切换到新的主库。
>
> ```bash
> masterha_check_repl --conf=/etc/mha.cnf
> ```
>
> 如果配置正确，MHA 会自动将新的从库提升为主库，并且所有的 MySQL 节点会重新同步。
>
> ### 6. **优化和维护**
> - **定期检查 MHA 状态**：定期使用 `masterha_check_repl` 检查 MySQL 集群的状态，确保复制同步无误。
> - **故障转移脚本**：你可以自定义故障转移脚本，以便根据特定需求进行调整，例如自动调整 DNS 或修改应用配置。
> - **监控**：可以将 MHA 集成到系统的监控工具（如 Zabbix、Prometheus）中，以便实时监控 MySQL 的健康状态。
>
> ### 总结
> 配置 MHA 主要包括以下步骤：
>
> 1. 配置 MySQL 主从复制。
> 2. 安装和配置 MHA Manager 以监控 MySQL 集群并执行故障转移。
> 3. 配置 SSH 无密码登录，以便 MHA Manager 能够与各个 MySQL 节点进行交互。
> 4. 测试故障转移过程，确保 MHA 能够在主库宕机时自动切换。
>
> 通过这些步骤，你就可以实现 MySQL 的高可用性，保证在数据库故障时系统能够自动切换到新的主库。
> 

## 3.大厂为何做垂直分表？

> ### 为什么大厂做垂直分表？
>
> 垂直分表（Vertical Partitioning）是将一个表中的字段按逻辑或访问频率进行拆分，创建多个小表。这种做法通常是为了优化性能，减少 I/O 操作，提高数据库的查询效率，尤其是在面对大数据量的情况下。大厂做垂直分表的主要原因，通常与以下几个因素密切相关：
>
> 1. **表的字段过多，数据查询性能低**：
>    当一张表的字段非常多，特别是包含一些大字段（如 `VARCHAR`、`BLOB`、`CLOB`）时，每次查询时，数据库需要加载大量不必要的数据，导致内存和磁盘 I/O 的开销变大。垂直分表能够将频繁访问的小字段与不常访问的大字段分开存储，从而减少每次查询时加载的无关数据。
>
> 2. **优化查询和提高执行效率**：
>    如果表中包含一些低频字段或大字段（如图片、文本等），在常规查询时，这些字段并不总是被访问，导致不必要的数据被载入到内存中，影响性能。通过垂直分表，可以将大字段和高频字段分开，查询时只加载需要的字段，避免全表扫描和大数据量的内存消耗。
>
> 3. **减少跨页读取的成本**：
>    由于 InnoDB 存储引擎使用的是页（Page）作为数据存储的基本单元，一个页的大小默认是 16KB。若一张表中的行数据过大，每一页可能只能容纳很少的行，这样在查询时可能需要跨多个页来检索数据。通过垂直分表，可以让每个小表的行数据更加紧凑，减少跨页读取，从而提高查询效率。
>
> 4. **提高数据的存储与管理效率**：
>    垂直分表可以把不同类型的数据放在不同的表中，这样可以更好地管理数据。例如，大字段（如文本、二进制数据）可以单独存储，以优化存储和检索性能。而小字段则可以存放在一个紧凑的小表中，以加速查询。
>
> ---
>
> ### 什么是水平分表？
>
> 水平分表（Horizontal Partitioning）是将数据按行拆分，即通过某种策略（如范围法、哈希法等）将数据分布到多个表中。每个表的结构是完全相同的，唯一的区别在于存储的数据行不同。常见的水平分表策略包括：
>
> - **范围法（Range Partitioning）**：按一定的范围划分数据，例如按日期、ID 等字段范围来划分表。
> - **哈希法（Hash Partitioning）**：根据某个字段的哈希值，将数据分到不同的表中。
>
> 水平分表的主要目的是解决单表数据量过大的问题，特别是在数据量大到无法在单台机器上高效存储和查询时。通过将数据拆分到多个表中，降低单个表的数据量，提高查询和存储性能。
>
> ### 什么是垂直分表？
>
> 垂直分表是将一张表的列（字段）拆分成多张表，通过主外键的关系将它们关联起来。与水平分表通过拆分数据行不同，垂直分表主要是将表的不同字段进行拆分。
>
> 垂直分表适用于以下场景：
>
> - **字段过多，且查询时频繁只需要部分字段**：如果表中有很多字段，但并不是每次查询都需要这些字段，垂直分表可以帮助将频繁访问的字段与不常访问的字段分开，减少查询时的数据量。
> - **大字段（如 `TEXT`、`BLOB`）**：这些字段占用空间大，频繁查询时不常访问，通过垂直分表，可以将这些大字段单独存储，以减少查询时的开销。
>   
>
> 垂直分表可以根据字段的类型、查询频率等因素进行拆分：
>
> - **小表**：存储查询频繁的小字段，通常包括索引字段、常用字段。
> - **大表**：存储低频访问的字段，如大文本字段、二进制文件等。
>
> ### 垂直分表的背景：InnoDB 存储引擎的工作原理
>
> 理解为什么垂直分表能够提高性能，我们需要从 **InnoDB** 存储引擎的底层机制来分析。
>
> 1. **页（Page）与区（Extent）**：
>    InnoDB 存储引擎将数据存储在称为 **页**（Page）中，每页大小为 **16KB**。多个连续的页组成一个 **区**（Extent），每个区通常有 64 页。每一页可以存储一定量的行数据，行的大小和页的容量直接影响存储效率和查询性能。
>
> 2. **跨页检索问题**：
>    如果一行数据的大小较大，可能会导致单页不能完全容纳一个完整的行数据，导致数据分布在多个页中。每次查询时，InnoDB 可能需要跨越多个页来检索同一行的数据，这增加了 I/O 操作的开销，影响查询性能。
>
> 3. **压缩页（Compressed Pages）**：
>    在 InnoDB 1.0 之后，压缩页成为一个新特性。压缩页可以减少数据在磁盘上的存储占用，但在跨页检索时，压缩和解压缩的过程会导致额外的 CPU 和时间消耗。因此，为了避免跨页检索，设计时应尽可能让一行数据能够完全存储在一个页内。
>
> ### 垂直分表的优化效果
>
> 假设一张表的每行数据为 1KB，而每页大小为 16KB，这样每页可以存储约 16 行数据。若数据量达到 1 亿行，那么表将占用 625 万页的数据空间。
>
> 通过垂直分表，假设每行数据能够被压缩到 64 字节（通过将一些大字段分离），那么每页就可以存储 256 行数据。这使得同样的数据量（1 亿行）仅需要 39 万页，极大地减少了页的数量，从而提高了数据访问效率。
>
> ### 垂直分表的应用条件
>
> 垂直分表的条件通常包括：
>
> 1. **单表数据量达到千万级别**：当表的数据量过大时，单个表的查询、存储、备份等操作变得非常缓慢，垂直分表能有效减轻这些负担。
> 2. **字段数超过 20 个且包含大字段类型**：当表的字段过多，且包括了 `VARCHAR`、`CLOB`、`BLOB` 等大字段类型时，垂直分表能够帮助将频繁访问的小字段与大字段分离，减少查询时的数据量。
> 3. **高频访问字段与低频访问字段区分明显**：通过将高频访问字段与低频访问字段分开存储，能够大大减少查询时的冗余数据加载，提升性能。
>
> ### 垂直分表的字段拆分策略
>
> 在进行垂直分表时，字段拆分的依据通常是：
>
> - **小表**：存储查询、排序时频繁使用的小字段，如主键、索引字段、状态字段等。
> - **大表**：存储低频访问的字段，如大文本字段、图片、文件数据等。 
>
> 通过这样的拆分策略，可以在保证查询效率的同时，降低存储和访问的开销。
>
> ---
>
> ### 总结
>
> 垂直分表是针对表中字段较多、数据量大的情况采取的一种优化策略。通过将表按字段拆分成多个小表，可以提高查询性能、减少磁盘 I/O 操作和内存开销，尤其适用于字段过多、包含大字段（如 `VARCHAR`、`BLOB` 等）的场景。垂直分表的实现通常依赖于对 MySQL 内部存储引擎（如 InnoDB）机制的深入理解，能够帮助解决大数据量、高频访问和低频字段分离等问题。
>
> 

> 下面通过一个实际的例子来展示如何使用垂直分表优化数据库查询性能。
>
> ### 场景背景
>
> 假设我们有一个 **用户信息表** (`users`)，它存储了每个用户的基本信息、联系方式、地址等。由于该表的字段比较多，且表中的一些字段访问频率较低（如用户的头像、地址等），而一些字段频繁查询（如用户名、邮箱、手机号码等），因此需要考虑通过垂直分表来优化查询性能。
>
> #### 原始 `users` 表结构
>
> ```sql
> CREATE TABLE users (
>     user_id INT PRIMARY KEY,       -- 用户ID
>     username VARCHAR(50),          -- 用户名
>     email VARCHAR(100),            -- 用户邮箱
>     phone VARCHAR(20),             -- 用户电话
>     password_hash VARCHAR(255),    -- 密码哈希值
>     address TEXT,                  -- 用户地址
>     profile_picture BLOB,          -- 用户头像
>     created_at DATETIME,           -- 注册时间
>     updated_at DATETIME            -- 信息更新时间
> );
> ```
>
> - 表中有很多字段，但并不是所有字段在每次查询时都需要使用。
> - `address` 和 `profile_picture` 是大字段，频繁查询时并不总是需要它们。
>
> ### 目标
>
> 通过 **垂直分表**，将高频字段和低频字段分离，提高查询性能，减少不必要的 I/O 操作。
>
> ### 垂直分表策略
>
> 我们将用户表按访问频率将字段拆分为两部分：
>
> - **高频查询字段**：如 `user_id`, `username`, `email`, `phone`, `password_hash`, `created_at`, `updated_at`。
> - **低频查询字段**：如 `address` 和 `profile_picture`（这类字段通常较大且不常查询）。
>
> #### 分表后的结构
>
> 1. **`users_basic` 表**：存储常用的、查询频繁的字段。
> 2. **`users_extra` 表**：存储不常用的、低频访问的字段。
>
> ```sql
> -- 高频字段表
> CREATE TABLE users_basic (
>     user_id INT PRIMARY KEY,        -- 用户ID
>     username VARCHAR(50),           -- 用户名
>     email VARCHAR(100),             -- 用户邮箱
>     phone VARCHAR(20),              -- 用户电话
>     password_hash VARCHAR(255),     -- 密码哈希值
>     created_at DATETIME,            -- 注册时间
>     updated_at DATETIME             -- 信息更新时间
> );
> 
> -- 低频字段表
> CREATE TABLE users_extra (
>     user_id INT PRIMARY KEY,        -- 用户ID
>     address TEXT,                   -- 用户地址
>     profile_picture BLOB,           -- 用户头像
>     FOREIGN KEY (user_id) REFERENCES users_basic(user_id)  -- 外键关联
> );
> ```
>
> ### 分表后的访问场景
>
> 1. **常规查询**：
>    - 假设我们需要查询一个用户的基本信息（例如用户名、邮箱、电话号码等），这时只需要查询 `users_basic` 表即可，避免了读取 `address` 和 `profile_picture` 字段，从而提高了查询效率。
>
>    ```sql
>    SELECT user_id, username, email, phone, created_at, updated_at
>    FROM users_basic
>    WHERE user_id = 123;
>    ```
>
> 2. **查询包含低频字段的用户信息**：
>    - 如果我们需要查询用户的地址或头像，只有在必要时才会去查询 `users_extra` 表，避免了不必要的数据加载。
>
>    ```sql
>    SELECT u.username, u.email, u.phone, e.address, e.profile_picture
>    FROM users_basic u
>    JOIN users_extra e ON u.user_id = e.user_id
>    WHERE u.user_id = 123;
>    ```
>
> 3. **查询所有字段**：
>    - 如果需要查询完整的用户信息（包括地址和头像），可以通过联合查询来获取所有字段。
>
>    ```sql
>    SELECT u.*, e.*
>    FROM users_basic u
>    LEFT JOIN users_extra e ON u.user_id = e.user_id
>    WHERE u.user_id = 123;
>    ```
>
> ### 优化效果
>
> 1. **减少不必要的数据加载**：
>    - 在大多数查询场景中，我们只需要查询用户的基本信息（用户名、邮箱、电话等）。通过垂直分表，这些常用字段与低频字段分开存储，查询时无需加载 `address` 和 `profile_picture` 这些不必要的数据，减少了 I/O 开销。
>
> 2. **提高缓存效率**：
>    - 常用的字段存储在 `users_basic` 表中，查询时只涉及较小的数据集合，这样可以提高缓存命中率，减少磁盘读取。
>
> 3. **提升查询速度**：
>    - 如果用户表的行数非常庞大（例如千万级用户），查询 `users_basic` 表时只需要扫描较少的数据，查询效率大大提升。
>
> 4. **数据存储和管理优化**：
>    - 将大字段（如头像、地址）存储在 `users_extra` 表中，有助于更好地管理这些数据。因为这些字段通常比较大，频繁读取可能对性能产生影响，将它们分开存储可以减少主表的负担。
>
> ### 总结
>
> 通过垂直分表，我们将频繁访问的字段与不常用的字段分开存储，提高了查询效率，并减少了不必要的磁盘 I/O 操作。此外，垂直分表使得数据的管理更加清晰，并能针对不同类型的数据做针对性优化。