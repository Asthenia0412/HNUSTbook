# 构建微服务项目的CI/CD流水线与Docker Compose部署：从需求到实践

在现代微服务架构中，构建高效的CI/CD流水线并结合Docker Compose进行部署是提升开发效率和系统稳定性的关键。本文基于一个复杂的微服务项目，详细阐述如何设计Jenkins流水线、配置Docker Compose，并确保贴近真实的开发流程。我们将模拟面试官的严格审查，分析并修正不合理部分，提供一个全面、可落地的方案。

## 项目背景

### 项目概述

我们假设有一个基于Spring Boot的微服务项目，包含以下**中间件**和**业务服务**，采用Gitflow开发模式，覆盖开发、FAT、UAT和生产环境。

#### 中间件

- **MySQL**: 关系型数据库，用于存储核心业务数据。
- **Redis**: 缓存服务，用于高性能数据存储。
- **MinIO**: 对象存储，用于文件上传。
- **MongoDB**: NoSQL数据库，适合灵活数据结构。
- **ElasticSearch**: 搜索引擎，用于全文搜索。
- **Nacos**: 配置与服务注册中心。
- **RocketMQNameServer** & **RocketMQBroker**: 分布式消息队列。
- **Sentinel Dashboard**: 流量控制与服务保护。
- **Seata**: 分布式事务管理。
- **Canal**: 数据库增量同步工具。

#### 业务服务

- **网关服务**: 统一入口，基于Spring Cloud Gateway。
- **SSO中心服务**: 单点登录，基于OAuth2。
- **分布式ID服务**: 生成全局唯一ID，基于Snowflake算法。
- **搜索服务**: 基于ElasticSearch的全文搜索。
- **业务文件上传服务**: 文件上传至MinIO。
- **权限RBAC服务**: 基于角色访问控制。
- **用户服务**: 用户管理。
- **产品服务**: 商品管理。
- **订单服务**: 订单处理。
- **支付服务**: 支付处理，集成第三方支付。
- **多商户服务**: 支持多租户架构。

### 业务场景

1. **中间件独立部署**：第一次部署需先部署中间件，与业务服务分开，使用独立的Docker Compose文件。

2. Gitflow开发模式

   ：

   - **分支**：`main`（生产）、`develop`（开发）、`feature`（特性）、`release`（发布）、`hotfix`（修复）。

   - 开发流程

     ：

     - 功能开发完成后，提交Merge Request（MR）到`develop`，触发FAT环境测试。
     - 双周迭代时，合并`develop`到`release`，触发UAT环境测试。
     - UAT通过后，合并`release`到`main`和`develop`，触发生产环境部署。
     - 若UAT失败，合并到`hotfix`，修复后重新合并到`release`，再到`main`和`develop`。

3. **多环境流水线**：为开发、FAT、UAT、生产环境分别构建流水线。

4. **Docker Compose配置**：业务服务需指定内存参数、JVM参数（包括OOM排查相关日志生成参数）以及合适的启动器。

5. **容器依赖关系**：服务间存在依赖（如网关依赖Nacos，订单服务依赖用户服务）。

6. CI/CD流程：

   - 运行单元测试。
   - 测试通过后构建Docker镜像，推送至私有仓库。
   - SSH到目标服务器，拉取新镜像，停止并删除旧容器，清理旧镜像（需优化此步骤）。

------

## Docker Compose 配置

### 中间件 Docker Compose

中间件需独立部署，确保稳定性和隔离性。以下是`docker-compose.middleware.yml`的完整配置，包含所有中间件、资源限制、网络隔离和健康检查。

```yaml
version: '3.8'
services:
  mysql:
    image: mysql:8.0
    environment:
      MYSQL_ROOT_PASSWORD: root123
      MYSQL_DATABASE: microservice_db
    volumes:
      - mysql_data:/var/lib/mysql
    ports:
      - "3306:3306"
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-uroot", "-proot123"]
      interval: 10s
      retries: 5
      timeout: 5s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    networks:
      - middleware-net

  redis:
    image: redis:7.0
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      retries: 5
      timeout: 5s
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 128M
    networks:
      - middleware-net

  minio:
    image: minio/minio:latest
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin123
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      retries: 5
      timeout: 5s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    networks:
      - middleware-net

  mongodb:
    image: mongo:5.0
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db
    healthcheck:
      test: ["CMD", "mongo", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      retries: 5
      timeout: 5s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    networks:
      - middleware-net

  elasticsearch:
    image: elasticsearch:8.8.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - es_data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200"]
      interval: 10s
      retries: 5
      timeout: 5s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2048M
        reservations:
          cpus: '0.5'
          memory: 1024M
    networks:
      - middleware-net

  nacos:
    image: nacos/nacos-server:2.2.0
    environment:
      MODE: standalone
      JVM_XMS: 512m
      JVM_XMX: 512m
      SPRING_DATASOURCE_PLATFORM: mysql
      MYSQL_SERVICE_HOST: mysql
      MYSQL_SERVICE_PORT: 3306
      MYSQL_SERVICE_USER: root
      MYSQL_SERVICE_PASSWORD: root123
      MYSQL_SERVICE_DB_NAME: nacos_config
    ports:
      - "8848:8848"
    volumes:
      - nacos_data:/home/nacos/data
    depends_on:
      mysql:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8848/nacos/v1/console/health"]
      interval: 10s
      retries: 5
      timeout: 5s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    networks:
      - middleware-net

  rocketmq-namesrv:
    image: apache/rocketmq:4.9.4
    command: sh mqnamesrv
    ports:
      - "9876:9876"
    healthcheck:
      test: ["CMD", "sh", "-c", "curl -f http://localhost:9876"]
      interval: 10s
      retries: 5
      timeout: 5s
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 128M
    networks:
      - middleware-net

  rocketmq-broker:
    image: apache/rocketmq:4.9.4
    command: sh mqbroker -n rocketmq-namesrv:9876
    ports:
      - "10909:10909"
      - "10911:10911"
    depends_on:
      rocketmq-namesrv:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "sh", "-c", "curl -f http://localhost:10911"]
      interval: 10s
      retries: 5
      timeout: 5s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    networks:
      - middleware-net

  sentinel:
    image: bladex/sentinel-dashboard:1.8.6
    ports:
      - "8858:8858"
    environment:
      JAVA_OPTS: "-Xms512m -Xmx512m"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8858"]
      interval: 10s
      retries: 5
      timeout: 5s
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 256M
    networks:
      - middleware-net

  seata:
    image: seataio/seata-server:1.5.2
    environment:
      SEATA_CONFIG_NAME: file:/root/seata-config/registry
      SEATA_IP: seata
    ports:
      - "8091:8091"
    depends_on:
      nacos:
        condition: service_healthy
    volumes:
      - seata_config:/root/seata-config
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8091"]
      interval: 10s
      retries: 5
      timeout: 5s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    networks:
      - middleware-net

  canal:
    image: canal/canal-server:v1.1.5
    environment:
      canal.destinations: example
      canal.instance.master.address: mysql:3306
      canal.instance.dbUsername: root
      canal.instance.dbPassword: root123
    depends_on:
      mysql:
        condition: service_healthy
    ports:
      - "11111:11111"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11111"]
      interval: 10s
      retries: 5
      timeout: 5s
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 128M
    networks:
      - middleware-net

networks:
  middleware-net:
    driver: bridge

volumes:
  mysql_data:
  redis_data:
  minio_data:
  mongo_data:
  es_data:
  nacos_data:
  seata_config:
```

#### 面试官拷打

1. 网络隔离是否充分？

   - **问题**：所有中间件在同一网络，可能导致不必要通信。

   - 修正

     ：为敏感服务（如MySQL）创建单独网络，仅允许必要服务访问。

     ```yaml
     networks:
       db-net:
         driver: bridge
       middleware-net:
         driver: bridge
     services:
       mysql:
         networks:
           - db-net
       nacos:
         networks:
           - db-net
           - middleware-net
     ```

2. 健康检查是否足够健壮？

   - **问题**：Canal和RocketMQ的健康检查仅检查端口，可能不准确。
   - **修正**：为Canal添加Admin API检查，为RocketMQ添加`mqadmin`命令检查。

3. 资源限制是否合理？

   - **问题**：ElasticSearch内存限制较低（2048M），可能导致性能瓶颈。
   - **修正**：根据实际负载调整为4-8GB，并监控JVM堆使用。

4. 数据持久化如何备份？

   - **问题**：未明确备份策略，生产环境数据丢失风险高。
   - **修正**：为MySQL、MongoDB配置定时备份，使用CronJob或外部工具（如AWS S3同步）。

### 业务服务 Docker Compose

业务服务的`docker-compose.services.yml`需明确所有服务的依赖关系、JVM参数、资源限制和健康检查。以下是完整配置：

```yaml
version: '3.8'
services:
  gateway:
    image: myregistry.local/gateway:${TAG:-latest}
    environment:
      JAVA_OPTS: >
        -Xms512m -Xmx512m
        -XX:MetaspaceSize=128m
        -XX:MaxMetaspaceSize=256m
        -XX:+UseG1GC
        -XX:+HeapDumpOnOutOfMemoryError
        -XX:HeapDumpPath=/logs/heapdump.hprof
        -Xlog:gc*:file=/logs/gc.log:time,tags:filecount=10,filesize=10M
        -XX:+PrintGCDetails
        -XX:+PrintGCDateStamps
    depends_on:
      nacos:
        condition: service_healthy
    volumes:
      - ./logs/gateway:/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]
      interval: 10s
      retries: 5
      timeout: 5s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1024M
        reservations:
          cpus: '0.25'
          memory: 512M
    networks:
      - middleware-net
      - services-net

  sso-service:
    image: myregistry.local/sso-service:${TAG:-latest}
    environment:
      JAVA_OPTS: >
        -Xms512m -Xmx512m
        -XX:MetaspaceSize=128m
        -XX:MaxMetaspaceSize=256m
        -XX:+UseG1GC
        -XX:+HeapDumpOnOutOfMemoryError
        -XX:HeapDumpPath=/logs/heapdump.hprof
        -Xlog:gc*:file=/logs/gc.log:time,tags:filecount=10,filesize=10M
        -XX:+PrintGCDetails
        -XX:+PrintGCDateStamps
    depends_on:
      nacos:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./logs/sso-service:/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/actuator/health"]
      interval: 10s
      retries: 5
      timeout: 5s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1024M
        reservations:
          cpus: '0.25'
          memory: 512M
    networks:
      - middleware-net
      - services-net

  distributed-id-service:
    image: myregistry.local/distributed-id-service:${TAG:-latest}
    environment:
      JAVA_OPTS: >
        -Xms256m -Xmx256m
        -XX:MetaspaceSize=64m
        -XX:MaxMetaspaceSize=128m
        -XX:+UseG1GC
        -XX:+HeapDumpOnOutOfMemoryError
        -XX:HeapDumpPath=/logs/heapdump.hprof
        -Xlog:gc*:file=/logs/gc.log:time,tags:filecount=10,filesize=10M
        -XX:+PrintGCDetails
        -XX:+PrintGCDateStamps
    depends_on:
      nacos:
        condition: service_healthy
    volumes:
      - ./logs/distributed-id-service:/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8082/actuator/health"]
      interval: 10s
      retries: 5
      timeout: 5s
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 256M
    networks:
      - middleware-net
      - services-net

  search-service:
    image: myregistry.local/search-service:${TAG:-latest}
    environment:
      JAVA_OPTS: >
        -Xms512m -Xmx512m
        -XX:MetaspaceSize=128m
        -XX:MaxMetaspaceSize=256m
        -XX:+UseG1GC
        -XX:+HeapDumpOnOutOfMemoryError
        -XX:HeapDumpPath=/logs/heapdump.hprof
        -Xlog:gc*:file=/logs/gc.log:time,tags:filecount=10,filesize=10M
        -XX:+PrintGCDetails
        -XX:+PrintGCDateStamps
    depends_on:
      nacos:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    volumes:
      - ./logs/search-service:/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/actuator/health"]
      interval: 10s
      retries: 5
      timeout: 5s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1024M
        reservations:
          cpus: '0.25'
          memory: 512M
    networks:
      - middleware-net
      - services-net

  file-upload-service:
    image: myregistry.local/file-upload-service:${TAG:-latest}
    environment:
      JAVA_OPTS: >
        -Xms512m -Xmx512m
        -XX:MetaspaceSize=128m
        -XX:MaxMetaspaceSize=256m
        -XX:+UseG1GC
        -XX:+HeapDumpOnOutOfMemoryError
        -XX:HeapDumpPath=/logs/heapdump.hprof
        -Xlog:gc*:file=/logs/gc.log:time,tags:filecount=10,filesize=10M
        -XX:+PrintGCDetails
        -XX:+PrintGCDateStamps
    depends_on:
      nacos:
        condition: service_healthy
      minio:
        condition: service_healthy
    volumes:
      - ./logs/file-upload-service:/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8084/actuator/health"]
      interval: 10s
      retries: 5
      timeout: 5s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1024M
        reservations:
          cpus: '0.25'
          memory: 512M
    networks:
      - middleware-net
      - services-net

  rbac-service:
    image: myregistry.local/rbac-service:${TAG:-latest}
    environment:
      JAVA_OPTS: >
        -Xms512m -Xmx512m
        -XX:MetaspaceSize=128m
        -XX:MaxMetaspaceSize=256m
        -XX:+UseG1GC
        -XX:+HeapDumpOnOutOfMemoryError
        -XX:HeapDumpPath=/logs/heapdump.hprof
        -Xlog:gc*:file=/logs/gc.log:time,tags:filecount=10,filesize=10M
        -XX:+PrintGCDetails
        -XX:+PrintGCDateStamps
    depends_on:
      nacos:
        condition: service_healthy
      mysql:
        condition: service_healthy
    volumes:
      - ./logs/rbac-service:/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8085/actuator/health"]
      interval: 10s
      retries: 5
      timeout: 5s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1024M
        reservations:
          cpus: '0.25'
          memory: 512M
    networks:
      - middleware-net
      - services-net

  user-service:
    image: myregistry.local/user-service:${TAG:-latest}
    environment:
      JAVA_OPTS: >
        -Xms512m -Xmx512m
        -XX:MetaspaceSize=128m
        -XX:MaxMetaspaceSize=256m
        -XX:+UseG1GC
        -XX:+HeapDumpOnOutOfMemoryError
        -XX:HeapDumpPath=/logs/heapdump.hprof
        -Xlog:gc*:file=/logs/gc.log:time,tags:filecount=10,filesize=10M
        -XX:+PrintGCDetails
        -XX:+PrintGCDateStamps
    depends_on:
      nacos:
        condition: service_healthy
      mysql:
        condition: service_healthy
      redis:
        condition: service_healthy
      sso-service:
        condition: service_healthy
    volumes:
      - ./logs/user-service:/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8086/actuator/health"]
      interval: 10s
      retries: 5
      timeout: 5s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1024M
        reservations:
          cpus: '0.25'
          memory: 512M
    networks:
      - middleware-net
      - services-net

  product-service:
    image: myregistry.local/product-service:${TAG:-latest}
    environment:
      JAVA_OPTS: >
        -Xms512m -Xmx512m
        -XX:MetaspaceSize=128m
        -XX:MaxMetaspaceSize=256m
        -XX:+UseG1GC
        -XX:+HeapDumpOnOutOfMemoryError
        -XX:HeapDumpPath=/logs/heapdump.hprof
        -Xlog:gc*:file=/logs/gc.log:time,tags:filecount=10,filesize=10M
        -XX:+PrintGCDetails
        -XX:+PrintGCDateStamps
    depends_on:
      nacos:
        condition: service_healthy
      mysql:
        condition: service_healthy
    volumes:
      - ./logs/product-service:/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8087/actuator/health"]
      interval: 10s
      retries: 5
      timeout: 5s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1024M
        reservations:
          cpus: '0.25'
          memory: 512M
    networks:
      - middleware-net
      - services-net

  order-service:
    image: myregistry.local/order-service:${TAG:-latest}
    environment:
      JAVA_OPTS: >
        -Xms512m -Xmx512m
        -XX:MetaspaceSize=128m
        -XX:MaxMetaspaceSize=256m
        -XX:+UseG1GC
        -XX:+HeapDumpOnOutOfMemoryError
        -XX:HeapDumpPath=/logs/heapdump.hprof
        -Xlog:gc*:file=/logs/gc.log:time,tags:filecount=10,filesize=10M
        -XX:+PrintGCDetails
        -XX:+PrintGCDateStamps
    depends_on:
      nacos:
        condition: service_healthy
      mysql:
        condition: service_healthy
      user-service:
        condition: service_healthy
      product-service:
        condition: service_healthy
    volumes:
      - ./logs/order-service:/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8088/actuator/health"]
      interval: 10s
      retries: 5
      timeout: 5s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1024M
        reservations:
          cpus: '0.25'
          memory: 512M
    networks:
      - middleware-net
      - services-net

  payment-service:
    image: myregistry.local/payment-service:${TAG:-latest}
    environment:
      JAVA_OPTS: >
        -Xms512m -Xmx512m
        -XX:MetaspaceSize=128m
        -XX:MaxMetaspaceSize=256m
        -XX:+UseG1GC
        -XX:+HeapDumpOnOutOfMemoryError
        -XX:HeapDumpPath=/logs/heapdump.hprof
        -Xlog:gc*:file=/logs/gc.log:time,tags:filecount=10,filesize=10M
        -XX:+PrintGCDetails
        -XX:+PrintGCDateStamps
    depends_on:
      nacos:
        condition: service_healthy
      mysql:
        condition: service_healthy
      order-service:
        condition: service_healthy
    volumes:
      - ./logs/payment-service:/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8089/actuator/health"]
      interval: 10s
      retries: 5
      timeout: 5s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1024M
        reservations:
          cpus: '0.25'
          memory: 512M
    networks:
      - middleware-net
      - services-net

  multi-tenant-service:
    image: myregistry.local/multi-tenant-service:${TAG:-latest}
    environment:
      JAVA_OPTS: >
        -Xms512m -Xmx512m
        -XX:MetaspaceSize=128m
        -XX:MaxMetaspaceSize=256m
        -XX:+UseG1GC
        -XX:+HeapDumpOnOutOfMemoryError
        -XX:HeapDumpPath=/logs/heapdump.hprof
        -Xlog:gc*:file=/logs/gc.log:time,tags:filecount=10,filesize=10M
        -XX:+PrintGCDetails
        -XX:+PrintGCDateStamps
    depends_on:
      nacos:
        condition: service_healthy
      mysql:
        condition: service_healthy
    volumes:
      - ./logs/multi-tenant-service:/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8090/actuator/health"]
      interval: 10s
      retries: 5
      timeout: 5s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1024M
        reservations:
          cpus: '0.25'
          memory: 512M
    networks:
      - middleware-net
      - services-net

networks:
  middleware-net:
    external: true
  services-net:
    driver: bridge

volumes:
  logs:
```

#### JVM参数说明

- `-Xms512m -Xmx512m`：初始和最大堆内存，平衡性能与资源。
- `-XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=256m`：控制元空间，防止溢出。
- `-XX:+UseG1GC`：使用G1垃圾回收器，适合微服务低延迟场景。
- `-XX:+HeapDumpOnOutOfMemoryError`：OOM时生成堆转储文件。
- `-XX:HeapDumpPath=/logs/heapdump.hprof`：指定堆转储路径。
- `-Xlog:gc*:file=/logs/gc.log:time,tags:filecount=10,filesize=10M`：记录GC日志，限制文件大小和数量。
- `-XX:+PrintGCDetails -XX:+PrintGCDateStamps`：输出详细GC信息和时间戳。

#### 启动器选择

- 默认使用Spring Boot内置的Tomcat，适合大多数场景。

- 对于高并发服务（如网关），可切换到Undertow：

  ```xml
  <dependency>
      <groupId>org.springframework.boot</groupId>
      <artifactId>spring-boot-starter-web</artifactId>
      <exclusions>
          <exclusion>
              <groupId>org.springframework.boot</groupId>
              <artifactId>spring-boot-starter-tomcat</artifactId>
          </exclusion>
      </exclusions>
  </dependency>
  <dependency>
      <groupId>org.springframework.boot</groupId>
      <artifactId>spring-boot-starter-undertow</artifactId>
  </dependency>
  ```

#### 面试官拷打

1. 端口暴露是否安全？

   - **问题**：未暴露端口，服务间如何通信？

   - 修正

     ：通过

     ```
     services-net
     ```

     网络实现内部通信，仅网关暴露

     ```
     8080
     ```

     端口到宿主机：

     ```yaml
     gateway:
       ports:
         - "8080:8080"
     ```

2. 依赖关系是否完整？

   - **问题**：订单服务依赖用户服务和产品服务，但未考虑分布式事务。
   - **修正**：订单服务集成Seata，确保分布式事务一致性。

3. 日志收集如何实现？

   - **问题**：仅将日志映射到主机，缺乏集中式日志管理。

   - 修正

     ：集成Loki或ELK，配置Filebeat收集容器日志：

     ```yaml
     filebeat:
       image: elastic/filebeat:8.8.0
       volumes:
         - ./logs:/logs:ro
       depends_on:
         elasticsearch:
           condition: service_healthy
     ```

4. 服务扩展性如何保证？

   - **问题**：单一实例可能无法应对高并发。

   - 修正

     ：为高负载服务（如网关）配置多实例：

     ```yaml
     gateway:
       deploy:
         replicas: 2
     ```

------

## Jenkins CI/CD 流水线设计

基于Gitflow，我们为开发、FAT、UAT和生产环境设计Jenkins流水线。以下是完整的`Jenkinsfile`：

```groovy
pipeline {
    agent any
    environment {
        DOCKER_REGISTRY = 'myregistry.local'
        DOCKER_CRED = credentials('docker-registry-cred')
        SSH_CRED = credentials('ssh-cred')
        GIT_COMMIT_SHORT = sh(script: "echo \${GIT_COMMIT:0:7}", returnStdout: true).trim()
    }
    stages {
        stage('Checkout') {
            steps {
                git branch: env.GIT_BRANCH, url: 'http://gitlab.local/project.git'
            }
        }
        stage('Unit Test') {
            steps {
                sh 'mvn clean test'
            }
            post {
                always {
                    junit '**/target/surefire-reports/*.xml'
                }
            }
        }
        stage('Code Coverage') {
            when { anyOf { branch 'develop'; branch 'release/*'; branch 'main' } }
            steps {
                sh 'mvn jacoco:report'
                publishHTML(target: [
                    reportDir: 'target/site/jacoco',
                    reportFiles: 'index.html',
                    reportName: 'JaCoCo Report'
                ])
            }
        }
        stage('Build Docker Image') {
            when { anyOf { branch 'develop'; branch 'release/*'; branch 'main' } }
            steps {
                sh 'mvn clean package -DskipTests'
                sh "docker build -t ${DOCKER_REGISTRY}/${env.JOB_NAME}:${GIT_COMMIT_SHORT} ."
                sh "docker tag ${DOCKER_REGISTRY}/${env.JOB_NAME}:${GIT_COMMIT_SHORT} ${DOCKER_REGISTRY}/${env.JOB_NAME}:latest"
            }
        }
        stage('Push to Registry') {
            when { anyOf { branch 'develop'; branch 'release/*'; branch 'main' } }
            steps {
                sh "docker login -u ${DOCKER_CRED_USR} -p ${DOCKER_CRED_PSW} ${DOCKER_REGISTRY}"
                sh "docker push ${DOCKER_REGISTRY}/${env.JOB_NAME}:${GIT_COMMIT_SHORT}"
                sh "docker push ${DOCKER_REGISTRY}/${env.JOB_NAME}:latest"
            }
        }
        stage('Deploy to FAT') {
            when { branch 'develop' }
            steps {
                sshagent(credentials: ['ssh-cred']) {
                    sh '''
                        ssh -o StrictHostKeyChecking=no user@fat-server '
                            docker-compose -f /path/to/docker-compose.services.yml pull &&
                            docker-compose -f /path/to/docker-compose.services.yml up -d &&
                            docker images ${DOCKER_REGISTRY}/${env.JOB_NAME} -q | sort -u | grep -v ${GIT_COMMIT_SHORT} | xargs -r docker rmi -f
                        '
                    '''
                }
            }
        }
        stage('Integration Test') {
            when { branch 'release/*' }
            steps {
                sh 'mvn verify -Pintegration-test'
            }
            post {
                always {
                    junit '**/target/failsafe-reports/*.xml'
                }
            }
        }
        stage('Deploy to UAT') {
            when { branch 'release/*' }
            steps {
                sshagent(credentials: ['ssh-cred']) {
                    sh '''
                        ssh -o StrictHostKeyChecking=no user@uat-server '
                            docker-compose -f /path/to/docker-compose.services.yml pull &&
                            docker-compose -f /path/to/docker-compose.services.yml up -d &&
                            docker images ${DOCKER_REGISTRY}/${env.JOB_NAME} -q | sort -u | grep -v ${GIT_COMMIT_SHORT} | xargs -r docker rmi -f
                        '
                    '''
                }
            }
        }
        stage('Deploy to Production') {
            when { branch 'main' }
            steps {
                input message: 'Approve deployment to production?', ok: 'Deploy'
                sshagent(credentials: ['ssh-cred']) {
                    sh '''
                        ssh -o StrictHostKeyChecking=no user@prod-server '
                            docker tag ${DOCKER_REGISTRY}/${env.JOB_NAME}:latest ${DOCKER_REGISTRY}/${env.JOB_NAME}:previous &&
                            docker-compose -f /path/to/docker-compose.services.yml pull &&
                            docker-compose -f /path/to/docker-compose.services.yml up -d &&
                            docker images ${DOCKER_REGISTRY}/${env.JOB_NAME} -q | sort -u | grep -v ${GIT_COMMIT_SHORT} | grep -v previous | xargs -r docker rmi -f
                        '
                    '''
                }
            }
        }
    }
    post {
        always {
            sh 'docker logout ${DOCKER_REGISTRY}'
        }
        success {
            slackSend channel: '#ci-cd', message: "Build ${env.JOB_NAME} #${env.BUILD_NUMBER} succeeded for ${env.GIT_BRANCH}"
        }
        failure {
            slackSend channel: '#ci-cd', message: "Build ${env.JOB_NAME} #${env.BUILD_NUMBER} failed for ${env.GIT_BRANCH}"
        }
    }
}
```

### 流水线逻辑

1. **Checkout**：检出代码，基于Git分支。
2. **Unit Test**：运行单元测试，生成测试报告。
3. **Code Coverage**：使用JaCoCo检查代码覆盖率，发布报告。
4. **Build Docker Image**：为`develop`、`release/*`和`main`分支构建镜像，使用Git Commit ID短码。
5. **Push to Registry**：推送镜像到私有仓库。
6. Deploy：
   - **FAT**：`develop`分支触发，部署到FAT环境。
   - **UAT**：`release/*`分支触发，运行集成测试后部署。
   - **Production**：`main`分支触发，需人工审批，支持回滚。
7. **Post**：清理Docker登录状态，发送Slack通知。

#### 集成JaCoCo

在`pom.xml`中配置JaCoCo，确保覆盖率达80%：

```xml
<plugin>
    <groupId>org.jacoco</groupId>
    <artifactId>jacoco-maven-plugin</artifactId>
    <version>0.8.8</version>
    <executions>
        <execution>
            <goals>
                <goal>prepare-agent</goal>
                <goal>report</goal>
                <goal>check</goal>
            </goals>
            <configuration>
                <rules>
                    <rule>
                        <element>BUNDLE</element>
                        <limits>
                            <limit>
                                <counter>LINE</counter>
                                <value>COVEREDRATIO</value>
                                <minimum>0.80</minimum>
                            </limit>
                        </limits>
                    </rule>
                </rules>
            </configuration>
        </execution>
    </executions>
</plugin>
```

#### 面试官拷打

1. SSH部署是否安全？

   - **问题**：SSH操作服务器存在安全风险，难以审计。

   - 修正

     ：使用Ansible或Kubernetes，减少手动操作。例如：

     ```yaml
     # Ansible playbook
     - name: Deploy Docker Compose
       hosts: all
       tasks:
         - name: Pull and deploy
           shell: |
             docker-compose -f /path/to/docker-compose.services.yml pull
             docker-compose -f /path/to/docker-compose.services.yml up -d
     ```

2. 镜像清理策略合理吗？

   - **问题**：直接删除旧镜像可能误删其他服务镜像。
   - **修正**：仅删除当前服务的老镜像，保留`previous`标签用于回滚。

3. 测试覆盖率如何验证？

   - **问题**：未设置自动失败机制。
   - **修正**：JaCoCo的`check`目标自动失败低于80%的构建。

4. 生产部署如何降低风险？

   - **问题**：无蓝绿部署或金丝雀发布。

   - 修正

     ：实现蓝绿部署，逐步切换流量：

     ```bash
     docker-compose -f /path/to/docker-compose.services.yml up -d --scale gateway=2
     ```

------

## 优化与真实开发流程贴合

### 优化建议

1. 服务发现与配置

   ：

   - 使用Nacos动态管理服务注册和配置。
   - 服务启动时从Nacos拉取环境变量，避免硬编码。

2. 日志与监控

   ：

   - 集成Prometheus和Grafana，监控CPU、内存、请求延迟。
   - 使用Loki收集容器日志，配置Grafana查看。

3. 自动化测试

   ：

   - FAT/UAT环境增加集成测试（Maven Failsafe插件）和压力测试（JMeter）。

4. 容器编排

   ：

   - 建议迁移到Kubernetes，使用Helm Chart管理复杂部署。

5. 安全性

   ：

   - Docker Registry启用TLS，使用Secrets管理密码。
   - 配置Nacos ACL，限制服务访问。

6. 备份与恢复

   ：

   - MySQL/MongoDB配置定时备份，存储至MinIO或S3。

   - 使用CronJob运行备份脚本：

     ```bash
     #!/bin/bash
     mysqldump -h mysql -uroot -proot123 microservice_db > /backup/db-$(date +%F).sql
     ```

### 真实开发流程贴合

- Gitflow改进

  ：

  - 强制Code Review，MR需两人通过。
  - `feature`分支命名规范：`feature/module-name-v1`。

- 环境隔离

  ：

  - 各环境使用独立Nacos命名空间、数据库实例。
  - 生产环境启用MySQL读写分离和Redis集群。

- 版本管理

  ：

  - 镜像版本基于语义化版本（如`v1.2.3`）或Git Commit ID。

- 部署策略

  ：

  - 生产环境采用蓝绿部署，UAT环境测试金丝雀发布。

------

## 总结

本文提供了一个完整的微服务项目CI/CD流水线和Docker Compose部署方案，覆盖所有中间件和业务服务，基于Gitflow实现多环境部署。通过模拟面试官审查，我们优化了网络隔离、资源限制、日志收集和部署策略，确保方案贴近真实开发场景。未来可进一步迁移到Kubernetes，集成Chaos Engineering，提升系统韧性。