[toc]



# 2024年

### 9.3

#### **A.事务ACID复习**:

1. 结合SQL代码示例：
以下是一个简单的SQL示例，用于展示如何在不同的隔离级别下操作数据库：
```sql
-- 假设有一个账户表 account，包含字段 id, name, balance
-- 开启事务
START TRANSACTION;
-- 查询账户余额
SELECT balance FROM account WHERE id = 1;
-- 更新账户余额
UPDATE account SET balance = balance - 100 WHERE id = 1;
-- 提交事务
COMMIT;
```
2. 分析脏读、不可重复读、幻读及隔离级别：
- **脏读**：在一个事务中，读取到了另一个未提交事务修改的数据。这种情况会导致数据不一致。
  隔离级别：**Read Uncommitted** 允许脏读发生。
- **不可重复读**：在一个事务中，多次读取同一数据时，结果不一致，因为其他事务在两次读取之间修改了该数据。
  隔离级别：**Read Committed** 可以避免脏读，但不可重复读仍然可能发生。
- **幻读**：在一个事务中，多次执行同一查询，结果集不一致，因为其他事务在两次查询之间插入了新的数据行。
  隔离级别：**Repeatable Read** 可以避免脏读和不可重复读，但幻读仍然可能发生。
- **Serializable**：这是最高的隔离级别，可以避免脏读、不可重复读和幻读。它通过锁定事务涉及的所有数据行来实现，但可能会导致较大的性能开销。
3. 文本内容（无Markdown标题）：
**Read Uncommitted**：允许脏读，事务可以看到其他事务未提交的数据，这是最低的隔离级别。
**Read Committed**：避免了脏读，但不可重复读和幻读仍然可能发生。这是大多数数据库系统的默认隔离级别。
**Repeatable Read**：避免了脏读和不可重复读，但幻读仍然可能发生。在这个隔离级别下，事务在执行过程中看到的数据是一致的。
**Serializable**：这是最高的隔离级别，可以避免脏读、不可重复读和幻读。它通过锁定事务涉及的所有数据行来实现，但可能会导致较大的性能开销。

#### **B.MVCC机制：**

在InnoDB中，每一个table中都有两个隐藏column。分别对应创建版本和删除版本号。且每个时间节点系统版本号不同

- B.1: insert/update/delete 操作对应版本号的处理方式如下：
  - **insert**: 写入当前系统版本号作为新行的“创建版本号”。
  - **update**: 写入当前系统版本号作为新行的“创建版本号”，并将当前系统版本号作为旧行的“删除版本号”。
  - **delete**: 写入当前系统版本号作为行的“删除版本号”。
- B.2: select 操作的查询规则如下：
  - 查询会返回那些创建版本号小于当前系统版本号的行，且这些行的删除版本号大于当前系统版本号。这样可以确保事务看到的是一致的数据快照，即事务开始时已经存在的数据，且没有被其他并发事务删除的数据。

#### **C.索引：**

##### C.1：索引本质

索引的本质是一种数据结构，它允许数据库高效地进行数据检索操作。在数据库管理系统中，索引的作用类似于书籍的目录，它提供了快速定位到特定数据行的能力，从而避免了全表扫描，提高了查询效率。
以下是索引的一些核心特点和本质：
1. **数据结构**：索引通常是基于特定的数据结构实现的，如B树（B-Tree）、B+树、哈希表、R树等。这些数据结构被设计用来优化查找、插入和删除操作。
2. **有序性**：索引通常按照一定的顺序存储数据，这样就可以利用二分查找等算法快速定位到特定值或值的范围。
3. **映射关系**：索引建立了数据库表中数据行与索引键值之间的映射关系。对于每一行数据，索引记录了其键值与数据行物理地址的对应关系。
4. **空间换时间**：索引通过占用额外的存储空间来减少查询操作的时间复杂度。索引本身也需要存储和维护，因此会占用额外的磁盘空间。
5. **辅助查询**：索引主要用于加速查询操作，尤其是WHERE子句、JOIN操作、ORDER BY和GROUP BY等。
6. **唯一性**：某些类型的索引（如主键索引）保证了索引键值的唯一性，这有助于维护数据的完整性。
7. **选择性**：索引的选择性是指索引键值区分数据行的能力。高选择性的索引可以更有效地过滤数据。
8. **维护成本**：虽然索引可以加速查询，但它们也需要在插入、删除和更新数据时进行维护，这可能会降低写操作的性能。
索引的这些本质属性共同决定了其在数据库系统中的重要作用，即在保证数据完整性和一致性的同时，提供快速的数据访问路径。****

##### C.2：聚簇索引

聚簇索引（Clustered Index）的本质不是表（table），而是一种特定的索引结构，它决定了数据在磁盘上的**物理存储顺序**。以下是聚簇索引的一些关键点：
1. **数据存储顺序**：聚簇索引决定了表中数据的物理存储顺序。在聚簇索引中，索引的叶节点直接包含了表的数据行，这意味着表的**数据行**实际上存储在**聚簇索引**的**叶节点**上。
2. **唯一性**：在大多数数据库系统中，每个表只能有**一个聚簇索引**，因为数据行只能有一种物理排序方式。
3. **主键与聚簇索引**：通常情况下，数据库表的**主键会自动成为**聚簇索引。这是因为主键具有唯一性，而聚簇索引能够很好地支持这种唯一性。
4. **非聚簇索引**：与聚簇索引相对的是**非聚簇索引**（也称为**二级索引**或**辅助索引**），它们不决定数据的物理存储顺序，而是包含**索引键值**和**指向数据行的指针**。
聚簇索引的本质特点如下：
- **索引结构**：聚簇索引通常是基于B+树结构实现的，其中叶节点包含了完整的行数据。
- **性能考虑**：由于数据行按照聚簇索引的顺序存储，因此对于基于聚簇索引键值的查询操作，可以直接访问到数据行，通常会有更好的性能。
- **插入和删除操作**：插入、删除和更新操作可能会更复杂，因为它们可能需要重新组织数据页以维持聚簇索引的顺序。
总的来说，聚簇索引是一种特殊的索引，它与表的数据行紧密相关，但并不是表本身。表是一个更广泛的概念，它包含了数据行、列、索引、约束等所有元素。聚簇索引只是表的一个组成部分，用于优化数据的检索性能。

##### C.3：主键索引选取规则： 

存在列满足unique&&not null?设定该列为主键索引列：创建隐藏列为主键索引列

##### C.4：聚簇索引劣势：

**A.页分裂**（在插入操作时，如果新行的聚簇索引键值在物理顺序中位于当前页的中间，可能引起页分裂，降低插入性能，并可能导致磁盘空间利用率下降。）

**B.页合并**（删除操作可能导致页的空闲空间增加，当相邻页的空闲空间过多时，可能需要进行页合并，这个过程同样会带来性能开销。）

**C.删除插入性能影响**（如果查询不使用聚簇索引的列，那么进行全表扫描的效率可能会比较低，因为数据块的物理顺序并不一定是最优的查询顺序。）

##### C.5：覆盖索引（Covering Index）

是一种数据库索引，它包含了查询中需要的所有列的数据，这意味着使用该索引进行查询时，不需要回表（即不需要再次访问原始表来获取数据）。

```sql
SELECT name, department FROM employees WHERE department = 'Sales';//SQL需求 
CREATE INDEX idx_department_name ON employees (department, name);//因大量使用该SQL 因此创建覆盖索引

```

##### C.6：回表（Backward Index Lookup 或 Full Table Scan）

回表是指在数据库查询操作中，当执行非聚簇索引查询并需要获取完整的行数据时，必须额外进行的步骤。下面详细分析回表的过程：

**聚簇索引与非聚簇索引**

在深入理解回表之前，我们需要了解聚簇索引和非聚簇索引的区别：
- **聚簇索引**：聚簇索引决定了数据在磁盘上的物理存储顺序。在聚簇索引中，索引的叶节点包含了完整的行数据。通常，表的主键会自动成为聚簇索引。
- **非聚簇索引**：非聚簇索引（也称为二级索引或辅助索引）不决定数据的物理存储顺序。它的叶节点包含了索引键值和指向数据行的指针（通常是行ID或磁盘地址）。

**回表过程**

当执行一个查询，如果使用了非聚簇索引，以下是回表的具体步骤：
1. **索引查找**：数据库首先在非聚簇索引中查找符合条件的索引键值。如果找到了，它会得到一个指向数据行的指针。
2. **获取行数据**：由于非聚簇索引的叶节点不包含完整的行数据，数据库需要使用得到的指针回到聚簇索引（或表的数据行）中，以获取完整的行数据。
3. **数据返回**：一旦完整的行数据被检索到，它就会被返回给用户。

**示例**

假设我们有一个 `employees` 表，它有一个聚簇索引在 `id` 列上，以及一个非聚簇索引在 `last_name` 列上。
```sql
CREATE TABLE employees (
    id INT AUTO_INCREMENT PRIMARY KEY,
    first_name VARCHAR(50),
    last_name VARCHAR(50),
    department_id INT,
    salary DECIMAL(10, 2)
);
CREATE INDEX idx_lastname ON employees(last_name);
```
如果我们执行以下查询：
```sql
SELECT * FROM employees WHERE last_name = 'Smith';
```
以下是回表的步骤：
1. **索引查找**：数据库使用 `idx_lastname` 索引查找所有 `last_name` 为 'Smith' 的记录。假设找到了多条记录，每条记录都有一个指向对应数据行的指针。
2. **获取行数据**：数据库通过指针回到聚簇索引（即 `id` 列的索引），检索完整的员工记录。
3. **数据返回**：完整的员工记录被返回给用户。

**回表的性能影响**

回表会增加额外的磁盘I/O操作，因为它需要从非聚簇索引的叶节点跳转到聚簇索引的叶节点来获取完整的数据行。如果查询涉及大量的行，这可能会导致性能问题。
为了减少回表的开销，可以考虑以下优化策略：
- **索引覆盖**：创建包含查询所需所有列的非聚簇索引，这样就不需要回表了。
- **选择性索引**：确保索引具有高选择性，以减少需要回表的行数。
- **查询优化**：尽量避免在查询中使用 `SELECT *`，而是只选择需要的列，以减少回表的数据量。

##### C.7：索引结构：

索引的本质是一种高效的数据检索机制，它通过存储额外的数据结构来加快数据库中记录的查找速度。以下是索引的两部分及其本质的详细解释：

**索引键（Index Key）**

- **定义**：索引键是从表中的列（一个或多个）提取的值，用于在索引结构中进行排序和查找。
- **本质**：索引键的本质是数据的一个映射，它将数据库中的记录与索引中的位置相对应。通过这个映射，数据库能够快速定位到满足特定条件的数据行，而不必扫描整个表。
- **功能**：
  - 提供排序依据，使得索引中的数据有序。
  - 作为查找的依据，支持快速的搜索操作。

**数据指针（Pointer）**

- **定义**：数据指针是索引中指向原始表记录位置的信息。在聚簇索引中，数据指针可能是记录的物理地址；在非聚簇索引中，它通常是记录的主键或其他唯一标识符。
- **本质**：数据指针的本质是一个引用，它建立了索引与实际数据之间的链接。通过这个引用，数据库能够从索引快速跳转到原始数据行。
- **功能**：
  - 标识记录在存储介质上的位置。
  - 支持从索引到数据的快速访问。

**索引的本质**

- **数据结构**：索引是基于特定的数据结构（如B-Tree、B+Tree、Hash表等）实现的，这些结构被设计来优化数据的插入、删除和查找操作。
- **空间换时间**：索引通过占用额外的存储空间来减少查询操作的时间复杂度，从而提高数据库的查询性能。
- **映射关系**：索引建立了一种映射关系，将索引键值映射到数据行的物理位置，使得数据库能够根据键值快速定位到数据。
- **优化器辅助**：数据库查询优化器使用索引来决定最有效的查询执行计划，从而提高查询效率。
- **维护开销**：索引需要额外的维护，如插入、删除和更新操作时对索引结构的调整，这可能会降低写操作的性能。
综上所述，索引的本质是一种以空间换时间的数据结构，它通过建立索引键与数据指针之间的映射关系，提供了一种快速访问数据库记录的机制。

##### C.8：哈希索引与自适应哈希索引

**哈希索引**

```sql
CREATE TABLE users(
	user_id INT PRIMARY KEY,
    username VARCHAR(50)
)
```

现在我们创建一个哈希索引：

```sql
create hash index idx_username on users(username);
```

在这个例子中，数据库会使用哈希函数来计算每个 `username` 的哈希值，并将这些哈希值映射到相应的 `user_id`。当我们执行以下查询时：

```sql
select user_id from users where username="john_doe"
```

**自适应哈希索引：**InnoDB引擎提供的特性，创建基于频繁访问的索引页上的哈希索引，是自动的。

```sql
CREATE TABLE orders (
    order_id INT PRIMARY KEY,
    customer_id INT,
    order_date DATE
);

```

如果数据库检测到对于 `customer_id` 的查询非常频繁，InnoDB存储引擎可能会自动为这个列创建自适应哈希索引。这个过程是自动的，并且是动态的，数据库会根据查询模式和数据访问模式来调整哈希索引。

例如，如果我们频繁执行以下查询：

```sql
SELECT * FROM orders WHERE customer_id = 12345;
```

InnoDB可能会为 `customer_id` 列创建自适应哈希索引，这样后续的查询就可以通过哈希索引快速找到对应的订单，而不需要扫描整个索引。

需要注意的是，自适应哈希索引的具体实现细节和触发条件是由数据库内部机制决定的，用户无法直接控制或创建自适应哈希索引。在某些数据库系统中，例如MySQL的InnoDB存储引擎，自适应哈希索引是自动管理的，用户通常只能通过配置参数来启用或禁用这个特性。

##### C.9冗余索引和重复索引

在数据库中，索引是提高查询性能的关键工具，但不当的管理可能会导致索引的冗余和重复，这不仅浪费存储空间，还可能降低数据库的性能。以下是冗余索引和重复索引的定义和分析：

**冗余索引（Redundant Index）**

**定义**：
冗余索引是指在一个索引已经能够满足查询需求的情况下，又创建了另一个功能上等效或部分重叠的索引。
**分析**：
- **功能重叠**：如果索引A包含列(a, b)，而索引B包含列(a)，那么索引B可能是冗余的，因为索引A已经包含了索引B的功能。
- **非最优查询计划**：冗余索引可能导致数据库查询优化器选择非最优的查询计划，因为优化器需要考虑更多的索引选项。
- **维护成本**：冗余索引需要额外的维护，例如在插入、删除或更新数据时，所有相关的索引都需要更新。
**示例**：
```sql
CREATE INDEX idx_ab ON table1(a, b);
CREATE INDEX idx_a ON table1(a); -- 可能是冗余的，因为idx_ab已经包含了a列
```
**重复索引（Duplicate Index）**

**定义**：
重复索引是指具有完全相同的列和列顺序的索引，即两个或多个索引在结构上完全相同。
**分析**：

- **资源浪费**：重复索引会浪费存储空间，因为它们存储了相同的数据。
- **性能下降**：在写操作（如INSERT、UPDATE、DELETE）时，每个重复索引都需要更新，这会增加写操作的开销，从而降低性能。
- **管理混乱**：重复索引可能导致数据库管理员在维护和优化数据库时产生混淆。
**示例**：
```sql
CREATE INDEX idx_a ON table1(a);
CREATE INDEX idx_a ON table1(a); -- 这是一个重复索引，因为它与上面的索引完全相同
```
**区别**

- **冗余索引**：通常是指索引的部分重叠，即一个索引包含了另一个索引的全部或部分列。
- **重复索引**：是指索引的完全重叠，即两个索引在结构和列顺序上完全相同。

**如何检测和解决冗余和重复索引**

- **检测**：数据库管理系统通常提供了工具或命令来分析索引，例如MySQL的`information_schema`或`EXPLAIN`命令。
- **解决**：一旦检测到冗余或重复索引，可以通过删除不必要的索引来优化数据库。在删除之前
- ，应该仔细分析索引的使用情况，以确保不会影响现有的查询性能。
```sql
-- 示例：删除重复索引
DROP INDEX idx_a ON table1;
```
在处理冗余和重复索引时，应该谨慎进行，确保不会对数据库的性能和功能产生负面影响。

#### D.慢查询

##### D.1查询开销的衡量

在MySQL中，衡量查询开销通常涉及以下几个步骤和指标：

1. **使用 `EXPLAIN` 或 `EXPLAIN ANALYZE`**

- **`EXPLAIN`**：这个命令可以用来查看MySQL如何执行一个查询语句。它会返回关于表的读取顺序、使用的索引、每个表的行数估计以及其他一些执行细节。
  ```sql
  EXPLAIN SELECT * FROM my_table WHERE id = 1;
  ```
- **`EXPLAIN ANALYZE`**（MySQL 8.0+）：这个命令不仅提供查询计划，还会实际执行查询并返回实际的执行时间和其他性能指标。
  
  ```sql
  EXPLAIN ANALYZE SELECT * FROM my_table WHERE id = 1;
  ```
2. **分析 `EXPLAIN` 输出**

以下是一些关键的指标和它们的意义：
- **`id`**：查询中每个SELECT语句的标识符。
- **`select_type`**：SELECT的类型，如SIMPLE（简单查询）、PRIMARY（外层查询）、UNION（UNION中的第二个或随后的SELECT）等。
- **`table`**：查询所涉及的表。
- **`type`**：连接类型，如ALL（全表扫描）、index（索引扫描）等。这个指标可以告诉你查询是否高效。
- **`possible_keys`**：可能用于查询的索引。
- **`key`**：实际使用的索引。
- **`key_len`**：使用的索引的长度。
- **`ref`**：显示索引的哪一列被使用了，如果可能的话，是一个常数。
- **`rows`**：MySQL认为必须检查的行数，这是一个估计值，而不是实际值。
- **`filtered`**：按表条件过滤的行百分比。
- **`Extra`**：包含MySQL解析查询的额外信息，如Using index（使用了覆盖索引）、Using where（使用了WHERE子句来过滤结果）等。
3. **使用 `SHOW PROFILE`（MySQL 5.7及以下版本）**

- 这个命令可以用来分析查询的性能，包括CPU和内存的使用情况。
  ```sql
  SET profiling = 1;
  SELECT * FROM my_table WHERE id = 1;
  SHOW PROFILES;
  ```
4. **监控性能变量**

- MySQL提供了一系列性能变量，可以通过`SHOW STATUS`命令来查看，这些变量可以帮助衡量查询的开销。
  ```sql
  SHOW STATUS LIKE 'Innodb_rows_read';
  ```

5. **实际执行时间**

- 使用`NOW()`函数在查询前后记录时间，可以计算出查询的实际执行时间。
  ```sql
  SET @start_time = NOW();
  SELECT * FROM my_table WHERE id = 1;
  SET @end_time = NOW();
  SELECT TIMEDIFF(@end_time, @start_time) AS query_time;
  ```
  通过上述方法，你可以全面地衡量MySQL查询的开销，并据此进行优化。记住，优化查询时，不仅要关注单个查询的性能，还要考虑整体系统负载和并发情况。

##### D.2查询切分与分解关联查询

**查询切分（Query Splitting）**

查询切分是将一个大查询分解成多个小查询的过程，每个小查询处理查询的一部分数据。这种方法通常用于处理大数据集，可以提高查询的性能。

1. **水平切分（Sharding）**

水平切分是将**数据行**按照一定规则分散到不同的表中。每个表只包含数据的一部分，这样查询时只需要访问包含所需数据的表。

2. **垂直切分（Skewing）**

垂直切分是将**数据列**分散到不同的表中。每个表包含数据的一个子集，这样查询时只需要访问包含所需列的表。

**分解关联查询（Decomposing Joins）**

分解关联查询是将一个复杂的关联查询分解成多个简单的查询，每个查询处理查询的一部分数据。这种方法可以减少查询的数据量，从而提高查询的性能。
1. **连接条件分解**

将一个复杂的连接条件分解成多个简单的连接条件，每个条件处理查询的一部分数据。

2. **表分解**

将一个大表分解成多个小表，每个小表包含数据的一个子集。查询时，只访问包含所需数据的表。

**示例**

假设有一个大表`orders`，包含大量的订单数据，我们想要查询特定日期范围内的订单信息。

**原始查询**

```sql
SELECT * FROM orders WHERE order_date BETWEEN '2023-01-01' AND '2023-01-31';
```
**查询切分**

我们可以将这个查询分解成两个小查询，每个查询处理日期范围的一半数据。
```sql
SELECT * FROM orders WHERE order_date BETWEEN '2023-01-01' AND '2023-01-15';
SELECT * FROM orders WHERE order_date BETWEEN '2023-01-16' AND '2023-01-31';
```
**分解关联查询**

如果`orders`表非常大，我们可以将订单数据分解成多个小表，每个表包含特定日期范围内的订单信息。
```sql
CREATE TABLE orders_jan_01_to_15 AS SELECT * FROM orders WHERE order_date BETWEEN '2023-01-01' AND '2023-01-15';
CREATE TABLE orders_jan_16_to_31 AS SELECT * FROM orders WHERE order_date BETWEEN '2023-01-16' AND '2023-01-31';
SELECT * FROM orders_jan_01_to_15 WHERE order_id = 1;
SELECT * FROM orders_jan_16_to_31 WHERE order_id = 1;
```
通过查询切分和分解关联查询，我们可以提高查询的性能，尤其是在处理大数据集时。然而，这种方法也会增加数据库的管理和维护成本，因此在实际应用中需要权衡利弊。

#### E.分区表

##### E.1分区表demo

MySQL的分区表是用于管理大型数据集的一种技术，它可以提高查询性能、优化存储空间和简化维护工作。以下是关于分区表的具体实例分析：
 **实例**
假设我们有一个名为`sales`的表，它包含大量的销售记录，其中`sale_date`列是销售发生的日期。随着时间推移，表中的数据量会不断增加，这可能会导致查询性能下降。

```sql
CREATE TABLE sales (
    sale_id INT AUTO_INCREMENT PRIMARY KEY,
    product_id INT,
    quantity INT,
    sale_date DATE
);
```
 **分析**
 1. 未分区表的问题
- **性能下降**：随着表中数据量的增加，查询性能可能会下降，特别是那些涉及`sale_date`列的范围查询。
- **存储空间**：未分区的表会占用更多的存储空间，因为所有数据都存储在同一个文件中。
- **维护难度**：对于大型表，备份、恢复和数据迁移变得更加复杂和耗时。
 2. 分区表的优势
- **提高性能**：分区可以将表分成多个较小的部分，每个分区可以独立存储和查询，从而提高性能。
- **优化存储**：分区可以更有效地利用存储空间，因为每个分区可以存储在不同的文件中。
- **简化维护**：分区可以简化备份、恢复和数据迁移的工作，因为可以单独处理每个分区。
 分区策略
 1. 范围分区（Range Partitioning）
- **定义**：根据某个列的范围将表分成多个分区。
- **示例**：我们可以根据`sale_date`列的范围将表分成每月一个分区。
```sql
CREATE TABLE sales (
    sale_id INT AUTO_INCREMENT PRIMARY KEY,
    product_id INT,
    quantity INT,
    sale_date DATE
)
PARTITION BY RANGE (sale_date)
(
    PARTITION p0 VALUES LESS THAN ('2023-01-01'),
    PARTITION p1 VALUES LESS THAN ('2023-02-01'),
    PARTITION p2 VALUES LESS THAN ('2023-03-01'),
    -- 更多分区...
);
```
 2. 列表分区（List Partitioning）
- **定义**：根据某个列的值将表分成多个分区。
- **示例**：我们可以根据`product_id`列的值将表分成多个分区。
```sql
CREATE TABLE sales (
    sale_id INT AUTO_INCREMENT PRIMARY KEY,
    product_id INT,
    quantity INT,
    sale_date DATE
)
PARTITION BY LIST (product_id)
(
    PARTITION p0 VALUES IN (1, 2, 3),
    PARTITION p1 VALUES IN (4, 5, 6),
    PARTITION p2 VALUES IN (7, 8, 9),
    -- 更多分区...
);
```
 3. 哈希分区（Hash Partitioning）
- **定义**：根据某个列的哈希值将表分成多个分区。
- **示例**：我们可以根据`sale_id`列的哈希值将表分成多个分区。
```sql
CREATE TABLE sales (
    sale_id INT AUTO_INCREMENT PRIMARY KEY,
    product_id INT,
    quantity INT,
    sale_date DATE
)
PARTITION BY HASH (sale_id)
PARTITIONS 4;
```
 **结论**
通过使用分区表，我们可以有效地管理大型数据集，提高查询性能，优化存储空间和简化维护工作。在实际应用中，应根据具体的数据特性和查询需求选择合适的分区策略。

##### E.2分区表的维护

一旦表被分区，你将需要采取一些特殊的措施来处理这些分区，因为它们可能分布在不同的物理位置上。以下是一些处理分区表的常见操作：
 添加新分区
1. **使用 `ALTER TABLE` 添加新分区**：
   
   ```sql
   ALTER TABLE sales ADD PARTITION (PARTITION p1 VALUES LESS THAN ('2023-04-01'));
   ```
2. **使用 `CREATE TABLE AS` 添加新分区**：
   
   ```sql
   CREATE TABLE sales_p1 AS SELECT * FROM sales WHERE sale_date > '2023-03-31';
   ```
    **删除旧分区**
1. **使用 `ALTER TABLE` 删除旧分区**：
   
   ```sql
   ALTER TABLE sales DROP PARTITION p0;
   ```
2. **使用 `CREATE TABLE AS` 删除旧分区**：
   ```sql
   CREATE TABLE sales_p0 AS SELECT * FROM sales WHERE sale_date <= '2023-03-31';
   ```
    **重命名分区**
```sql
ALTER TABLE sales RENAME PARTITION p0 TO p0_new;
```
 **移动分区**：
在某些情况下，你可能需要将一个分区移动到不同的物理位置，例如，从一个硬盘移动到另一个硬盘。这通常通过将数据从原始位置移动到新位置，然后更新分区定义来实现。
 **合并分区**：
在某些情况下，你可能需要将多个分区合并成一个分区。这通常涉及到将多个分区的数据合并，并更新分区定义。
 注意事项

- **备份和恢复**：在执行任何分区操作之前，确保你有适当的备份，以防操作失败。
- **性能考虑**：某些分区操作可能需要大量的时间和资源，因此在执行之前，请考虑这些操作对系统性能的影响。
- **一致性**：在处理分区时，确保数据的一致性。例如，在添加新分区之前，确保没有旧数据丢失。
在处理分区表时，请仔细考虑操作的影响，并确保你有适当的计划和步骤来执行这些操作。

#### F.后端分页

##### F.1.基于Mybatis-plus实现的分页机制

MyBatis-Plus 是一个增强型的 MyBatis 框架，它提供了许多方便的 API 和功能，包括分页支持。MyBatis-Plus 的分页功能依赖于 MyBatis 的插件机制，因此需要在 MyBatis 的配置文件中添加相应的插件配置。
 1. MyBatis 配置文件
首先，我们需要在 MyBatis 的配置文件（通常位于 `src/main/resources` 目录下的 `mybatis-config.xml`）中配置分页插件。
```xml
<configuration>
    <plugins>
        <plugin interceptor="com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor">
            <property name="pagination" value="true"/>
        </plugin>
    </plugins>
</configuration>
```
 2. 业务场景
假设我们有一个 `User` 实体类，它有一个 `id` 字段作为主键，以及一个 `name` 字段。我们的后端需要提供分页查询接口，以便前端可以根据页码和每页显示的数量来获取用户列表。
 3. 创建分页查询接口
在 MyBatis-Plus 中，你可以使用 `Page` 对象来创建分页查询。以下是一个简单的分页查询接口示例：
```java
import com.baomidou.mybatisplus.core.metadata.IPage;
import com.baomidou.mybatisplus.extension.plugins.pagination.Page;
import com.baomidou.mybatisplus.extension.service.IService;
import com.example.model.User;
public interface UserService extends IService<User> {
    IPage<User> page(Page<User> page, UserQuery query);
}
```
 4. 创建分页查询实现
在 `UserService` 的实现类中，你需要实现 `page` 方法。这个方法将接收一个 `Page` 对象和一个 `UserQuery` 对象，其中 `UserQuery` 包含了查询条件。
```java
import com.baomidou.mybatisplus.core.metadata.IPage;
import com.baomidou.mybatisplus.extension.plugins.pagination.Page;
import com.example.model.User;
import com.example.query.UserQuery;
import com.example.service.UserService;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;
@Service
public class UserServiceImpl implements UserService {
    @Autowired
    private UserMapper userMapper;
    @Override
    public IPage<User> page(Page<User> page, UserQuery query) {
        return userMapper.selectPage(page, new LambdaQueryWrapper<User>()
                .eq(query.getId() != null, User::getId, query.getId())
                .like(query.getName() != null, User::getName, query.getName()));
    }
}
```
在这个实现中，我们使用了 MyBatis-Plus 的 `selectPage` 方法来执行分页查询。我们传递了一个 `Page` 对象和一个 `LambdaQueryWrapper` 对象，后者包含了查询条件。
 5. 前端调用分页查询接口
在前端，你可以使用 JavaScript 库（如 jQuery 或 Axios）来发送请求，并根据页码和每页显示的数量来获取用户列表。
```javascript
function fetchUserList(pageNumber, pageSize) {
    var query = {
        id: null,
        name: null
    };
    $.ajax({
        url: '/user/page',
        type: 'POST',
        data: JSON.stringify({ page: pageNumber, size: pageSize, query: query }),
        contentType: 'application/json',
        success: function(response) {
            // 处理返回的用户列表数据
        }
    });
}
```
在这个例子中，我们假设后端 API 的路径是 `/user/page`，它接受一个 JSON 格式的请求体，其中包含页码、每页显示的数量和查询条件。
通过这种方式，你可以使用 MyBatis和 MyBatis-Plus 来实现一个分页功能的后端服务。下面是完整的示例，包括前端调用分页查询接口的代码。

 **后端代码**
在 MyBatis-Plus 中，你可以使用 `Page` 对象来创建分页查询。
 **控制器代码**
在 Spring Boot 应用程序中，你需要创建一个控制器来处理前端发送的请求。

```java
import com.baomidou.mybatisplus.core.metadata.IPage;
import com.baomidou.mybatisplus.extension.plugins.pagination.Page;
import com.example.model.User;
import com.example.query.UserQuery;
import com.example.service.UserService;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestBody;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;
@RestController
@RequestMapping("/user")
public class UserController {
    @Autowired
    private UserService userService;
    @PostMapping("/page")
    public IPage<User> page(@RequestBody UserQuery query) {
        Page<User> page = new Page<>(query.getPage(), query.getSize());
        return userService.page(page, query);
    }
}
```

### 9.4

#### A.MongoDB复习

##### A.1Why we choose MongoDB

**1.灵活的数据模型:**MongoDB使用一种名为BSON（Binary JSON）的文档存储格式，它允许存储复杂的数据类型，无需预先定义表结构，使得数据模型非常灵活。

**2.高性能:**MongoDB支持高性能的数据持久化，它通过内部机制，如内存映射、索引和副本集，来优化读写操作。

**3.高可用性:**MongoDB的副本集（Replica Sets）功能可以提供数据冗余和自动故障转移，确保了数据的高可用性。

**4.水平可扩展:**MongoDB支持分片（Sharding），这使得数据库可以轻松地通过添加更多的服务器来水平扩展，以支持大数据量的存储和高吞吐量的操作。

**5.丰富的查询语言:**MongoDB提供了丰富的查询接口，支持动态查询、数据聚合、文本搜索和地理空间查询等。

**6.部署的易用性**MongoDB设计简单，部署和维护相对容易，它不需要复杂的配置，支持自动修复和简单的备份操作。

**7.支持多语言客户端**：MongoDB有官方的驱动程序支持多种编程语言，如Java、Python、PHP、C#、C++、Node.js等，方便开发者使用。

**8.副本集的容错性**副本集可以容忍多个节点的故障，并且能够自动恢复，提高了系统的容错能力。

**9.无模式(Schema-less)**MongoDB的无模式特性意味着同一个集合中的文档不需要有相同的字段，这对于处理不断变化的数据结构非常有利。

**10.网格文件系统**MongoDB通过GridFS可以存储和检索超过16MB的文件，适合处理大文件存储。

##### A.2MongoDB的文件架构

- **数据文件（.ns和.data）**:
  - `.ns` 文件：存储命名空间信息，即集合（collection）和索引（index）的元数据。
  - `.data` 文件：存储集合中的实际数据。
- **日志文件（.log）**:
  - 日志文件记录了MongoDB的操作和系统事件，对于调试和审计非常有用。
- **配置文件（mongod.conf）**:
  - 配置文件包含了MongoDB实例的配置选项，如端口号、数据目录路径、日志路径等。
- **诊断文件（.diaglog）**:
  - 如果开启了诊断日志，MongoDB会生成.diaglog文件，用于记录数据库的操作细节。
- **索引文件（.0、.1、.ns等）**:
  - 索引文件用于存储集合的索引数据，它们通常以数字命名。
- **journal文件（.journal）**:
  - 如果启用了journaling（日志记录），MongoDB会使用journal文件来确保数据操作的持久性。在系统崩溃时，journal文件可以用来恢复数据。
- **锁文件（.lock）**:
  - 锁文件用于防止同一数据目录被多个MongoDB实例同时使用。
- **元数据文件（.metadata）**:
  - 存储有关 WiredTiger 存储引擎的元数据。
- **WiredTiger存储引擎文件（WiredTiger.wt等）**:
  - 对于使用WiredTiger存储引擎的MongoDB实例，这些文件用于存储数据和索引。

##### A.3MongoDB的调试工作

**调试MongoDB：**

调试MongoDB通常涉及以下几个步骤：
- **检查日志文件**:
  
  - MongoDB的日志文件通常位于`/var/log/mongodb/mongod.log`（在Linux系统上）。查看日志文件可以帮助诊断问题。
- **使用MongoDB shell**:
  
  - 启动MongoDB shell (`mongo`) 并执行各种命令来检查数据库状态，例如：
    ```javascript
    db.stats() // 查看数据库统计信息
    db.serverStatus() // 查看服务器状态
    ```
- **使用诊断命令**:
  - 使用`db.currentOp()`来查看当前正在进行的操作。
  - 使用`db.killOp()`来终止特定的操作。
- **配置诊断参数**:
  - 在配置文件中设置`diagnosticLogging`和`verbose`参数来增加日志的详细程度。
- **使用第三方工具**:
  - 使用如MongoDB Compass等工具来可视化数据库操作和性能分析。

**MongoDB CRUD操作：**

以下是MongoDB的CRUD（创建、读取、更新、删除）操作的示例：
- **创建（Create）**:
  ```javascript
  db.collection.insertOne({ name: "Alice", age: 25 }) // 插入单个文档
  db.collection.insertMany([{ name: "Bob", age: 30 }, { name: "Charlie", age: 35 }]) // 插入多个文档
  ```
- **读取（Read）**:
  ```javascript
  db.collection.find({}) // 查询所有文档
  db.collection.find({ age: { $gt: 30 } }) // 查询年龄大于30的文档
  db.collection.findOne({ name: "Alice" }) // 查询第一个名为Alice的文档
  ```
- **更新（Update）**:
  ```javascript
  db.collection.updateOne({ name: "Alice" }, { $set: { age: 26 } }) // 更新第一个名为Alice的文档的年龄
  db.collection.updateMany({ age: { $lt: 30 } }, { $inc: { age: 1 } }) // 将所有年龄小于30的文档年龄加1
  ```
- **删除（Delete）**:
  ```javascript
  db.collection.deleteOne({ name: "Alice" }) // 删除第一个名为Alice的文档
  db.collection.deleteMany({ age: { $gte: 35 } }) // 删除所有年龄大于等于35的文档
  ```
  在进行这些操作时，可以使用各种查询操作符来精确控制数据的操作。需要注意的是，CRUD操作可能需要适当的权限才能执行。

##### A.4MongoDB的索引相关


 索引的类型：

1. **单字段索引（Single Field）**：在文档的单个字段上创建索引。
2. **复合索引（Compound Index）**：在文档的多个字段上创建索引。
3. **多键索引（Multikey Index）**：用于索引数组类型的字段，可以对数组中的每个元素创建索引。
4. **文本索引（Text Index）**：用于文本搜索。
5. **哈希索引（Hashed Index）**：对字段值的哈希进行索引，主要用于分片。
 索引命令：
1. **创建索引**：
   ```shell
   db.collection.createIndex({ <field1>: <type>, <field2>: <type>, ... })
   ```
   例如，为`name`字段创建升序索引：
   ```shell
   db.users.createIndex({ "name": 1 })
   ```
2. **创建复合索引**：
   ```shell
   db.collection.createIndex({ <field1>: <type>, <field2>: <type>, ... })
   ```
   例如，为`name`和`age`字段创建复合索引：
   ```shell
   db.users.createIndex({ "name": 1, "age": -1 })
   ```
3. **列出集合的所有索引**：
   ```shell
   db.collection.getIndexes()
   ```
4. **删除索引**：
   根据索引名删除：
   ```shell
   db.collection.dropIndex(<index-name>)
   ```
   删除所有索引（除了`_id`索引）：
   ```shell
   db.collection.dropIndexes()
   ```
5. **解释查询计划**：
   使用`explain`来获取查询的执行计划，这有助于理解是否使用了索引：
   ```shell
   db.collection.find({ <query> }).explain("executionStats")
   ```
    索引的注意事项：
- **性能影响**：索引可以提高查询速度，但也会降低插入、更新和删除操作的速度，因为索引本身也需要维护。
- **存储空间**：索引需要额外的存储空间。
- **索引选择性**：选择那些能够有效区分文档的字段作为索引，以提高查询效率。
- **索引大小**：复合索引的条目数量受限于索引键的总大小，所有索引键的大小总和不能超过1024字节。
使用索引时，应根据实际的应用场景和查询模式来创建合适的索引，以达到最优的性能。

> 在MongoDB中，当你创建一个索引时，MongoDB会自动为该索引生成一个名称。默认情况下，这个名称是由索引的字段名和排序方向组成的。对于你提供的例子 `db.users.createIndex({ "name": 1, "age": -1 })`，生成的索引名大致会是这样的格式：
> ```
> name_1_age_-1
> ```
> 要找到具体的索引名，你可以使用 `getIndexes()` 方法列出集合中的所有索引，并查看每个索引的 `name` 字段。
> 以下是列出所有索引并找到特定索引名的步骤：
>
> ```shell
> db.users.getIndexes()
> ```
> 这会返回一个数组，其中包含所有索引的详细信息，包括每个索引的名称。你可以从中找到与你创建的复合索引对应的名称。
> 例如，输出可能会是这样的：
> ```json
> [
>   {
>     // 第一个索引对象
>     "v" : 2, // 索引的版本号。v:2表示这是MongoDB 2.2及以后版本的索引格式。
>     "key" : {
>       "_id" : 1 // 索引的键。这里表示_id字段上的索引，且排序方向为升序（1表示升序，-1表示降序）。
>     },
>     "name" : "_id_", // 索引的名称。对于_id字段，MongoDB默认创建一个名为_id_的索引。
>     "ns" : "yourDatabaseName.users" // 索引所在的命名空间。格式通常是数据库名.集合名。
>   },
>   {
>     // 第二个索引对象
>     "v" : 2, // 同上，索引版本号。
>     "unique" : false, // 布尔值，表示索引是否是唯一的。这里为false，意味着索引中的值可以重复。
>     "key" : {
>       "name" : 1, // 索引的键。这里表示name字段上的索引，且排序方向为升序。
>       "age" : -1 // 索引的键。这里表示age字段上的索引，且排序方向为降序。
>     },
>     "name" : "name_1_age_-1", // 索引的名称。MongoDB根据索引的字段名和排序方向自动生成。
>     "ns" : "yourDatabaseName.users" // 同上，索引所在的命名空间。
>   }
> ]
> 
> ```
> 在上面的输出中，`"name" : "name_1_age_-1"` 就是你需要用来删除索引的索引名。
> 现在，你可以使用这个索引名来删除索引：
> ```shell
> db.users.dropIndex("name_1_age_-1")
> ```
> 这将删除名为 "name_1_age_-1" 的索引。如果你不确定确切的索引名，一定要先通过 `getIndexes()` 方法检查，以免删除错误的索引。

##### A.5基于电商业务整合MongoDB命令

> 要将shell命令写入一个文件并执行它，你可以按照以下步骤操作：
> ### 步骤 1: 创建一个脚本文件
> 使用文本编辑器（如 `nano`, `vim`, `gedit` 等）创建一个新的文件。例如，我们可以创建一个名为 `script.sh` 的文件。
> ```shell
> nano script.sh
> ```
> ### 步骤 2: 写入shell命令
> 在打开的编辑器中，输入你的shell命令。例如：
> ```shell
> #!/bin/bash
> # 这是注释，说明这个脚本将使用bash来执行
> # MongoDB 示例命令
> mongo <<EOF #<<EOF 是一个Here文档的标记，它告诉shell接下来的文本块直到另一个 EOF 标记为止都应该被当作标准输入传递给 mongo 命令。
> use yourDatabase;
> db.collection.insertOne({ field: "value" });
> db.collection.find();
> EOF#Here文档结束: 这标记了Here文档的结束。所有在 mongo <<EOF 和这个 EOF 标记之间的文本都将作为标准输入传递给 mongo 命令。
> ```
> 确保在文件的第一行包含了 `#!/bin/bash`（或者适合你脚本的其他解释器路径），这被称为shebang，它告诉系统应该使用哪个解释器来执行这个脚本。
> ### 步骤 3: 保存并关闭文件
> 在 `nano` 中，你可以通过按 `Ctrl + X`，然后按 `Y` 来保存文件，最后按 `Enter` 确认文件名并退出编辑器。
> ### 步骤 4: 使脚本可执行
> 你需要给脚本文件设置执行权限：
> ```shell
> chmod +x script.sh
> #chmod:change mode的意思
> #+x +是添加 x是execute permission也就是添加执行权限
> #script.sh 是一个shell脚本文件
> ```
> ### 步骤 5: 执行脚本
> 现在，你可以通过以下命令来执行你的脚本：
> ```shell
> ./script.sh
> ```
> 确保你位于包含 `script.sh` 文件的目录中，或者提供脚本的完整路径。
> ### 注意事项：
> - 如果你的脚本需要以root权限运行，你可能需要使用 `sudo` 来执行它：`sudo ./script.sh`
> - 如果你的脚本中包含对其他用户不安全的命令，或者你需要以其他用户身份运行，确保你知道你在做什么。
> - 如果你在Windows系统上编写脚本，你可能需要创建一个批处理文件（`.bat`）或PowerShell脚本文件（`.ps1`），并且使用不同的命令和语法。
> 以上就是将shell命令写入文件并执行的基本步骤。

在电商业务中，MongoDB可以用来存储和查询各种类型的数据，例如用户信息、商品信息、订单信息等。以下是一些与电商业务相关的MongoDB命令和知识点的讲解：

**1. 创建集合（Collection）**

首先，你可能需要为不同的数据类型创建集合：
```shell
db.createCollection("users")       # 创建用户集合
db.createCollection("products")    # 创建商品集合
db.createCollection("orders")      # 创建订单集合
```
**2.插入文档（Insert Documents）**

插入数据到集合中：
```shell
# 插入用户
db.users.insertOne({
  username: "user123",
  email: "user123@example.com",
  password: "hashed_password",
  createdAt: new Date()
})
# 插入商品
db.products.insertOne({
  name: "Product Name",
  category: "Category",
  price: 99.99,
  stock: 100,
  description: "Product Description"
})
# 插入订单
db.orders.insertOne({
  userId: ObjectId("507f191e810c19729de860ea"), # 假设userId是用户的ObjectId
  productId: ObjectId("507f1f77bcf86cd799439011"),
  quantity: 2,
  status: "pending",
  createdAt: new Date()
})
```
3. **创建索引（Create Indexes）**

为了提高查询性能，可以在常用查询的字段上创建索引：
```shell
# 在用户集合的username字段上创建唯一索引
db.users.createIndex({ username: 1 }, { unique: true })
# 在商品集合的name字段上创建文本索引，以便进行全文搜索
db.products.createIndex({ name: "text" })
# 在订单集合的userId和status字段上创建复合索引
db.orders.createIndex({ userId: 1, status: 1 })
```
4. **查询数据（Query Data）**

执行各种查询操作：
```shell
# 查询特定用户的所有订单
db.orders.find({ userId: ObjectId("507f191e810c19729de860ea") })
# 查询类别为"Electronics"的所有商品
db.products.find({ category: "Electronics" })
# 查询价格低于50元的所有商品
db.products.find({ price: { $lt: 50 } })
# 使用文本索引进行全文搜索
db.products.find({ $text: { $search: "Product Name" } })
```
5. **更新数据（Update Data）**

更新集合中的文档：
```shell
# 更新商品库存
db.products.updateOne(
  { _id: ObjectId("507f1f77bcf86cd799439011") },
  { $inc: { stock: -2 } } # 假设卖出了2个商品，库存减少2
)
# 更新订单状态
db.orders.updateOne(
  { _id: ObjectId("507f1f77bcf86cd799439012") },
  { $set: { status: "shipped" } }
)
```
6. **删除数据（Delete Data）**

从集合中删除文档：
```shell
# 删除特定订单
db.orders.deleteOne({ _id: ObjectId("507f1f77bcf86cd799439012") })
# 删除所有已完成的订单
db.orders.deleteMany({ status: "completed" })
```
**注意事项：**

- 使用 `ObjectId` 来引用其他集合中的文档。
- 对于敏感信息（如密码），应当存储其哈希值，而不是明文。
- 索引可以显著提高查询性能，但会占用额外的存储空间，并且会稍微减慢写操作的速度。
- 使用 `$text` 索引进行全文搜索时，确保字段已经创建了文本索引。
这些命令和知识点是MongoDB在电商业务中常用的基础操作。在实际应用中，你可能还需要处理更复杂的查询、聚合操作、事务处理等。

##### A.6聚合管道操作符

MongoDB的聚合操作是一种用于处理数据并返回计算结果的方法，类似于SQL中的GROUP BY语句。聚合操作可以对集合中的数据进行分组、转换、计算等操作，最终输出一个结果集。
在MongoDB中，聚合操作主要通过聚合管道（Aggregation Pipeline）来实现。聚合管道是一系列的数据处理阶段，每个阶段对输入的文档序列执行特定的操作，并将结果输出到下一阶段。下面是一些常用的聚合管道操作符和它们的功能：
 聚合管道操作符：
1. **$match**：
   - 用于过滤文档，只输出符合条件的文档。
   - 类似于SQL中的WHERE子句。
2. **$group**：
   - 用于将集合中的文档分组，可以对分组后的数据进行聚合。
   - 类似于SQL中的GROUP BY。
3. **$project**：
   - 用于重塑每个文档的结构，选择、添加或删除字段。
   - 可以用来创建计算字段。
4. **$sort**：
   - 用于对输入的文档进行排序。
5. **$limit**：
   - 用于限制聚合管道返回的文档数。
6. **$skip**：
   - 用于在聚合管道中跳过指定数量的文档。
7. **$unwind**：
   - 用于将数组类型的字段拆分成多个文档。
8. **$out**：
   - 将聚合管道的结果输出到一个新的集合中。
    重塑文档示例：
     假设我们有一个名为 `orders` 的集合，其中包含以下文档：
```json
{
  "_id": ObjectId("507f191e810c19729de860ea"),
  "customer": "Alice",
  "orderDate": ISODate("2023-01-01T00:00:00Z"),
  "items": [
    { "name": "T-shirt", "price": 20, "quantity": 2 },
    { "name": "Jeans", "price": 40, "quantity": 1 }
  ]
}
```
以下是一个聚合管道的示例，它将重塑文档以计算每个订单的总价：
```javascript
db.orders.aggregate([
  {
    $project: {
      customer: 1,
      orderDate: 1,
      total: { $sum: "$items.price" }
    }
  }
]);
```
在这个例子中，`$project` 阶段用于添加一个新的字段 `total`，它是通过计算数组 `items` 中每个项目的 `price` 字段的总和得到的。
 聚合管道操作步骤：

1. **$match**：首先，你可以使用 `$match` 来过滤出特定条件的文档。
2. **$group**：然后，使用 `$group` 来对文档进行分组，并计算每个分组的总和、平均值等。
3. **$project**：接下来，使用 `$project` 来重塑文档，选择需要的字段，并可以添加计算字段。
4. **$sort**：使用 `$sort` 来对结果进行排序。
5. **$limit** 和 **$skip**：最后，可以使用 `$limit` 和 `$skip` 来限制结果的数量或跳过一些文档。
聚合管道是非常强大的，可以执行复杂的操作来处理和分析数据。在实际应用中，这些阶段可以组合使用，以完成复杂的数据处理任务。

> 以下是一个基于电商场景的MongoDB聚合管道操作示例，该示例尽可能使用了各种聚合管道操作符。假设我们有一个名为`orders`的集合，该集合包含了电商平台的订单数据。
> ```javascript
> db.orders.aggregate([
>     {
>         $match: {
>             status: "completed"  // 筛选出已完成状态的订单
>         }
>     },
>     {
>         $group: {
>             _id: "$customerId",  // 按客户ID分组
>             totalAmount: { $sum: "$amount" },  // 计算每个客户的总消费金额
>             averageAmount: { $avg: "$amount" },  // 计算每个客户的平均消费金额
>             orderCount: { $sum: 1 }  // 统计每个客户的订单数量
>         }
>     },
>     {
>         $sort: {
>             totalAmount: -1  // 按总消费金额降序排序
>         }
>     },
>     {
>         $limit: 10  // 取消费金额最高的前10个客户
>     },
>     {
>         $lookup: {
>             from: "customers",  // 从customers集合中查找客户信息
>             localField: "_id",
>             foreignField: "_id",
>             as: "customerInfo"
>         }
>     },
>     {
>         $unwind: "$customerInfo"  // 展开customerInfo数组
>     },
>     {
>         $project: { //控制输出文档的结构
>             _id: 0,  // 不显示_id字段
>             customerId: "$_id",
>             customerName: "$customerInfo.name",
>             totalAmount: 1,
>             averageAmount: 1,
>             orderCount: 1
>         }
>     },
>     {
>         $out: "top_customers"  // 将结果输出到新的集合top_customers
>     },
>     {
>         $facet: { //在同个聚合管道阶段中同时进行多个分组操作。输出多个分组的结果
>             stats: [
>                 { $count: "total" }  // 统计总客户数
>             ],
>             categories: [
>                 {
>                     $unwind: "$customerInfo.categories"  // 展开客户类别
>                 },
>                 {
>                     $group: {
>                         _id: "$customerInfo.categories",
>                         count: { $sum: 1 }  // 统计每个类别的客户数量
>                     }
>                 }
>             ]
>         }
>     },
>     {
>         $bucket: {//将输入文档根据指定的表达式和边界划分为桶 对每个桶内文档引用聚合 
>             groupBy: "$averageAmount",  // 按平均消费金额分组
>             boundaries: [0, 100, 200, 300, 400, 500, 600],  // 分组边界
>             default: "Other",  // 默认分组
>             output: {
>                 count: { $sum: 1 },
>                 averageAmount: { $avg: "$averageAmount" }
>             }
>         }
>     }
> ]);
> ```
> 这个聚合管道操作包含了以下步骤：
> 1. `$match`：筛选出已完成状态的订单。
> 2. `$group`：按客户ID分组，并计算总消费金额、平均消费金额和订单数量。
> 3. `$sort`：按总消费金额降序排序。
> 4. `$limit`：取消费金额最高的前10个客户。
> 5. `$lookup`：从customers集合中查找客户信息。
> 6. `$unwind`：展开customerInfo数组。
> 7. `$project`：选择要显示的字段。
> 8. `$out`：将结果输出到新的集合。
> 9. `$facet`：对数据进行分组统计，包括总客户数和每个类别的客户数量。
> 10. `$bucket`：按平均消费金额分组，并计算每个分组的客户数量和平均消费金额。

### 9.6

1.英语复习89新20

2.算法：DP-找出乘积最大的子数组的积

JUC（Java并发工具）:

- 操作系统管理进程，而进程可以包含多个线程（轻量级进程）。
- 传统GUI程序使用主事件循环，其缺点是如果有耗时操作会阻塞整个界面。解决方法是使用事件分发线程（Event Dispatch Thread, EDT）。
- 进程之间内存空间是独立的，而同一进程中的多个线程共享内存空间。
- 线程安全：当多个线程访问某个类时，该类始终能表现出正确的行为。
- 有状态：如果在堆区开辟了共享实例，例如 `private long count = 0;`，则该变量为全局变量。
- 有状态可能导致线程不安全：策略A是使用 `AtomicLong`，策略B是对涉及 `count` 的方法使用 `synchronized`。
- 竞态条件：程序的执行结果依赖于线程的执行时序或者事件的顺序，可能导致不一致的结果。
- 延迟初始化：如 `Instance s = null;`，在方法中延迟创建实例。若 `s` 没有被 `volatile` 修饰，可能会在线程间导致不一致的结果。
- 内置锁：通过 `synchronized` 关键字实现。
- 可重入：一个同步方法可以调用另一个同步方法，即使是嵌套调用，而不会发生死锁。
- `synchronized` 的特性：实现操作的原子性和保证内存可见性（所有读写操作都必须在同一个锁上同步）。
- 重排序：在没有同步化的情况下，编译器、处理器、运行时都可能会调整操作的执行顺序。
- 非原子64位操作：早期处理器无法原子地处理64位操作，如 `long` 和 `double`。解决方法是使用 `volatile` 关键字确保操作的原子性。
- 发布与逃逸：如果一个对象在方法外被访问，则称其逃逸出该方法。
- 匿名内部类发布：可能会导致外部类被逃逸，因此使用工厂模式来创建对象。
- 线程封闭：通过避免不同线程间的数据共享来避免同步问题。例如，Swing的线程分发机制。
- `ThreadLocal`：为每个线程提供一个单独的实例，例如数据库连接 `ThreadLocal<Connection>`。
- `final` 修饰的变量：`final` 变量本身是线程安全的，但其所引用的对象的状态不一定线程安全。

ElasticSearch:

- ElasticSearch 是基于 Lucene 的分布式文档型搜索引擎。

- 在早期版本中，ElasticSearch 的逻辑结构是索引包含类型，类型包含文档。但从 7.0 版本开始，类型已被废弃，索引直接包含文档。

- TF-IDF 算法：词频-逆文档频率，用于评估一个词在文档中的重要性。

- 逻辑设计：文档被类型分组，类型类似于 SQL 中的表格，包含行（文档）。一个或多个类型存在于索引中，类似于多个表格存在于数据库中。

- 物理设计：索引由多个分片组成，主分片和副本分片可以分布在不同的节点上。默认情况下，每个索引有5个主分片，每个主分片有一个副本分片。

- 文档用 JSON 表示，ElasticSearch 处理的最小单元是分片。

- ElasticSearch 索引物理上被分割成多个分片，每个分片是一个独立的 Lucene 索引。

- 倒排索引：通过词条快速找到包含它们的文档。

- 随着机器节点的增加，ElasticSearch 集群可以水平扩展，实现负载均衡。

- 文档在索引中根据其 ID 进行散列分配到特定的分片上，不是随机分布，确保了分片的均匀使用。

- 索引例子：以下是一个正确的 curl 命令，用于在 ElasticSearch 中创建一个文档

- **数据类型**：ElasticSearch 支持多种数据类型，包括字符串、数字、日期、布尔值、地理空间数据等。正确地定义字段类型对于搜索和分析至关重要。

- **分析器**：在索引和搜索过程中，分析器用于处理文本字段。它包括字符过滤器、分词器和令牌过滤器，用于将文本转换为词条。

- **缓存**：ElasticSearch 使用多种缓存来提高性能，包括字段数据缓存、查询缓存和请求缓存。

- **监控与日志**：ElasticSearch 提供了内置的监控工具，可以监控集群的健康状况、性能指标和日志信息。

- **安全**：ElasticSearch 提供了安全功能，包括用户认证、角色权限控制、加密通信等。

- **插件**：ElasticSearch 允许通过插件来扩展其功能，例如，Kibana 插件用于数据可视化，X-Pack 插件提供安全、监控、告警等功能。

- **集群伸缩**：ElasticSearch 集群可以通过增加节点来伸缩，以处理更多的数据和更高的查询负载。

- **故障转移**：当主分片所在的节点发生故障时，副本分片可以提升为主分片，确保集群的持续可用性。

- **索引模板**：索引模板可以用于自动为新创建的索引设置映射和设置，简化索引管理。

- **快照和恢复**：ElasticSearch 支持创建索引的快照，并可以将快照恢复到新索引中，用于备份和灾难恢复。

  - ```sh
    curl -X PUT "http://localhost:9200/get-together/group/1?pretty" -H 'Content-Type: application/json' -d'
    {
      "name": "ElasticSearch Denver",
      "organizer": "Lee"
    }'
    ```

    



# 10.2日报

1.力扣：合并两个有序链表-以前学的是L1指针 L2指针 cur指针，选小的给cur用。这次自己想了一个纯暴力法，时间复杂度高，不过自己能独立想出思路也算不错

2.六级单词新20复115

3.计网相关：

A.RPC本用做C/S架构通讯,HTTP比RPC晚,RPC比较定制化,但后续Web浏览器流行,需要有统一的规则,于是HTTP替代了RPC,RPC退出了外网通讯舞台,但是由于比HTTP的头信息更少,信息冗余少,因此用于微服务组件通讯.http2.0也是RPC的底层之一,一般是基于TCP

B.WebSocket是在http建立成功后，在消息头用connection:upgrade 并且配置upgrade为websocket的实现的,注意要带一个base64编码的密钥,这个用于C/S校验.WebSocket全双工.替代了原本的长轮训or不断轮循(百度网盘验证码登录的原理就是这个,不断发http请求对客户端负载大)

4.OS相关:

1.图灵机：纸带+读写头+(储存/控制/运算)

2.32和64位得分CPU和总线来看,64位AMD和因特尔基本都是48位寻址,64位没必要.软件64位不能在32位机器上面跑,因为指令集不兼容,但是32位软件加兼容代码可以在64位机器跑.CPU的32和64看的是地址总线,传输总线,数据总线的宽度。

3.寄存器：通用寄存器,指令寄存器(不存地址存当前命令),程序计数器(存下一个地址)->Cache,注意这是SRAM,L1分数据和指令,L2不分,L1L2内核私有,L3共享.后面就是内存和硬盘

4.想让代码跑的快,二维数组得连续,因为cache读的是cacheline,一般64kb,这是从数据上做优化,从指令上优化就是尽可能排序,让分支预测器优化,给数排序后再读入Cache里面.切记：就是让代码容易被缓存命中，命中了就跑得快了。

5.缓存一致性：写直达问题不大,直接写memory,坏处就是慢.写回倒是快了,就是脏数据容易导致两个核的缓存不一致。怎么办？总线嗅探，实时让核心去问旁边的核是不是一致的，不一致就改。坏处是太消耗性能了。基于这个想法

6.MESI协议,M修改,E独享,S共享,I无效.先独享,有人读了就共享,我改了另外一个就无效,无效了就继续重新读

7.因为cacheLine读的是64kb（默认64kb,）,万一AB都在一个cacheline里面，特别是在结构体经常发生,那AB就容易出现伪共享：说白了就是缓存了跟没缓存没什么区别，属于是看似移动到缓存，但是最后又得重新读。所以你得做内存对齐，别让cacheline一次性给你把两个core里面放的数据都读进去了,策略是在cpp代码里面写宏定义就行

8.调度优先级,deadline,realtime,fair.越急值越小 fair就是公平了

9.**在 CFS 算法调度的时候，会优先选择 vruntime 少的任务**，类似一堆杯子里面奶茶少的杯子就加点奶茶，加奶茶就是调用你，调用你vruntime就增加。我就一定先用vruntime少的任务。

10.SCHED_DEADLINE：是按照 deadline 进行调度的，距离当前时间点最近的 deadline 的任务会被优先调度； SCHED_FIFO：对于相同优先级的任务，按先来先服务的原则，但是优先级更高的任务，可以抢占低优先级的任务，也就是优先级高的可以「插队」； 

SCHED_RR：对于相同优先级的任务，轮流着运行，每个任务都有一定的时间片，当用完时间片的任务会被放到队列尾部，以保证相同优先级任务的公平性，但是高优先级的任务依然可以抢占低优先级的任务；

 而 Fair 调度类是应用于普通任务，都是由 CFS 调度器管理的，分为两种调度策略： 

SCHED_NORMAL：普通任务使用的调度策略；

 SCHED_BATCH：后台任务的调度策略，不和终端进行交互，因此在不影响其他需要交互的任务，可以适当降低它的优先级

# 10.3日报

1.LC:复习了BFS,用bfs做了计算二叉树深度,很久没写dfs了,果然手生了

2.六级单词新20复习100

3.工程知识：

A.就[多类型场频搭建统一发奖服务]的场景,重构if-else的冗余代码为工厂模式,即先设计统一的发奖接口,再针对优惠卷,月卡等不同具体商品的发奖设计发奖Service的实现类,然后编写工厂类,工厂类提供多个方法来new具体的发奖服务,接着拿到new出来的发奖服务再去调用service里面的方法。然后写了单元测试

B.就[替换Redis双集群升级]-原本服务A和服务B的调用redis工具类不同,现在需要整合到一个集群中统一调用。策略是设计服务A的Adapter类,服务B的Adapter类.这两个类都实现了adapter接口.adapter接口的包含了get和set方法.而服务的Adapter类就是Override上述方法,然后通过new一个A服务,在get方法中调用A服务的getX()方法。接着就是拿JDK动态代理去新建代理对象，测试类通过jdkproxy拿到代理对象，接着就对对象进行操作。这体现了抽象工厂模式。

4.操作系统:

A.宏内核，包含多个模块，整个内核像一个完整的程序；+微内核，有一个最小版本的内核，一些模块和服务则由用户态管理；+混合内核，是宏内核和微内核的结合体，内核中抽象出了微内核的概念，也就是内核中会有一个小型的内核，其他模块就在这个基础上搭建，整个内核是个完整的程序；Linux 的内核设计是采用了宏内核，Window 的内核设计则是采用了混合内核。

B.SMP对称多处理，代表着每个 CPU 的地位是相等的，对资源的使用权限也是相同的，多个 CPU 共享同一个内存，每个 CPU 都可以访问完整的内存和硬件资源。

C.ELF它是 Linux 操作系统中可执行文件的存储格式

D.0.1+0.2!=0.3原因是。计算机处理小数的策略是乘2取整法，但是0.1是无限循环的,所以只能截取部分精度。

E.为什么负数要用补码？-3+1直接算就是-4,用了补码避免将负数转化为减法才能得到-2,说白了就是得统一计算方式，减少资源浪费。

F.虚拟内存是一种内存管理技术，使程序可以使用比物理内存更大的地址空间。页表是操作系统用来映射虚拟地址到物理地址的数据结构，它记录了每个虚拟页对应的物理页框。多级页表是一种优化的页表结构，通过分层管理减少内存占用，提高访问效率，适用于大规模虚拟地址空间。段页是一种内存管理方式，结合了段式管理和分页管理的优点。它将程序分为多个段，每个段可以进一步划分为固定大小的页，从而实现灵活的内存分配和保护。通过这种方式，可以提高内存的利用率，同时简化地址转换过程。

G.操作系统的进程形式，状态，通信方式，调度算法。操作系统的中断，系统调用....and so on...

# 10.5日报

1.LC继续做了一道easy的BFS,二叉树翻转

2.六级新20复习109个

3.Mybatis源码-看到XML解析部分+一点点执行器

4.设计模式-原型模式：顺序不同的卷子 单例模式-懒汉(安全+不安全)饿汉+内部类+双重锁+枚举(枚举是最推荐的)+建造者模式(房屋装修选配场景)

5.看了点http,复习了状态码,补充了强制缓存和协商缓存的知识..

今天看不太进去东西,吃完晚饭倒头就睡,睡了两三个小时脑子昏昏沉沉.

下午也是时间多用作娱乐了

感觉呆寝室里学习久了很无趣，也没什么动力出去玩。学校太偏僻了，感觉但凡去个略微繁华的地方都得浪费很多时间通勤，算了，还是呆寝室吧，太懒了。

# 10.9日报

1.六级新学20复习108

2.LC完成BST树插入节点：依旧是递归,我错误的原因在于想的过于复杂,只用考虑 A.判断root.val与val的关系从而令root.left or right被递归结果赋值 B.最后的叶子结点处插入,不应该单独用if判断,而是直接放在root为Null的If中.我的思维惯性是root为null就返回null,而插入节点恰好就得在没有子节点之处插入.还是思维太僵化了,很不灵活,很悲哀.

3.看了一部分计组

4.比较详细的看了MySQL的锁部分：

A.全局锁(flush tables with read Lock) 表锁(表锁-元数据-意向锁-auto-inc锁) 行级锁(GapLock RecordLock 以及缝合上述二者的Next-KeyLock)

B.加锁的对象是索引

C.S锁共享 X锁独占...

D.一些具体的代码实操,lock in share mode与for update对应S与X

E.MySQL加行级锁的详细分析,唯一索引等值与范围查询,非唯一索引的等值与范围查询,没有加锁的查询.这一块比较特别的是,所谓的非唯一索引就是二级索引了,二级索引加锁得同时加二级索引和对应的主键索引.这一块说实话没太学明白,明日有空继续研读,还有一块就是gapLock的偏移量一般是5,经验主义得到的.当然,如果gap不在最左或者最右,那就给区间加上锁,反之如上.

F.生产事故-update在生产机切记得用索引,否则慢SQL

5.复习适配器模式-学习场景-多个Mq消息体去提取指定字段值-这一块复杂的逻辑在于,假若我有3个pojo类,我希望将A类的a字段与B类的c字段建立关联,会使用link,涉及一些反射操作. 适配器模式的本质就是提供一个更广泛的接口,让一个接口能兼容多种差异

6.复习桥接模式-多渠道支付与多支付模式-最笨的写法就是传两个参数进来,一个channel一个mode,然后channel里面套mode的if,例如在微信的if里面写若干个mode来表示多支付模式.这么干的坏处就是,支付宝也得写3个mode,明天我加个云闪付是不是也得写3个,那支付平台这么多,这么写不得累死么,而且后人维护起来挺麻烦.桥接模式就是做抽离工作,你的mode和channel得分开,既然那么多渠道共享相同的若干mode,我为何不单独写好mode,然后你们新增平台后,我调用mode即可.这样就实现了解耦合.



# 10.10日报

1.六级复习109新增20

2.LC: 给一串字符串,问最长构造的回文串是多少.策略是hashset,contains存在就意味着有两个相同，则长度+2.最后把偶数个的字符都测完后,set中剩下的全都是字符串中只有一次出现的字符,那我随机取一个放在回文中间即可，就是+1. 上述操作的三目运算放在最后return时候就行了

3.MySQL

A.补了一个一直没意识到的知识漏洞,聚合函数如果和字段一起用,得将一起用的字段group by.

B.一些MySQL中细节的储存结构-表-分段-块-页-行,以及建表操作导致的底层储存原理,譬如not null可以节省一个byte空间.

4.熟悉了一些Python语法,刷了点题

5.今天是真的摆完了,明天得振作些了,天天满课是真疲惫啊

# 10.11日报

1.六级复习102新增20

2.算法：完成-最大数-思路：int数组转为String数组,自定义排序规则,通过compareTo比较AB和BA两种拼接方式的值,使得两两相近的局部拼接结果和最大,使用while解决前导零问题,最后substring裁剪除去前导零索引后的正式值

3.MySQL学习：

A.黑马书P1-P101,梳理了知识体系,将数据库理论与MySQL实操进行结合,对先前项目中的零散知识做了归纳.

4.Python学习：

A.对PyGame库进行了API的认知,完成了简单的框内移动精灵的游戏demo

5.Java学习：

A.设计模式1：学习组合模式-营销差异化场景-决策树引擎搭建场景的代码训练，通过对传统if-else代码的重构，实现松耦合。

B.设计模式2：学习装饰器模式-SSO单点登录的功能拓展场景，增加了拦截用户访问方法的范围场景，重构强耦合代码

# 10.12日报

1.六级复习104，新增20

2.算法：计算投递简历，AB两个HR检测到相同简历顺序的期望。实际是将整个int数组进行去重，然后返回去重后的长度。证明部分是围绕：为什么去重后的数组长度等于期望

3.MySQL：

A.黑马MySQL教程P102-P201,一天的时间都用来阅读和复现代码了,收获很大,知识相对之前的零散状态更加体系化了,不得不说,黑马出的书籍是很浅显易懂的.我读国外经典的中译本的效率,是远远不如阅读这种商业化培训机构在市场中卷出来的资料的效率的.

# 10.13日报

1.六级复习84，新增20

2.算法：滑动窗口easy-给定一个二进制字符串,以及一个数字k,要求找出字符串,满足条件为,0出现次数<=k ||1出现次数<=k.思路是把字符串转char数组,用cnt数组,0索引表示0的数量,1索引表示1的数量,遍历char数组,拿cnt[char[i]&1]++.然后遇到cnt[char[0]]>k&&cnt[char[1]]>k就移动左边界left,然后让cnt减法(左边界移动了自然滑动窗口里面的0或者1就减少了)具体实现:cnt[char[left++]]--;单次for拿到的子数组数量+=到ans中,具体表达是 i-left+1.最后return ans就行了

3.MySQL

A.黑马书P201-P306,这本书基本读完了,启发比较大的是:数据库编程/控制流程/相关一些MySQL支持的API/函数/存储过程/游标/事件/水平和垂直分表/分区技术/Innodb三个特点：事务/外键/行级锁。总的来说，这本书写的非常接近实践。同时唤醒了我半年多前的关于MySQL的具体实操的记忆。太久没写过sql了，许多知识点的遗忘是客观的，这些缺漏被这本书提供的知识补齐了。

4.复习了MongoDB相关八股,翻看自己的技术存档,发觉上一次复习MongoDB还是9月4日,如今已经一个多月过去了,时光的流逝真是令人慨叹啊。

5.展望与规划：

1.十一月之前把Spring Microservices in action读完,体系化一下微服务的知识。

2.读Redis in action

3.多复盘场景题

# 10.14日报

1.六级新增20个，复习108

2.LC：给定一个数组，与k值。若k>0，每个元素替换为其后k个元素相加的和，若k<0， 每个元素替换为前k个元素相加的和，若k=0,初始化为0。且数组为环形，需要考虑到边界问题，策略是对于k<0情况，索引设计为(i-j+n)%n，对于k>0情况索引设计为(i+j)%n，使用%n来确保索引始终在n的范围内

3.Redis

A.归纳整理了Redis的三种缓存模型，输出了博客，录制了视频。这一块记忆会比较深刻

4.JavaSE

A.把学校发的SE书简单过了1/3，补齐了一些平时用的较少的API，对于细微处的遗忘拾起记忆。

5.整体这一天过得比较松弛，可能是因为一上午没有课的缘故。

# 10.16日报

1.六级新增20个，复习102个

2.LC做了一道中等难度，给定数组与标准k,要求连续子数组相乘乘积小于k,策略是维护一个滑动窗口,左边界初始化为0，右边界也初始化为0，我们for循环先动右边界，左边界的移动是被迫的。伴随右边界移动，滑动窗口框起来的数字越来越多，就有可能相乘结果大于等于k，一旦遇到这种情况，左边界就得开始动了，我们这里的动分两步，一方面是总乘积里面得除去一个左边界上的元素，另外一方面是左边界的索引需要自增一位，且这个行为得是while，不能是if,为什么？如果你运气够好，左边界移动一位你的总乘积就回到比k小状态了，那是最好的。但是倘若运气不够好呢？倘若这个数组设计的右边界的新值很大呢?因此我就得在该for循环里面不断while，直到乘积<k。然后每次for走完一遍，都将right-left+1加到ans里面。这是一个通用知识，在很多问：子数组个数+滑动窗口的题目里面都是这样处理的。本质是计算右边界为right，左边界为left，二者围成的滑动窗口的子数组组合可能性。

3.JSP/Servlet阅读-林信良书P1-P73，从下午读到晚上，虽然已经是十五年前的书了，但是对于jsp这种古老技术的描述的确很细致，从整个项目结构的文件功用，到宏观的架构设计，循序渐进。我认为最可取的一点是，介绍是渐进式的，没有一上来就灌输一大堆定义，让大脑摄取的知识存在逻辑上的推导连贯性。就目前来看，这本书写的不错。

4.黑马的NoSQL阅读，上午看了一节课，大致把MongoDB的开端复习了一下，然后收获比较大的是BASE理论，最终一致性,CAP之类的纯理论知识，先前在背面经时候遇到，但是没有做系统性整理，这里给出了表格和划分。有时间可以多读读，最近要读的书太多了，有点应接不暇了。

5.Vue.js实战，回寝室后做了7个简单lab,大致是重温了组件传值,然后进阶语法里面把四个常用全局属性的demo敲了，不得不说,Vue2的有些东西被Vue3舍弃不是没有理由的。

6.总结：

我的整个大一对技术的学习是急于求成的，成果很显然，养成了干活的能力。但是缺陷在于：我对技术的发展沿革没有细致的了解，就像我知晓怎么用SpringBoot做crud,但是我对ssm做crud是相对生疏的，对用Servlet+jsp做网站是更加生疏的。我先前的所作所为仅仅是满足了目前市场最广泛应用的技术需求，但是这显得太浮于表面了。

我愈发觉得，技术发展的沿革就是在复杂的技术上面修建新的建筑，让这个复杂的技术更加易用，但利弊均衡，易用性的代价是牺牲了灵活性，丧失了对更底层设计的细致控制。

沉下心来老老实实把那些不再直接被使用，但是依旧在新兴框架之中发挥着作用的陈旧技术学好，理应是我大二上学期的主旋律。

# 10.17日报

1.力扣一道easy。题意是给定一个数n，判断n是否完全由给定的数乘得，譬如给定2,3,6.那我输入6就满足，输入17就不满足。我们转化思路：让n依次除2,3,6就行了。但是考虑到一次可能不到位，那我对于2,3,6都得分别做一个while,条件是n%2==0，对于3和6同理。然后想起来得考虑特殊情况，如果n比1要小，直接return一个false就行。然后如果一个数n能挺过三个while，最终等于1，就说明这个数完全就是可以用2或3或6任意取数做乘法组成的。

2.六级新增20个，复习106个。

3.JSP书从P74读到P203，大致把Servlet相关的Listener,Filter看完了，看了一部分jsp的语法。感触是：古老的东西用起来确实挺不方便的，但是能想出来这样设计的人，挺牛的。

4.Vue做Lab，全局属性，实例属性，全局配置一共13个lab做掉了，组件进阶没太看懂，createElement目前没在业务场景里面遇到过，先不管了，以后遇见再说。然后走马观花的看了transition的用法，感觉用处不大，因为这种渐变效果大概率是用其他组件库来做，我觉得Vue的定位更像是一个工程框架，至于渐变这种视觉层的东西，用第三方封装的库肯定比自己写要好，还是以工程建模为主线。然后敲了五个关于路由的lab,这路由以前也用过，但是感觉认知还是太浅了，也发觉忘掉了许多东西，明日有闲暇再多看看吧。

5.总结：

效率还行，整体来说学习的痛感不强烈。jsp书读了大半天还是有些枯燥，明天读NoSQL+JSP换换口味。这理论知识啊，就得交叉轮换复习，不然早晚都忘掉。

# 10.19日报

1.力扣一道easy,题意是：在一个无环无向图中，给定二维数组edges，找出哪一个节点是中心节点（该图中心节点仅有一颗，与其他节点相连）。实际考察的是度的概念。倘若有n个节点，则希望我找到度为n-1的节点。策略是将整个edges遍历。edges的0索引和1索引的元素分别添加到map中，节点名是key,出现的次数是value。接着就是遍历整个keyset()。寻找map.get(key)==n-1，倘若找到了，直接返回key。倘若没找到，返回-1

2.六级复习102，新增20个

3.早上把黑马的那本Vue.js看完了，对Vue2的工程化加深了印象，捡起了遗忘的许多知识，也补充了第一回学时遗漏的细节。有时间了得把Vue3从头看看，我记着几个月前仿佛还是看了Vue3的，但是也只是对ref和reactive这种印象比较深刻了，肯定有很多细节掌握的不清楚的。

4.下午和晚上在看黑马的SpringCloud书。不得不说，我先前对微服务的理解还是太浅薄了，对于SpringCloud中的若干组件并没有一个体系化的认知，对于其细分功能没有深层次的研究。所幸问题暴露的较早，还有时间挽回。

5.手搓了一个简单的微服务Demo，传了仓库，针对开发过程中的问题做了归纳。SpringCloud的版本和SpringBoot版本对不上的情况，大概率会导致服务启动失败。

6.重构了HNUSTBook这个仓库的文件结构，先前设计的还是太乱了。现在重新按照前端，后端，Web3，爬虫进行了归纳整理。知识体系还是要保持清晰明朗的状态，这样复习起来才有头绪。

7.今明两天的任务是继续归纳SpringCloud组件的原理细节，继续写文档和做lab。

# 10.20日报

1.力扣一道easy:给定图（节点数量,边的集合,src,dest）请求判断，是否有一条边正好连接src和dest。策略：1.针对每一个节点建立邻接表,将与其相邻的所有节点添加到表中,该表以List形式表达 2.定义visited数组,针对每一个节点,默认其没有被访问 3.深度优先搜索所有的邻接表,每一次新的DFS都令src为邻接表的下一个元素,递归出口为：src与dest重合。

2.六级新增20个，复习88个。

3.SpringCloud NetFlix相关组件的使用策略复习

4.分析了一个基于SpringCloud架构的博客项目代码，拆解了功能，总结了文档。

5.看了部分Dubbo知识,了解其大致生态位与基本用法

6.复习Nacos与Sentinel，复习了SpringCloudAlibaba与SpringCloudNetFlix的差异。

7.复习了SpringMVC的基本机制，学习了SpringMVC的部分源码

8.明日读计文柯的Spring技术内幕，把SpringMVC的源码阅读部分，第一遍先建立认知。再复习一下SpringIOC和SpringAOP看过的源码，这两个知识点时间线太久了，整个的继承与实现的复杂关系遗忘了很多，需要再巩固一下。

# 10.21日报

1.力扣一道Easy。给定有向图(节点个数n,有向边二维数组,从0走到n-1总共需要走的轮数k)，判断从0号节点能走到n-1号节点的走法种类。从图出发会想到DFS，从种类出发会想到用dp。本次用dp,考量状态转移方程：由于给定了二维数组的每一个一维数组，且一维数组的0索引元素是起点，1索引元素是终点。于是发现每一条有向边都代表了一次转移。我们需要初始化`dp[0][0]=1`原因很简单，走了0轮且还在0号元素,说明就是从0号走到0号，只有一种走法，于是组合数为1，后面所有的dp都是从这个1出发的`dp[i+1][dest]=dp[i+1][dest]+dp[i][src]`这里的第一个维度是当前已经走的轮数,第二个维度是当前走到的节点.我们将这个状态转移方程应用0~k的循环,最后return`dp[k][n-1]`可以得到结果

2.六级新增20个，复习88个。

3.SpringMVC的源码阅读，先前只是捋清楚了DispatcherServlet&&HandlerMapping&&HandlerExecutionChains&&Adapters的流程，没有下沉到web容器的IOC容器的启动上。今天补充了web.xml方式启动(Servlet2.0)与代码启动(Servlet3.0)两种初始化策略,补充了初始化流程，复习了Servlet,Filter,Listener。但是还是没有看懂SpringMVC的源码，这玩意的继承结构太复杂了。暂且先如此吧，姑且放置段时间，等代码量高些了再尝试读读。

4.NoSQL方面看了Neo4J的概念，以及Java客户端操作其工作的方式。这种图形数据库感觉很适合用来储存网站的用户好友关联，准备自己项目的时候可以考虑加进去。然后看了点MongoDB的主从集群，我发现和微服务沾点边的中间件都支持集群模式。Redis,MongoDB,ElasticSearch比比皆是。

5.很客观的说，今天没有很大的进步。只能说是在既有知识储备的基础上，对其原理性做了一点点深入，没有拓宽技术视野，而且整体学习的比较表面，这是读不懂Spring源码导致的。计网好久没看了，许多记忆模糊了很多，明日复习计网吧。

# 10.22日报

1.力扣一道easy：实现Fn=Fn-1+Fn-2+Fn-3。惯性思维是直接DP，今天学习记忆化数组，把每一次算出来的Fn存在数组里面，DFS先判断当前Fn是否已经存在数组里了，如果有就不重新计算，好处是减少冗余计算。另一个策略是滚动数组，三个变量分别代表Fn-1,Fn-2,Fn-3，不断更新这三个量，适合递推的场景

2.六级新增20个，复习80个

3.计网看了Http1.1的优化方向，大致三个：A.尽量不发http请求(尽量缓存) B.如果要发请求,则三个策略(1.合并多个请求到一条http中，2.延迟发包，3.减少重定向(重定向产生更多的http请求)) C.response做压缩,引出gzip无损压缩,以及有损压缩形成的webp.

4.Spring源码读了SpringCore的资源加载和元数据过滤的部分，首先是学习Resource,将url,file,classpath等指向的文件用resource统一起来。其次是ResourceLoader,将上述统一起来的Resource加载到Java程序中，再者是ResourcePatternResovler,考虑到ResourceLoader可能会遇到通配符,例如"http:\\example.com\java\**"这种**通配情况，所以得用这种模解析器。最后就是DocumentLoader，用来支持XML的文档加载。完成Bean定义的加载。之后就是元数据问题，这一块目前只看了MetadataReader，生成的MetaData是一个 "字段=布尔值"的结构，针对的是具体的JavaBean,涉及的内容包括是不是abstract的,是不是接口,是不是final,是不是static的，注意：上述描述的都是类的特性，如果要考虑方法，则只考虑被注解修饰的方式，只要是被注解修饰了的方法都会被添加到metadata中,其本质是ASM框架,性能比反射更高。联想到AOP的实现原理中，有CgLib和JDK动态代理，为什么CgLib性能好？就是因为其基于ASM直接操纵字节码，而JDK动态代理需要反射，需要通过虚拟机。接着就是看了AnnotationMetadata，它是基于有MetadataReader读出来，再对其中的“注解
“做特定的判断，比如是否是@Service这种特异性判断,以及去取注解的属性。

# 10.23日报

1.力扣一道中等：给定形如[1,5,2,3,4,5,100,200]数组,要求找出最长连续子序列.因子序列不考虑顺序,因此我先Arrays.sort.拿到[1,2,3,4,5,5,100,200].接着准备贪心,先用max表示全局最优,用tmp_max表示局部最优.依次遍历新数组,考虑三种情况：A.nums[i-1]和nums[i]相等,相等则continue B.nums[1]-nums[i-1]=1.这正是我想要的连续,所以tmp_max++,C.nums[i]-nums[i-1]>1.这就是典型的不连续,例如5和100的相邻关系.接着每次for.max = Math.max(max,tmp_max)贪心即可,最后return max.

2.六级新增20,复习122.

3.JUC复习：

A.Thread三种创建：继承thread,实现callable,实现runnable.

B.Thread有target,类型为runnable.构造传参实现runnable类是可行的,以及复习join,yield,start,run这些....

C.就绪和运行的state都是runnable.区别在于前者没有轮到时间片.

D.@FunctionInterface修饰的接口,只可以有一个抽象方法.

E.量太多无法一一列举,诸如此类吧.

4.Spring源码阅读：

4A. `TypeFilter` 类与先前学习的 `Resource` 类可以有机结合。假设我希望读取一个存在通配符的文件夹，识别其中是否有 `@Controller`、`@Service` 等 Spring 注解。可以创建 `PathMatchingResourcePatternResolver`，由于要判断注解，注解部分修饰的方法，因此需要获取元数据。首先构造 `metadataReaderFactory`，获取 `metadataReader`，读取到元数据，将文件夹的元数据全部读入 `Resource[]` 中。这时 `TypeFilter` 发力了，我们可以用 `TypeFilter annotationTypeFilter = new AnnotationTypeFilter(MyAnnotation.class)`，这样只会读取有 `@MyAnnotation` 修饰的类。例如 `@Service` 之类的，会因为没有被 `TypeFilter` 指定。这其实是在为 Spring 的 `@ComponentScan` 做铺垫，`@ComponentScan` 无非是将读取的类扩大到 `@Component`、`@Controller`、`@Service`、`@Repository` 等。如果没有实现读取类的功能，又如何将类加载到 IoC 容器中形成 Java Bean 呢？万丈高楼平地起。不过，`TypeFilter` 接口除了对注解进行特异化读取外，还可以使用 `AssignableTypeFilter` 考量指定类型的相关类，并支持 AspectJ 表达式和正则表达式。

4B. 我们实际上并不希望每一个 Bean 都被强制性加载，因此提供了 `Condition` 接口——Spring 中的 `@Conditional` 来决定该 Bean 是否被加载。现在考量其构造：我们可以使用类似 `TypeFilter` 的 `match` 方法，参数一：`ConditionContext`，参数二：`AnnotatedTypeMetadata`。我们发现，元数据确实很重要，出现频率很高！在 `match` 的具体实现中，我们可以使用 `getClass().getClassLoader().loadClass(className);` 进行判断。如果加载成功，则返回 `true`；若失败，则抛出一个错误。好了，现在我们可以结合 `Resource`、`Resolver` 和 `Reader` 来对类进行识别了。对于 `com.test.spring.ConditionDemo` 是可以识别的，但 `com.test.spring.ConditionDemo1` 就因为 `className` 不匹配而识别失效了。

4C.SpringValidator的逻辑：在 POJO 类中，我们常常使用 `@NotNull`、`@Size`、`@Min`、`@Max` 等注解来约束数据的有效性。然而，深入探究这种校验机制的实现，会发现它主要由两个部分构成：`supports` 和 `validate`。`supports` 方法用于判断给定的类是否可以被当前的 `Validator` 验证，而 `validate` 方法则包含具体的校验逻辑。需要注意的是，`Validator` 与 Spring 的关联并不非常紧密。实际上，`Validator` 在应用中最常见的使用场景是控制器层（Controller）中，用于处理和校验前端传入的数据。通过这种方式，开发者能够将复杂的校验逻辑封装起来，只需在 POJO 属性上添加简单的注解，便可以触发相关的校验逻辑。此外，Spring Validator 的实现也可以与其他校验框架（如 Hibernate Validator）结合使用，后者是 Spring 默认的实现。Spring 的 `@Valid` 注解常用于方法参数中，以触发验证过程，确保输入数据的有效性。

# 10.24日报

1.LC一道medium，给定形如[1,4,6,7,3,2,4,6,8],找出现次数大于Math.floor(nums.length/3)的数构成的List,策略是A.设计map,key存数,value存数出现的次数 2.设计list 3.遍历map.Entry,判断题设条件,符合要求则放入list 4.返回List.似乎还能用摩尔投票法做,但是下回再看这个方法吧,也算是没看题解就ac了,有题目太套路的嫌疑...

2.六级新增20,复习100

3.读SpringBoot in action.有一说一,翻译的真不错.SpringSecruity部分在微服务中感觉用处不大了,已经用sso单点登录替代了。但是配置类得实现SecruityConfigAdapter接口这个思路值得记忆,适配器模式在这的用处面试可以举例.

4.把SpringDataJPA,MybatisPlus又复习了一次,这两套ORM框架的注解差异还挺大,得注意分辨

5.看了点js,filter符合条件才能走,map相当于把每一个数组元素用函数体内函数映射构成新数组,reduce比较复杂,四个参量,累加器,当前元素,当前元素索引,初始数组.

6.数据库课设打算认真用学过的技术做,暂定前段Vue2+Element,后端上SpringCloud吧，今天先做一点点，把前端整体UI和表格整了，写了九个vue组件，真得累似了吧

7.看了点Converter.较为有用之处是：SpringMVC中，将http请求参数转化为控制器方法参数的DataBinding.SpringData中数据库实体和应用程序的Domain模型的转换。做Bean认证中验证逻辑前后的转换。写微服务时，假设不用Feign而用RestTemplate,序列化和反序列化http响应体的转换。以及整个Spring内部的ConversionService,实现普遍的类型转换。Converter比较特别的是，高度和泛型相关。

# 10.25日报

1.LC一道medium二分，题意是在一个单调递增数组中，找出最大的（索引和指向值相同）的索引。策略是判断nums[n-mid]>=mid则left=mid+1.否则right = mid-1.

2.六级新增20个，复习100个

3.读高并发书，复习了异步同步阻塞非阻塞等概念，重新梳理了进程和线程的结构，Java线程三种创建方式，要牢记FutureTask是集成了Runnable和Future.因此可以当target用.看了部分线程池原理，复习了线程状态，JNI，以及JVM线程的runnable等价于操作系统线程的就绪/运行(取决于是否拿到时间片).线程池submit接收可回调的runnable和不可回调的runnable，execute() 只能接受 Runnable。
可以将 Callable<T> 包装为 FutureTask，然后通过 execute() 提交。常用策略是：A.Callable<T> xxx B.FutureTask<T> futureTask = new FutureTask<>(task); C.futureTask等价Runnable做Target用

4.读Spring源码，就验证绑定和类型转换这一块而言。ConversionService里面包含三个主要组分：A.Parser:将字符串转为对象 B.Converter:对象之间的互相转化 C.Printer:将对象转化为字符串。上述三者要注意，Spring是支持Locale的，因此可以做国标转换，例如人民币换美元。接着看了点BeanDefinition,以及相关的Hold和Registry

5.看了点cpp的万能头和一些stl

6.明天重点还是读juc的书，我的理论基础太浅薄了。

# 10.26日报

1.LC一道medium二分，给定数组形如[3,2,1,4,5,2],要求找出其中重复元素，且数组中值属于[1,n-1],数组长度为n。策略：提取数据构建新的逻辑数组。l初始化为1,r初始化为n-1,不断计算mid.mid实质是一个（索引+1）.统计在[l,r]中小于等于mid的元素个数cnt.倘若cnt<=mid.则让l=mid+1,反之则r=mid-1

2.六级新增20，复习120

3.今天只看了JUC

A.线程调度/优先级/生命周期/Jstack

B.线程名/sleep/interupt和stop区别/join/yield/daemon

C.JUC线程池架构/Executors四种快捷池/submit与execute/线程池调度流程/ThreadFactory/任务阻塞队列/调度器钩子方法/线程池四种拒绝策略/线程池优雅关闭(先shutdown,再awaittermination,再shutdownnow,最后补一个awaitTermination)/Executors线程池潜在问题，分两组。A.FixThreadPool和newSingleExecutor共性于无界队列问题,cache和sceduled共性于线程数量无上限导致的OOM

D.线程池IO型2n线程,CPU密集n线程/混合型通常是微服务的http请求/cpu密集让核与线程对应是避免上下文切换导致的时间浪费

E.ThreadLocal的演进，KEY都是thread,但是value部分从value演变为了`<ThreadLocal,value>`好处在于同个线程可以有多个独享变量了/ThreadLocal两个主要场景:A.线程隔离,数据库的connection B.跨函数调用:传递请求中的UserID,Session,HttpRequest(微服务)

# 10.27日报

1.LC一道medium.给定二维数组,找出其中第k小的数字,先二维展开一维,然后排序,返回第k-1索引对应的数就行

2.六级：新增20，复习120

3.JUC：线程安全/自增运算的线程不安全分析/临界区资源和临界区代码段/synchronized的锁芯问题,class对象和实例对象的区别/静态同步方法(class对象为锁芯)/生产者-消费者模型

4.redis的cluster集群：分片slots/Moved和ASK(收缩)两种重定向/节点通过gossip算法逐渐实现数据一致性/HashSlots 16384/故障转移：从主观下线到客观下线

5.redis热点key:集群扩容/key分散到不同服务器/jvm二级缓存

6.TCP第三次握手没回复：没有收到ack,服务端会做超时重传,此过程容易发生SYN FLOOD攻击：,向服务器大量发起SYN报文。当服务器回复SYN+ACK报文后，不会收到ACK回应报文，导致服务器上**建立大量的半连接队列**,半连接队列满了，这就无法处理正常的TCP请求

7.Redis的RDB日志卡顿,RDB分三种：A.直接save(会卡) B.bgsave(fork一个子进程去save,不卡) C.savemn(m秒内n修改触发bgsave),RDB是直接存数据,AOF是追加已执行的命令,三种策略:A.Always(同步写回磁盘) B.everySec(先写到aof缓存,每秒同步磁盘一次) C.no(先写aof缓存,再操作系统决定合适写到磁盘),AOF重写：把AOF日志中的无效和重复命令去掉

8.@NotEmpty会接受空字符串,@NotBlank不接收空字符串,收前端的数据时记得用@NotBlank.当然,二者都不支持Null.

- @NotNull: 不能为null，但可以为空（如空字符串或空集合）
- @NotEmpty: 不能为null,可以为空的字符串，**但长度必须大于0**
- @NotBlank：不能为 null，不能为空字符串

# 10.28日报

1.LC一道medium。给定目标值target与一个数组。从数组中找出差值与target最小的三个数之和。朴素想法是三重for嵌套,但时间复杂度是O(N^3)，考虑先给数组排序,对有序数组进行二分,时间复杂度为 `O(N^2)+O(nLogN)`，实际为`O(N^2)`。具体策略是：遍历数组，确定基础点i,i+1为二分起点,数组最后一个元素为二分右端点。不断二分逼近。

2.六级新增20复习122

3.JUC

A.生产者-消费者模式-线程安全于不安全的实现模式

B.对象结构与内置锁：Java对象结构/Mark Word的结构信息/JOL查看对象布局/大小端：X86为小端，但HTTP等协议通讯用大端。小端是操作系统低地址存放字符串的高地址/无锁,偏向锁,轻量级锁,重量级锁

C.偏向锁的原理/膨胀/撤销

D.轻量级锁的原理(普通自旋锁/自适应自旋锁)/分类/膨胀

E.重量级锁/开销分析

F.线程通讯：管道/等待-通知/共享内存

G.低效率轮询与wait和notify(注意：Object对象和Class对象均可以使用上述二者)/WaitSet/EntrySet

4.装了RedisInsight,可以在windows操作虚拟机里的redis服务

5.跑前端项目,积累一些pnpm经验,后端环境配了一半,服务能启动了,但是启动停机,明天继续排查.

6.分析复杂项目的pojo层次，Entity->Enums->DTO->Vo,其中VO分req和resp,对于有分页需求的：ApiResult(返回给前端的resp)>PageBaseResp(分页的resp)>xxxxResp(具体业务的resp)对于无分页需求的：ApiResult>xxxxResp

7.练习mybatisplus,还是写的不熟练,练习时长有限,明日回寝室继续练

8.十一月要开始准备六级听力了,还尚未写过一套六级卷子,期中的Java和数据库也得开始准备了，起码书得开始看了。还得准备排球考试，真是沟槽的窒息感啊

# 10.29日报

1.Lc一道medium,给定数组与目标值与元素个数,要求返回一个List,包含目标值附近的k个数.策略是构建滑动窗口,根据给定距离算法,移动left和right直到窗口闭区间内元素刚好等于k,则返回这个集合.

2.六级新增20个，复习122个

3.调了一下午项目,没什么进展,促使我要切记把API接口文档写好后再建表,写Entity,写DTO,写VO(Request和Resposne).SpringBoot尽量用2.x版本,3.x和mybatisplus不兼容的情况太普遍了,试了三四个3.x的版本,报各式各样的错.下午时间空耗到debug上面去了,很悲哀的时间浪费.

4.把ruoyi代码生成器看了看，看来相当方便，先建表，然后代码生成器导入表，下载zip，zip中有三个文件，一个sql,这个sql是给ruoyi的菜单栏用的，一个vue的api+views，直接覆盖丢进去就行。最后一个java中分src和mapper,前者合并到ruoyi-system的src中，后者丢resource里面就行。还有点小bug，前端可以输出表格，分页数据也可以看到，但是elementUI不显示已添加的数据行，有空得再看看。ruoyi这玩意还是强，虽然僵化，但是干活速度还是快。暑假看了部分ruoyi的源码，感慨是封装的太完备了，一层套一层。

5.晚上时间把Atomic类看了看,大致分为AtomicInteger,AtomicLong,AtomicReference一类,AtomicIntegerArray,AtomicLongArray,AtomicReferenceArray一类,还有些分类忘记了。看了看基本的API。然后就是Atomic类的底层Unsafe类，相当于是用java做类似C的行为，管理内存。所以不安全。值得注意的是，unsafe的theUnsafe是static final的，因此不能new实例拿到。比较的策略是A.用反射getDeclaredField B.JvmUtil去取。再者就是Unsafe层面的CASAPI是得o,偏移量,预期值,新值。但是对unsafe做封装的atomic类就直接用预期值,新值做入参了。这点也反映出对地址偏移量的考虑是比较不安全的，得加一层封装。

6.把前天看的大端小端复习了点，然后synchronized的锁膨胀部分，从轻量级锁到重量级锁，也就是锁的mark word的线程Id和自旋信息被替换成了monitor,以后新的线程过来发现你这个重量级锁，就不会做CAS自旋了，直接走monitor的阻塞和等待队列，等着拿线程就行。

7.工程性质的探索本身就意味着对时间的浪费，我还是常常为这种没有稳定收益的时间亏损而内疚。等量时间用于学习原理性知识，回报率是较高的。不过工程经验的确只能靠不断debug获得，哎，很难权衡吧。

# 10.30日报

1.LC一道medium，给定一个形如[1,6,4,3,2,5,9]的数组,问调整几个元素后,数组将变升序。策略是使用单调栈，分别从左右开始迭代。在发现当前元素比栈顶元素要小（单调左栈）和当前元素比栈顶元素要大（单调右栈），更新左边界和右边界到当前值的索引。不断迭代，最后返回right-left+1即可。实际是用单调栈来找滑动窗口，最后返回窗口的大小

2.六级新增20单词,复习122单词

3.把JavaSe的IO流部分复习了，手写了若干demo，上一回接触这个知识点还是去年的十月份，一年过去忘了许多，考试前得记起来了。

4.上oj把22年的c期末考试机试做了，大概只有两三道A不出来。原因是string.h这个库的函数不太熟,strcat,strcpy,strcmp,strlen,strchr....写了若干demo作为复习参照。

5.JUC部分：

A.JUC的Atomic原子操作包

B.基础原子类AtomicInteger

C.数组原子类AtomicIntegerArray

D.AtomicInteger的安全性分析，实质是对CAS的封装+不断的自旋->引入降低自旋开支的LongAddr(空间换时间,类似哈希)

E.引用类型原子类->解决以前只能只有基本类型原子类的问题

F.属性更新原子类：譬如AtomicIntegerFieldUpdater,因为引用类型原子类例如<User>不能保证user类内部的属性操作是原子的，那就得用Updater来代劳

G.ABA问题-用一个栈的结构来阐明

H.使用AtomicStampedReference和AtomicMarkableRefernce来解决，前者用计数器，后者用布尔值标记

I.CAS弊端分析与LongAddr原理分析

J.CPU物理缓存结构/并发编程的原子性,可见性,有序性问题/总线锁与缓存锁/MSI协议/MESI协议与RFO请求

# 10.31日报

1.LC一道medium,给定形如[4,5,3,0,0,2,4]的数组,要求输出一个数组,新数组与输入数组长度相等,每一个位置对应,且对应位置的值是整个数组中第二次出现输入数组相应位置的值的索引与相应位置索引值的差。譬如上述数组的输出结果为[1,5,4,2,1,1,0].用2号索引举例,其值为3,遍历数组直到6号索引才出现了比3大的数,因此2号索引在新数组的值就是6-2=4.策略是维护一个单调栈，从左遍历到右，单调栈从栈底到栈顶索引依次升高。在遍历到每个节点用栈顶元素指向的值与当前值比较，如果当前值大，则记录当前索引与栈顶元素这个索引，做差+1，将其存入新数组的对应索引指向的值，最终返回新数组。

2.六级新增20，复习100

3.MybatisPlus的IServce<>的crud方法/Wrapper的妙用/分页..充分训练crud能力/看了部分Mapper层的方法..select/delete/insert/update.

4.配复杂项目的环境,总结经验：先改application.yml中的中间件ip/再看项目的schema.sql(有的开源项目只给建表语句不给建库语句,那你得去application的url里面找数据库的名字,自己建库,在库里面去跑schema.sql)/IDEA直接pull项目加载更快/要对涉及的每一个中间件的账号和密码仔细考虑,启动失败的原因常见于本地中间件的conf配置与application的属性不一致,其次就是关注Maven中依赖的版本是否与本地跑的中间件服务的版本兼容.

5.JUC部分：

A.编译器重排序/指令重排序/As-if-Serial规则/硬件层面的内存屏障

B.JMM/JMM与JVM区别/JMM八个操作/JMM解决有序性问题/Volatile语义中的内存屏障/这一块得在脑子里面把 主存-工作内存-高速缓存-线程 操作的图勾勒出来，本质就是：主存到工作内存read,工作内存到高速缓存load,高速缓存到线程就是use,这个过程也会assign赋值.接着从工作内存往主存是先store后write.read和load/store和write成对出现.后面谈的JMM层面的内存屏障也是基于store和Load来说的。

C.学习的脉络是从物理层到逻辑层。也就是先学习：内存->三级缓存->寄存器中的#lock汇编指令造成的缓存锁相较于总线锁的优越性.再考虑到希望跨平台兼容不同的机器码,设计出JMM来屏蔽底层.接着就JMM这个逻辑层设计出Read,Load,Store,Read与对应的逻辑内存架构...

# 11.1日报

1.LC一道单调栈的medium.给一个形如[6,5,4,0,9,12,34,74]的数组,要求找出一个元组（i,j）,要求j-i最大。要求是i<j&&nums[i]<=nums[j]。考量i是小元素且i指向的元素是小元素.那从较小的左侧开始找,对包含在单调递减区间的元素,都取其索引压入单调栈中.（stack.isEmpty()||nums[stack.peek()]>nums[i]）。接着从右往左利用stack找i,也就是固定点j,然后不断匹配合适的i.用贪心找j-i的最大值即可。

2.六级新增20，复习100左右

3.看数据库的考试课ppt,这一块主要是关系代数运算没有接触过,刷了一些往年真题,感觉这门课问题不大,每天看一点点吧。

4.JUC复习：

A.JMM/六个操作/内存屏障/volatile防止重排序+保持可见性/volatile不保护原子性的理由/Happens-before的六个规则
B.显示锁Lock/可重入锁ReentrantLock/显示锁模板/用Condition来在显示锁中复刻Object.wait()和notify()的等待-通知机制/LockSupport的pack与unpack与Object.wait()与Thread.Sleep()的差异比较/显示锁分类

5.今天总体来说比较放松，首先是睡到十点钟，背完单词刷完算法就一点了。看一些数据库考试内容，写一些题，玩会手机一下午就过去了。晚上就看了点JUC的新内容，复习了昨天知识，然后写了两篇博客。这种松弛的生活还是太容易腐蚀人的意志了，明天真得耐下性子继续看书+复现代码+总结博客吧。高并发这一块的细微知识点太丰富了,在延伸广度的同时,得逐层分析依赖关系,学习底层的设计原理。

# 11.2日报

1.LC一道单调栈的medium,判断数组中是否有满足132规则的子数组。策略是维护单调递减栈，从右到左处理。画图做起来比较快

2.英语新增20，复习106

3.看了几套往年的Java考试题

4.SpringCloud相关复习

A.${xxx}的配置需要在centos中export xxx=xxx

B.bootstrap比application早加载,一般存springcloud环境变量

C.Redis6379,Zookeepr2181,rabbitmq3306,eureka7777,configserver7788,zuul7799.nginx80

D.eureka分server,instance,client

E.脚手架模块设计->单个服务的设计->api/client/server

F.微服务治理三板斧->缓存/限流/降级

G.ConfigServer相关的本地配置/dev/xxxmaker-redis.config文件夹放在config-server的resource中

H.RESTful-表示层状态转换-一些基础API

I.把Client的Feign服务+熔断器类流程复习一遍，输出博客一篇

J,Ribbon的负载均衡算法->线性轮询/随机/响应时间权重/最少链接/重试策略

5.看了点JUC

A.把悲观锁乐观锁:syn轻量和基于aqs的ReentrantLock是乐观。syn重量锁悲观/可重入锁/公平与非公平:ReentrantLock默认非公平,传参true公平,tryLock非公平/syn不可中断,Lock可中断/ReentrantLock是独占锁,但是ReentrantReadWriteLock是共享锁

B.JUC看不太进去,明天再看吧。

6.头有点晕,不清楚为什么,感觉最近比较松弛来着.

# 11.3日报

1.LC一道单调栈,题意是找符合要求的最长子数组长度(涉及到数组元素大小)。策略是先用前缀和求出截止到i天工作饱和和工作不饱和的程度（>8小时为1,else为-1）。然后针对这个前缀和数组进行从左到右的单调递减栈的压入元素。然后从右到左用nums[i]与栈中元素做比较，从而找到合适的i和j,从而算出最长的子数组长度

2.单词新增20，复习86个

3.JUC部分：

A.悲观锁的问题/通过CAS实现乐观锁/不可重入的自旋锁/可重入的自旋锁(有state来计数了)/CAS可能导致的总线风暴（拓展SMP架构的多内核-1总线-1内存图）/CLH自旋锁（AQS的基础）

B.公平锁与非公平锁(ReentrantLock默认非公平,传参为true则公平),Semaphore传参true为公平

C.可中断锁与不可中断锁：指的是等待取锁的排队过程是否可以中断，syn不可以，lock中有一个lock.lockInterruptibly.

D.共享锁与独占锁：ReentrantReadWriteLock共享/ReentrantLock` 和 `synchronized独占。注意：读写锁可以取出读锁和写锁，写锁可以降级为读锁，但是读锁不可以升级为写锁，因为可能有死锁风险

E.AQS的状态标志位，队列节点类，JUC显示锁基于AQS,ReentrantLock和AQS的关系

F.模板模式-ReentrantLock的公平和非公平实质是依托于AQS的sync的两种模式...这一块没有看的很细，明天继续

4.SpringCloud部分

A.Hystrix的三种状态：**闭合状态（Closed）**：**打开状态（Open）**：**半开状态（Half-Open）**：以及相关的一些配置参数的深入学习

B.探究Feign的实现原理，基于RestfulAPI+SpringCloudweb依赖环境，就动态代理和静态代理的区别输出了一篇博客。

# 11.4日报

1.LC一道Medium,给定数组,输出新数组,新数组每一个元素都是旧数组该索引元素右侧的第一个比其大的数。且旧的数组是循环数组。策略是取模+遍历2*n

2.六级新增20,复习96

3.Feign原理部分:

A. XXXService->XXXServiceProxy->InvocationHandler->MethodHandler. 在Java代理模式中，`XXXService` 是定义业务方法的接口，`XXXServiceProxy` 是该接口的代理实现。`InvocationHandler` 是一个接口，用于处理代理实例上的方法调用，而 `MethodHandler` 是一个具体的概念，通常在 `InvocationHandler` 的实现中，它负责处理特定的方法调用。在 `InvocationHandler` 中，通常会维护一个 `dispatch` 映射（Map<Method, MethodHandler>），其中键是 `Method` 对象，值是 `MethodHandler` 对象。在 `InvocationHandler` 的 `invoke` 方法中，具体的实现是通过 `dispatch.get(method).invoke(args)` 来完成的，而不是 `dispatch.get(method).invoke()`。

B. Hystrix集成到Feign中，可以通过定义一个实现了Feign客户端接口的fallback类来实现。在 `InvocationHandler` 的 `invoke` 方法中，如果调用原始方法失败，Hystrix 会捕获异常并执行 fallback 方法。这通常通过在 `@FeignClient` 注解中指定 `fallback` 属性来实现，而不是直接在 `InvocationHandler` 的 `invoke` 方法中处理。

C. Ribbon的负载均衡集成到Feign中，Feign 客户端默认已经集成了 Ribbon。在发送 HTTP 请求之前，Feign 使用 Ribbon 来选择服务实例，并将请求发送到该实例。在 `MethodHandler` 中，Feign 会使用 Ribbon 的客户端配置来构建请求的完整 URL，而不是直接在 `MethodHandler` 中拼接 URL 和发送 HTTP 包。通过配置 Ribbon，可以自定义负载均衡规则，例如使用不同的 `IRule` 实现。

4.AQS原理分析

A. （AQS）概述（AQS）是Java并发包中的一个抽象类，它提供了一个基于FIFO队列的框架，用于实现阻塞锁和相关的同步器（如信号量、事件等）。AQS内部维护了一个状态变量（state）和一个FIFO等待队列，用于管理同步状态和线程的阻塞与唤醒。

B. AQS核心组件

1. 状态变量（state）：一个整数值，表示同步状态，用于表示锁的持有情况或信号量的数量。
2. 等待队列：一个FIFO的双向链表，节点类型为Node，用于存储等待获取同步状态的线程。
3. Node节点：包含线程引用、等待状态、前驱节点和后继节点等信息。

C. AQS核心方法

1. acquire(int arg)：独占方式获取同步状态，如果当前线程成功获取同步状态，则返回；否则，进入等待队列等待。
2. release(int arg)：独占方式释放同步状态，释放后，唤醒等待队列中的下一个节点。
3. acquireShared(int arg)：共享方式获取同步状态，如果当前线程成功获取同步状态，则返回；否则，进入等待队列等待。
4. releaseShared(int arg)：共享方式释放同步状态，释放后，唤醒等待队列中的下一个节点。

D. AQS实现原理

1. 独占锁获取与释放：
   - 获取锁：尝试修改状态变量，如果成功，则表示获取锁；否则，将当前线程封装为Node节点，加入等待队列，并通过自旋或阻塞的方式等待。
   - 释放锁：修改状态变量，唤醒等待队列中的头节点。
2. 共享锁获取与释放：
   - 获取锁：尝试修改状态变量，如果成功，则表示获取锁；否则，将当前线程封装为Node节点，加入等待队列，并通过自旋或阻塞的方式等待。
   - 释放锁：修改状态变量，唤醒等待队列中的所有符合条件的节点。
3. 等待队列的管理：
   - 当线程获取同步状态失败时，会被封装为Node节点，并加入到等待队列的尾部。
   - 当线程释放同步状态时，会唤醒等待队列中的头节点。
   - 等待队列中的节点会通过自旋或阻塞的方式等待，直到前驱节点为头节点，才有机会尝试获取同步状态。
4. 条件队列：
   - AQS还支持条件队列，用于实现类似Object的wait/notify机制。
   - 条件队列是一个单向链表，节点类型为ConditionNode，用于存储等待特定条件的线程。

# 11.5日报

1.力扣一道easy,给定苹果包数组,篮子数组.苹果包数组的每一个元素表示这个包中有多少个苹果,篮子数组每一个元素表示这个篮子可以放多少个苹果.现在希望把苹果从包中取出,全部放入篮子中,且使用最少的篮子完成此事。策略:A.取出所有苹果 B.对篮子按照容量升序排列 C.依次从最后的篮子开始放苹果,当当前苹果余额小于篮子容积时break.在return处 sum>0?ans+1:ans;即可

2.六级新增20个，复习96个

3.工程知识：

A.改用FinalShell连虚拟机,上传文件和下载文件比FXP方便许多,且更有linux的体验感了

B.复习了常用的linux命令

C.复习了微服务项目的docker-compose部署-先配env,再处理service.

D.复习了RabbitMQ的队列-绑定-交换器模型.复习了创建和管理上述三者的命令,以及相关业务场景-譬如微服务中的订单处理,客户之间的邮件发送:但凡是异步信息传递,我们优先考虑RabbitMQ

4.数据库课设:

A.针对SpringBoot版本和相关依赖进行了技术选型,通过互联网查询确保所有依赖版本都是稳定的.[耗时较久]

B.环境变量记录-记录工程细节

C.完成了五个实体表和一个关系表的设计

D.完成了2个模块,12个接口的设计

E.完成6个entity和1个result的设计

F.有时间再把MongoDB和Redis接入的相关功能和接口进行设计,后端文档处理完后再写代码,接着就是重新设计前端界面..还可以加入发布帖子和点赞/登录排行榜功能...充分利用中间件.可以考虑使用RabbitMQ完成站内信箱,使用ElasticSearch实现分词搜索-这些不急着做,先把主体功能写完.毕竟新功能又得设计新表了

# 11.6日报

1.力扣一道medium,给定多个背包及其当前装载情况和可放置的额外石头，计算能放满背包的最大数量。策略是拿背包数组和已放数组做减法,构造差数组。接着排序差数组,从零开始给差数组里面填充石.直到用完额外石头为止.最后遍历差数组,记录差为0的背包个数.该记录就是能放满背包的最大数量

2.六级新增20，复习100

3.JUC：

A.Condition单向队列和AQS双向队列转换：C多个,A一个：为Condition与ReentrantLock提供底层支持

B.安全同步容器类：Collection.synchronizedxxx(),vector,hashtable,stack：锁的粒度太粗：只适合低并发量的多线程,不适合高并发场景

C.高并发容器类：ConcurrentHashMap,CopyOnWriteArrayList与扩容机制：以迭代过程是否可以crud容器为例验证synchronized粒度过粗导致无法实现，转而使用高并发容器类

D.BlockingQueue:Array/LinkedList/Priority/Delay/Synchronous.其中Priority对消费者阻塞,Delay是通过计算时间差来允许消费者获取队列中元素

E.ConcurrentHashMap的JDK6和JDK8差异性/从Segment(继承R锁)走向CAS全体,syn局部/hashmap的扩容与树化,切记阈值64节点长度,8链表
F.饿汉模式/双重检查锁

4.工程：

A.完成Admin模块的六个接口的：Mapper/Service/ServiceImpl/Controller代码实现。

B.补充Entity对应的DTO,实现Entity->DTO一一对应,针对日期字段做了修饰处理

C.使用Eolinker测试了六个接口,可以正常工作->积累经验：写测试json一定要注意：从SQL表出发。只看Entity可能会忽略部分字段的特性，譬如enum...

D.完善项目文档

5.前端：

A.使用IDEA构建Vite项目get

B.了解了OpenTiny组件库,个人认为比elementUI更美观？也许这次项目可以试试这个UI库

# 11.7日报

1.力扣一道medium.买雪糕数组,策略是先给数组进行排序,再从便宜的买起,从而买到数量最大的雪糕

2.六级新增20，复习96个

3.工程经验复盘

A.Linux的权限并非是子目录继承父目录的..譬如chmod 777 /opt了,但是/opt/zookeeper这个目录是没有rwx权限的.你如果想在该目录上传内容,得单独chmod 777 /opt/zookeeper .当然,上述的操作得是sudo状态的

B.tar用来解压和压缩：-z是使用gzip算法工作。处理.tar.gz格式或者.tgz的压缩包;-x表示解压-extract ;-v表示verbose详细输出解压的内容;-f表示要解压的文件名,注意-f得最后用

C.`cp zoo-sample.cfg zoo.cfg`复制一份前者,新文件命名为后者.

D.vim相关操作：vim 文件名->打开;按i进入插入模式,按ESC退出模式;ESC后输出:wq保存退出vim

E.sh脚本通常通过./zkServer.sh start来启动.此处的./表示当前目录.start是一个参数,恰好脚本用这个参数来决定启动

4.ZooKeeper的应用场景/部署/结构

5.离散数学-复习

# 11.8日报

1.LC一道Easy,K次取反后最大化数组和.因为策略是优先对负数的元素翻转,因此我先将整个数组升序排列.从0索引开始遍历,当当前元素值为负数且k>0,则翻转该元素且令k自减。接着是处理边界情况,也就是k的数量比负数更多,也就是将所有的负数翻转后k还有冗余.这些冗余的k次数会导致我们的正数变成负数,如果希望损失最小,则得再将数组排序,让翻转发生在nums[0]这个最小元素上.当然：并非所有的k都会导致nums[0]翻转,倘若余下的k是偶数,无事发生,因为偶数次数会抵消.若是技术次,则让nums[0]为0,然后计算数组元素和返回即可

2.单词新增20,复习126个

3.阅读Netty书籍,明确了同步/异步/阻塞/非阻塞的关系,清晰化了用户态和内核态的区分.认知了read和write系统调用,捋清楚了传统的IO(同步阻塞),没有商业价值的同步非阻塞(不断新建线程轮询-过于消耗内存而不被使用),IO多路复用(Netty使用的模型-先建立select,接着使用一个线程通过select控制多个文件描述符(譬如socket))/以及异步非阻塞的关系.

4.回忆了9.27日记忆的Netty相关API操作,EventLoopGroup/Bootstrap/Handler相关概念/跟着教程手搓了CS架构的通讯代码.

5.高数刷题：看了部分函数和极限的内容

6.IO流和File的代码实现不太熟悉,太久没有写过相关的业务了。今日训练了：新建多级文件夹+文件+使用i/o的FileStream,接着用i/o的Reader/Writer进行编码,最后套入Buffer中去读/写.

7.最近的日子开始紧迫起来了,需要应付期中两门和期末若干门数理课+思政课的考试。压力还是比较大的。有时候看到朋友圈里同学们较为雀跃的日常，难免心生羡慕。但是就业环境太严峻了，假使现在沉溺于脱产而虚妄的惬意中，我应该会成为那80%失业率的贡献者之一吧。思绪这些没有太多价值，焦虑并不能解决实际的问题，还是得凝心聚力，继续沉淀。

# 11.9日报

1.Lc一道medium.给定形如[5,5,5,6]的数组与值k。我可以做k次删除元素的操作，希望k次之后能够让数组中留存的元素种类最少。观察到[元素]与[出现次数]的关系。建立hashmap。将[元素]作为key，将[出现次数]作为value。使用for循环填充map。因为看到"最少"的描述，因此考虑贪心，贪心得排序，map没法排序。我们取map.values()作为list进行排序即可。接着就是迭代list，只要k>0且k-tmp>0就继续迭代，同时list的size自减一次，毕竟你删去了一种元素。倘若k-tmp<0直接返回size即可。

2.六级新增20，复习96个

3.离散数学复习

4.NIO的Buffer/Selector/Channel相关的大量API复习，以及串通学习了几个代码demo

5.今日感悟：

A.今日刷了几份大厂面经，其中juc的出现频率很高，命中了我先前花费十天梳理的juc知识体系。但是我的深度仍然不够，面对面试题无法高效组织语言回答。因此juc书必须得反复看，反复给自己讲，这样才能做到逻辑清晰，脱口而出。

B.Netty的API和NIO的API需要深挖，这一块的模版代码往常是被我忽略的。但是考量到面试的挖掘细节程度，需要提高注意。

C.学历>实习>项目>技术。观察多篇面经，基本上来都是先问实习，问完实习再问项目，纯八股场景少。在设计话术时候需要通过项目和实习把面试官往我的八股舒适区引。这一块的项目还没开始准备，暂定一个Netty相关的轮子，一个Springcloud的应用吧。大一做的苍穹外卖应该进入历史的垃圾堆了。

D.今日很摆，哎。

# 11.10日报

1.力扣一道easy,给定数组，求和最大且元素最少的子序列，满足子序列和大于余下元素和。排序+贪心即可 

2.六级新增20，复习76 

3.看了sentinel和docker的原理

 4.把数据库课设第一个版本的接口写完了，测完了。今天工作量是6个接口。 

5.把前端的架子搭起来了，vue2+ts。有时间继续完善

# 11.11日报

1.力扣一道medium.今天是第300道题。给定整数数组arr,你可以删除若干个数，最后要恰好令余下的数之和>=原数组各元素之和的一半。由于涉及到元素和出现次数，下意识考虑map。key存数字的类,value存这个数出现了几次。然后对把values都取出来放到list里面,对list排序。降序排序完成后用两个变量分别记录已经删除的种类和已经删去的值。用已经删去的值做判断，最后返回一个种类数量即可

2.六级新增20，复习97个

3.数据库考试复习-看了一半的题库

4.写数据库课设：

A.后端加一个新接口：登录接口

B.前端从零开始写，把主页面+注册+登录的功能写完了

C.路由守卫这一块是第一回实操，出现许多问题，排查很久bug。我们做前端鉴权的思路可以是：登录成功后拿到json,存入localstorage.接着再往里面设置一个登录成功的key-value对。接着就是从json中取出代表该用户权限的字段(数据库里面设定好的-在注册时候确定的)-注意这一块是没有引号的。然后根据这个字段分类做router.push。

D.vue3的话，前端发送请求得在vite配置跨域。毕竟现在前后端分离，前端的端口和后端端口不一样。通过配置同源策略实现localhost:5173/Admin/getList转化为localhost:8080/Admin/getList的场景。

5.今天几乎没有摄入任何理论性的知识,大部分的时间都在刷题+写项目。这种节奏下，时间过得比较快。但是要警惕这种快节奏催生的浮躁心理。原理性的知识是必须得静下心来认真学习的。

# 11.12日报

1.力扣easy：打折购买糖果最小开销。题设给定：买三颗糖只用付两颗的钱。且免费的那颗糖只能比付费的两颗糖便宜。策略是先给数组排序，接着考虑i%3位置的糖。我们只让i%3位置的糖免费，也就意味着需要为i+1和i+2颗糖付费。这里的i+1和i+2我们通过if(i%3!=0)中的total+=nums[n-i]表达.之所以让i从左到右,但是算糖从右到左：是因为考虑到当总的糖<3时候,nums[0]的付费无法被计入.那只能用nums[n-i]表达了。

2.六级新增20，复习82

3.工程知识：

A.梳理了定时任务：从Timer到ScheduleExecutorService,再到DelayQueue.在单体项目中的定时任务,实现了从单线程到多线程的演变.内在机制也具备多样性,譬如Timer和ScheduleExecutorService依赖线程,而DelayQueue的底层是PriorityQueue和小根堆

B.动手实操了XXL-JOB：1.每一个boot项目都是一个执行器,boot中用@XxlJob修饰的方法是任务 2.执行周期在调度中心用corn配,在方法中写业务即可。3.给不同的用户分配执行不同"执行器"的权限。实现调度和执行的解耦。4.分组任务在注解中使用,group属性区分,在调度台分别执行。5.失败重试得在注解里配置failRetryCount=3..这样的次数。6.广播机制：就电商业务而言，平台需要发布全站促销活动，我们希望每个执行器都执行，则要在注解属性中配置executorRouteStrategy="broadcast" 7.分片机制：传入index和total，处理ABCD四个地区的发货业务。这里xxl-job干的活就是自动把任务分配给四个不同的执行器。具体实现：控制台给多个任务配一样的jobHandler.但是参数不一样。这部分如果改为多机的话,就是让多个服务使用相同的AppName.

C.美化了前端项目

4.知识获取：

复习了些se的方法，应付考试所需要的。

# 11.13日报

1.力扣easy：给定乱序数组,定义数对（i,j）。就2n个元素可以分为n个数对。现在要求从每个数对中取出的最小值相加结果最大。观察题设：发现"最"：考虑贪心。策略：先对数组升序排列。观察得到0 2 4 6等数对中位置较小的索引指向的值较小。步长为二遍历2n，对每一个nums[i]累加即得到结果

2.六级新增20个，复习92个

3.工程训练：

A.重构了课设项目的前端UI，从左右布局更新为了Top导航栏+内容栏平铺满，更符合我的审美习惯。

B.实现了类Apple的整体UI风格，新增Main页。

C.新增Admin功能页：实现五个功能模块的数据获取+前端请求发送。此过程中发现Delete接口和Update接口在后端设计时存在稳定，在前后端联调环节修复问题。5个功能模块正常工作

D.前端项目积累工程性排查知识x2：关于router-link和view的一一对应+vue-router的循环导向问题

4.Netty学习：

A.Netty逻辑架构应分为网络通讯，事件调度，服务编排三层。分别对应Sor非SBootStrap(BSP)+Channel/EventLoopGroup与EventLoop/ChannelPipeLine与ChannelHanlder

B.Netty本质是对NIO的封装,解决了TCP重连/TCP粘包拆包/手动编解码的痛点

C.ES,RocketMQ,Dubbo对Netty有比较深刻的使用

D.梳理了从while到ThreadPerConnection再到Reactor的模型演变路线,技术的演变是有逻辑可循的,是一个不断优化和解决问题的过程

E.单/多/主从多：本质是ELG的EL数量不同+Boss和Worker分工。针对主从：是主负责建立,而通道注册到从.Ps,

F.ChannelPipeline的双向链表结构，大概为[I1,O1,I2,O2,I3,O3],入站是(I1->I2->I3),出站是(O3->O2->O1)

G.一对一：Channel->EventLoop->ChannelPipeLine

5.总结：

白天学习效率太低了，看一会书就想玩手机，很悲哀。

晚上连着干了三小时项目，都忘记休息了。做工程时间纵然是飞逝，知识性储备收益却是细微的。

# 11.14日报

1.力扣一道medium：给定偶数元素数组，先尽可能让构成和较小的若干数对，然后从这些数对里面找最大的数对和。先排序再二分，这题太套路化了。

2.六级新增20，复习86个

3.工程：

A.看基于Netty的Http服务器实现GET响应源码。梳理Netty工作流程，了解自定义Handler的细节，输出复盘视频一个。

B.手写RPC看了三个topic的代码：

B.1：topic0:最朴素的思路是，使用传统的BIO，调用者凭借Socket+ObjectI/OputStream传递一个字段（譬如id）。接着提供者用这个id在自己的Service中取到返回值，将这个返回值通过Socket+ObjectI/OputStream传递给调用者。这样做问题挺大：首先是传递的字段数量只有一个，其次是成功和失败没有响应。

B.2：topic1针对前者设计了RPCRequest和RPCResponse两个pojo.传递方法名,类名,参数类型与参数表，以及返回结果+状态码。我们觉着将IO操作和业务放一起，耦合性太高了，因此将IO独立出来，作为IOClient,以后Client调用IOClient即可。后来发觉构造Request也有复杂的模版流程，这些代码和业务逻辑放一起也太耦合了，于是也独立出来，因为无论什么请求都要构造Request，我们采用JDK动态代理来处理该部分。OK了，现在我们在业务层调用Client,Client里面调用Proxy,Proxy中调用IOClient.我们的Code变得优雅起来了。

B.3：topic2：这回不去动调用者部分，目前已经足够优雅了。我们考量一下服务提供者。先前我们只考虑调用的方法来自一个Service，但是业务场景是复杂的，我们需要让更多的Service被支持。map是个不错的想法，我们在Spring源码中发觉了它的妙用。我可以使用反射来获取Service的名字作为key，用Service的Class对象作为value。又考量到先前while+新建线程的Server有点性能低下，将其迭代为线程池是更好的选择。但是线程池和Runnable逻辑放起来似乎还是太耦合了，那我们将Runnable分离为一个类，在线程池版的Server调用，业务逻辑更清晰了。

C.复习登录：cookies->session->jwt->oauth2/相关的web前端存储：localstorage,sessionstorage,cookies相关机制。

4.感觉明天得开始复习六级听力和刷题了。又是临近期中，真是屋漏偏逢连夜雨啊。

# 11.15日报



1.力扣一道medium：给定数组，每个元素都是一个人的重量。一艘船可以坐两个人，每艘船有限重。问最少多少艘船可以运走所有的人。思路是：不论如何，都可以运走重的人。能否运走轻的人就看轻重二人相加是否还在limit内。如果是的话轻的指针就右移动。每次重的人代表的右指针都会左移。因为他无论如何都能上船。

2.单词新增20，复习116

3.知识性学习：

A.复习了JavaSE的考试内容

B.学习了RPC框架的手搓流程，这一块还得继续深化

4.项目工作：

A.设计好了数据库课设的留言板。思路是：使用grid卡片布局生成若干个卡片。每个卡片呈现的内容需要实时向后端请求json。后端发过来的是一个json数组。其中有两个比较关键的参数，一个是contentPreview,一个是content.这个Preview是用来展示在卡片上的短文字。策略是在后端的Service层通过对content的截取来实现。目的是让界面看起来美观。而content是完整的preview.content只有当用户点击卡片才可以触发。这个类似于小红书网页版的卡片。不点开只能看一点内容，点开可以在不改变网页router的前提，弹出一个卡片，在卡片上做更多呈现。牛客的网页版也是这种思路，我觉得还是比较美观的

B.然后就是比较传统的后端设计，这个无非就是先写一个BlogRequest和BlogResponse.然后就是Entity,Service,ServiceImpl.Controller.写完这些就拿apifox测后端接口，后端测完了没问题就和前端项目联调。联调主要是看前端的axios是不是配置错了。今天因为新开了一个Discuss类，之前配置的跨域没有包含这个类目，导致debug许久没出来。以后要注意先配vite.config.js了。

C.这个数据库课设整体上感觉已经不错了，UI采取黑白灰+卡片浮动布局。我还是觉着鼠标滑到卡片上，卡片有滑动效果挺商务的。下周抽时间把user的前端界面画一下，基本就完工了。这一块工作量很小，因为业务逻辑和Admin端差不多。倒是今天做的留言板的业务逻辑比较复杂，需要花较多的时间。

# 11.16日报

1.力扣一道Medium：给定数组nums,要求对数组任意排序后存在最多的伟大数:伟大数定义：排序后数组perms perms[i]>nums[i] 且i在[0,nums.length-1]之间。由于没有指定要求按升序或者降序排列，排列顺序可以自定。我们先升序排列。接着用tmp遍历perms,设定变量i。一旦出现tmp>nums[i]。就让i++,最后返回i的值就是伟大数的最大值。思路是田忌赛马。拿最劣等的马做nums[i]。只有tmp>nums[i]时候才让i自增，意思是才让tmp和nums[i]绑定在一起，从而捆绑一个较大的元素，这样不断向右迭代，大的tmp全部被小的nums[i]消耗掉了。我们再将绑定的tmp和nums[i]放在对齐的位置即可（因为顺序是我们自定义的，我们想怎么排就怎么排）。

2.六级新增20，复习102

3.离散复习

4.JavaSE复习

5.C语言复习

6.复习Redis：看了String的数据结构，跟着敲了一遍SDS的C代码，学习了SDS相较于传统string.h的优越性：1.查长度因为有len所以O(1) 2.不用\0判定结束而是用len，从而让char[] buf可以存二进制值了（传统用\0判定会导致0x00的二进制数据存在buf中时因为0而异常），复习相关的strcpy,realloc,malloc,struct的相关定义,熟悉语法，输出博客一篇
7.六级做了一套听力，一套长篇阅读，错麻了，还是得练题，明天得开始训练了。
8.今天真的太摆了，完全没有什么产出，明天必须状态拉满，再这样下去要废了。

# 11.17日报

1.力扣：easy一道：给定两个数组，分别代表椅子和人的位置，要求移动最少得次数让人坐上椅子。策略是先对两个数组升序排列。接着从i=0开始计算移动距离，累计和即可。这是比较典型的两排序贪心。

2.六级新增20，复习103

3.前端：

A.box-sizing默认是content-box,该状态width=content,会产生子元素边框超过父元素情况。策略是修改为border-box，该情况下width=content+padding+border，让整个子元素都在父元素框内

B.导航栏常见的设计是 display:flex; 让其子元素默认横向排布, justify-content: space-between;均匀空白 切记justify控制主轴 align-content: center; align控制交叉轴。且默认flex-direction的主轴是水平轴

C.box-shadow的参量分别是x轴偏移,y轴偏移,模糊半径,阴影颜色。切记xy是斜向右下方正方向的。

D.transition用于控制元素变化的持续时间，实现一个"过程的呈现"。而具体的变化结果是伪类的css决定的。譬如.scale-box{ transition: transform 0.3 ease} .scale-box:hover{transform: scale(1.5)}前者在transition后指定transform,从而监听到其hover时候的transform变化，添加一个持续时间。ease是一个先加速后减速的时间函数，产生平滑效果。其他的时间函数例如liner,steps等也有不同功能。

E.transfrom常见有：translate(x,y)平移水平x,竖直y；rotate(angle)该元素旋转若干角度；scale(x,y)元素在x和y方向缩放倍率；skew(x,y)在x,y方向组件缩放倾斜角度；matrix(a,b,c,d,e,f)两两一组作为因子，分别是缩放，倾斜与平移。transform-orgin可以确定基准点。这里的倾斜是有点3d效果在里面的

F.align-items控制单行对齐，align-content控制多行对齐。

4.后端：

A.redis的string,list,set,sortedset,bitmap,hyperlog,geo,hash,streams,pubsub的电商业务场景下运用。输出博客一篇。

5.备考：

A.复习JavaSE的IO流和多线程

6.项目：

A.完成数据库课设，整理前后端文档，整理开发基本思路，输出视频一个。

# 11.18日报

1.LC一道medium，双序列匹配，双指针+排序+贪心解决。

2.六级新增20，复习103

3.复习Java考试

4.备考是最难受的，难以言喻的难受吧。

# 11.19日报

1.LC一道Medium：给定两个字符串，均为英文字母。要求实现方法：判定x串的每一个元素均可以在y串中找到一个字典序比其更大或者等于的字符。如果判定成功则return true。一个简单例子："abc"和"def"，这就是典型的true。但是"abc"和"aaa"就不行，因为第一个串的里的bc没在y串中找到比其字典序更大的元素。解决策略是：x字符-'a'做索引，然后value是该元素出现的次数。接着遍历y串元素，对于每一个y串元素，都从当前元素开始遍历，遍历完整个hash(也就是26个字符的数组)。一旦找到匹配的y串元素，则break，并且记录为flag为true。在外层判定flag，一旦发现有false情况，直接break。x串就没必要看后面的元素是否在y串能找到>=自己的字符情况了。

2.六级新增20，复习117。

3.前端学习：

A.filter是image的滤镜,常用的效果是filter: brightness(80%).让Banner的背景图暗淡,衬托文字。

B.flex-wrapper:wrap。让display:flex的子元素贯彻：如果一行排不下，就排成两行。但是如果是默认的nowrap,则会排成一行,且超出部分切割。wrap-reverse是换行，但是被挤出去的那一行放在原始行上方。

C.flex子元素的距离通过父元素的gap设置，譬如gap:20px。

D.页面背景遮罩设计：position:fixed;固定在页面，不随滚轮滑动。通过对top,left,right,bottom均设置为0：遮罩四个边缘固定在页面的四个角。background-color:rgba(0,0,0,0.5)：半透明的黑色背景是遮盖的精髓。最后是z-index:999，确保弹窗和遮盖在页面展示内容之上。剩下就是display:flex以及justify-c和align-c这种常规操作了。

E.弹出框体设计：border-radius: 10px;边界圆角设计;width:80%.宽度要小于界面元素,这样才能凸显出弹窗是漂浮在原始界面之上的。max-width为800px，防止大屏幕弹窗过大。overflow-y:auto。这里因为要展示从后端拉取的员工信息，员工信息可能有几百条，一个屏幕是展示不完的，避免溢出，让用户滚动滑轮从上到下逐条看。

F.表格设计：border-collapse：collapse：两个表格的重复边界只展示一条，单线边框更美观。

G.th和td用padding8px，让文本不至于紧贴边框，美观。

H.button要注意两点：a.border:none去除传统按钮的默认边框 b.cursor:pointer 鼠标悬停转为手符号,有交互感.

4.备考：
C语言看API,string和io的部分例子手敲若干遍加深印象。

5.项目：

把数据库课设的欢迎页前端UI美化了一下，先前的卡片太丑了，加点对比色和阴影。

6.Java终于考完了，明天开始看数据库了，还有6天时间。

# 11.20日报

1.LC一道medium，田忌赛马题，使用TreeMap的API完成。比如higherKey和firstKey

2.单词新增20个，复习112个

3.复习数据库

4.沟槽的换季感冒，效率非常低。

# 11.21日报

1.LC一道medium：给定二进制数组，问将其全部翻转为内容为1的最少次数。翻转通过异或实现，三个三个一组从左到右进行，在nums[i]==0时候进行三个连续翻转。这里的连续是因为要求尽可能使用最小的次数。记录次数返回即可

2.六级新增20，复习116

3.数据库复习刷题

4.Completable：

A.好处：相较于Future可以实现异步的编排,异常的捕获,简而言之就是可以链式调用和处理了,而且可以组合多个异步任务的结果

B.`CompletableFuture` 常用的 API 包括：`supplyAsync()` / `runAsync()`（异步执行任务），`thenApply()` / `thenAccept()` / `thenRun()`（任务完成后的回调），`exceptionally()` / `handle()`（异常处理），`allOf()` / `anyOf()`（组合多个任务），以及 `get()` / `join()`（获取结果）。

5.设计模式：

A.复习责任链模式：后端对用户登录的校验场景。责任链模式另外一个应用是Netty的pipeline中的Handler链条，整理逻辑图，输出博客与视频

B.复习策略模式和桥接模式：针对线上/线下的wx/zfb/银行卡场景做代码的解耦。编写逻辑是：先写策略接口，再写策略实现类。先写桥接处理器接口，再写桥接处理器实现类，桥接处理器需要注入策略接口，然后调用策略接口的内容。最后在OrderService中凭借Map完成前端请求和具体Processor的配对，然后根据前端请求参数完成具体支付平台的配对(switch判断wx等平台)最后将这个判断得到的策略实现类注入到桥接处理器中，调用桥接处理器，调用其中被注入的策略类，从而调用这个策略类中实现的具体逻辑。整理逻辑图，输出博客一篇，输出视频一个。

# 11.22日报

1.LC一道medium：给定二进制数组，需求是翻转为全1，问最少翻转次数。且翻转操作会导致nums[i]到nums[nums.length-1]的所有元素一起翻转一次。因此需要考虑：针对0元素，我希望翻转该元素后一共翻转了奇数次，针对1元素，希望翻转它后一共翻转了偶数次。因此在翻转前，我们需要判定num==(operation%2)。只有为真才进行翻转。

2.六级新增20，复习112

3.复习数据库，刷题

4.写设计模式的项目：设计模式相关：输出博客+视频+代码传Github仓库

A.观察者模式：基于到店业务的观察者监听店铺状态,多系统联动场景[商铺系统/用户系统/统计系统/订单系统->监听店铺状态,及时做出业务变更]：核心是Observer接口和Subject接口。将Observer的实现类注册到Subject。然后将Subject注册到某个业务Service中，让Controller调用该业务Service，从而让具体的Observer监听前端请求。

B.命令模式：整合Request和Response到一个Command中，通过实现Command接口，建立多个命令类。命令类整合到CommandService中调用。在Controller中通过不同的调用CommandService具体方法的顺序，次数与组合。即可模拟小红书的发布笔记/点赞/评论笔记功能。该设计模式使得功能之间的耦合程度更低，将来需要添加收藏/店铺等功能，只需要实现Command类，然后于execute()中完善业务逻辑，设计新的Request和Response，在CommandService中创建新的方法对应即可。

# 11.23日报

1.LC一道medium：合并后数组的最大元素。策略是从右往左合并。用sum表示右侧元素,nums[i]为左侧元素。如果sum>=nums[i]就合，否则就用nums[i]代替sum。

 2.六级新增20，复习150

 3.复习数据库考试

 4.设计模式：

 模板模式

 A.接收订单请求：无论是普通订单还是秒杀订单，首先都需要接收来自客户端的订单请求。 

B.验证用户信息：模板方法流程中的第一步是验证用户信息，这是所有订单处理的共同步骤。 

C.计算订单价格：接下来，根据订单信息计算订单的总价格，这也是所有订单处理流程中的通用步骤。 

D.创建订单：在系统中创建订单记录，这一步骤同样适用于所有类型的订单。

 E.特殊处理：这是模板方法中的一个抽象方法processorSpecificOrder，具体实现由子类提供。对于普通订单，可能涉及发货处理；对于秒杀订单，可能需要进行库存检查等特殊流程。 通过模板模式，这些通用步骤被封装在抽象父类OrderProcessor中，而特殊步骤则由具体的子类实现，从而避免了代码冗余，并提高了代码的可维护性和可扩展性。 

状态模式

 A.创建订单： 用户通过发送POST请求到orders/create来创建一个新订单。系统将订单状态初始化为"待支付"，并返回订单创建成功的信息。 

B.支付订单： 用户通过发送POST请求到orders/pay/{orderId}来支付一个订单。系统将订单状态从"待支付"转换为"已支付"，并返回订单支付成功的信息。

 C.发货订单： 在订单支付成功后，系统可以通过发送POST请求到orders/ship/{orderId}来处理发货操作。订单状态从"已支付"转换为"已发货"，并返回订单发货成功的信息。

 D.完成订单： 最后，系统通过发送POST请求到orders/complete/{orderId}来完成订单。订单状态变为"已完成"，并返回订单完成的信息。 

E.设计模式的作用： 整个业务流程采用了状态模式，它允许订单状态在保持对象结构不变的情况下，根据不同的状态改变行为。 状态模式通过将每个状态封装成独立的类，并在上下文（OrderContext）中管理这些状态，使得状态转换逻辑更加清晰和灵活。 当订单状态发生变化时，只需要改变上下文中的状态对象，而不需要修改上下文本身，从而实现了开闭原则，增强了代码的可维护性和可扩展性。

# 11.24日报

1.LC一道medium。喂饱仓鼠的排列：策略是先判定HHH中间，仅有H，HH头或者HH尾。然后给每一个仓鼠都放一个食物，接着判定H.H情况，一旦出现跳转两格并且在总食物数减1即可

2.六级新增20，复习122

3.复习数据库

4.设计模式-访问者模式，写代码，测试用例，输出博客，输出视频。

# 11.25日报

1.LC一道medium：贪心+交换次序

2.六级新增20，复习130

3.复习数据库

4.复习到有点身体不适了,很厌恶考试

# 11.26日报

1.LC一道easy：是统计将二进制数组m转化为k，且只能将1转化为0，需要转化多少位。策略是先将m和n做&，如果m&n==n，则用Java的Integer.bitCount()API统计m^k的个数，这个个数就是需要转化为1的0的个数了

2.单词新增20，复习130

3.知识储备新增：

A.设计模式的行为型暂时撒花了，常用的八个设计模式做好了代码实现+博客输出+视频输出

B.今天开始复习结构型设计模式，从享元模式开始，我比较喜欢从陌生处向熟稔处行进。

C.重构了设计模式测试项目的文件结构，在Controller Service Pojo的分包里面分别按行为，创建，结构建了新分包，这样不同隶属的设计模式代码的寻找速度更高。

4.写了3小节的离散数学作业，这一块12.29得提交，否则没有平时成绩，高数A上的笔记也要开始补了。

5.终于考完数据库了，无考一身轻。接下来就是每天渐进式的复习高数，离散，大物，概率轮，计组这几门课了。还得记着把马哲选择题和大题看看，思修得交实践报告，得去上课了。

6.近期的规划是把设计模式的基础打扎实，发觉放慢脚步的学习方式效果不错。我对设计模式的初次学习是通过阅读博客实现的，但是显然效果不佳，因为自己没有做相应的编码练习。这次通过编码+代码测试+文本输出+视频输出的策略，发觉掌握的愈发牢靠。很多的知识巩固是发生于输出时的，这是我应该谨记的。

# 11.27日报

1.LC一道medium：经典的环形数组问题。需要将一个长度为n的数组，展开下标到2n。通过下标取元素时用取模来规避数组越界问题。本题的创新点在于：需要辨别相邻两块瓷砖的颜色不同的连续k集合数量。这里我们需要在2n的(n到2n-1)区段才能进行集合数量的自增。原因是如果在0到n-1集合自增，会遗漏第n-1块瓷砖。因为这块瓷砖得跟第n块(真实数组中的第0块)进行比较。

2.六级新增20，复习102

3.复习概率论到古典概型

4.离散数学作业P1.4 P1.5 P2.1 P2.2

5.复习外观模式，输出博客，总结流程图，输出视频

6.看开源项目，学习新思路：密码加盐的具体处理流程

7.复习Mybatis-plus的CRUD操作，避免手生导致的肌肉性遗忘

8.听六级听力一套

9.发觉时间很不够用，需要推进的事情太多了，但是我的效率太低了。

# 11.28日报

1.LC一道medium:比较经典的记忆化+DFS板子题。题设是给定两个字符串，要求找到最长公共的子序列。注意两点：A.把字符串转化成字符数组考虑 B.子序列是有序的。DFS的两个参数分别为第一个字符数组的索引和第二个字符数组的索引，分别都从最后一个位置开始向左走。记忆化走过的路，如果走过该点直接返回。如果数组1的第i个元素和数组2的第j个元素值相等，说明是公共的，则i和j都往左边dfs+1。如若不然则贪心判别dfs(i-1,j)和dfs(i,j-1)。最后判定一下i和j小于0的边界case，遇到就return 0;

2.六级新增20，复习102

3.看概率论，推动一点点进度

4.离散写作业

5.设计模式：装饰器模式+价格在会员和优惠卷场景下的打折。这一块涉及到同一个接口的不同实现类注入，出现了循环依赖问题。折腾了一下午+晚上。最后的策略是用一个Config类注入@Bean，然后给DefaultPriceCalculator之外的装饰器都用@Lazy修饰，避免循环依赖问题。觉着装饰器模式的逻辑还是比较复杂的，卡了我许久。

6.看RocketMq的八股+实操经验

7.过一篇六级听力。

8.今天很累，由于代码Debug原因，几乎没有做休息。中午写算法卡了思绪许久，写完代码后考量到时间不够充裕，直接开始写设计模式的代码，但是又因为循环依赖问题的debug，空耗时间到三点四十，急冲冲的去一教上课。下课后想着bug还没解决，想先把问题揪出来，折腾到七点多终于解决，遂吃一份晚餐，接着把数据库的课设和实验的报告都整理+打印，随后整理和输出了装饰器模式的细节，整理思绪。余下时光慢慢看技术博客，做一些日积月累性质的学习。

# 11.29日报

1.LC一道medium：树形DP：打家劫舍的场景发生在二叉树上。我们考虑状态有两种：选择or不选择。倘若选择该节点，则状态转移方程为：rob=当前节点的值+该节点左子节点不选择的值+该节点右子节点不选择的值。倘若不选择该节点，则状态转移方程为：notRob=左子节点选or不选的最大值+右子节点选or不选的最大值。每层返回一个int[]{rob,notRob}即可。值得关注的是：我们考虑问题是从二叉树的最下层开始逐层往上考虑的，但是代码逻辑是从二叉树的最上层逐层往下执行的。

2.六级新增20，复习110

3.完成思政课程报告，注意十六周周一得交，两次缺到了，最后两节课必须得去了，不然真怕挂科了。

4.完成C语言实验报告，注意这个十八周之前得交

5.写了2个part的离散作业

6.看概率论，没太看进去，心神不宁

7.设计模式：适配器模式：业务需求：将前端发送的double数据修改为Integer类型。策略：抽象出适配器接口+实现适配器类。Service调适配器类,Controller调Service，输出博客，输出视频，项目归档Github仓库。

8.Docker拉取不到镜像的主要诱因有两个：其一是dns是8.8.8.8，这个需要在linux的resolv.conf文件中修改为114.114.114.114。其二是代理挂了，这个因素很波动，因为昨天配置在daemon.com里面的代理可能今天就不工作了，只能在需要的时候自己去临时搜今日可用的代理。另一个解决策略是在docker pull的时候直接注明来源的仓库，可以临时绕开镜像挂的问题：譬如用docker.unsee.tech/apache/rocketmq而非/apache/rocketmq

9.看Kafka，RabbitMq,RocketMq相关八股+业务场景，归纳异同，这一块内容较多。

10.六级听力一份。

11.感觉三十天备考六级+高数离散概率计组大物马哲思政的任务约莫有点重了。但是每日均一些时间备考吧，不然技术到位但拿不到学位证就幽默了。

# 11.30日报

1.LC一道easy。简单博弈论+分类讨论。给定一个数组，其中元素分两种，一种是个位数，另一种是十位数。有A和B两个玩家，二者只能选择取个位数或者十位数的累加和。且A是先手+永远选择对自己最优的策略。请问就输入的数组而言，A能否赢？既然A每次都选最优策略，也就是但凡个位数和十位数各自相加的和不等，天平朝一方倾斜，A都能拿到较大的结果，导致B只能选较小的结果，从而A赢。因此我们只需要考虑个位数和与十位数和相等情况return false即可，因为其他情况A都赢定了。这道题A下来蛮快的，约莫是两三分钟？

2.六级新增20，复习103.

3.离散数学作业part2

4.概率论：二维离散rv刷题

5.高数：极限的几种情况，洛必达，等价无穷小等一些刷题技巧。上次学这一块还是大一下开头准备转专业考试的时候。记忆的确遗忘许多了。

6.新增知识Kafka相关八股：架构/顺序写/磁盘结构/Partition负载均衡/Kafka劣势/and so on.

7.搭架子调依赖：把之前用于测试中间件的微服务架子的Eureka换成了Nacos,用GateWay替代了zuul。依赖这一块因为版本差异导致异常，花费了许久时间调试。

8.复习RabbitMQ知识：看文档，复习API。本地部署了一个RabbitMQ。遥想上回部署它还是九月份。

9.就电商下单业务场景写了MQ的Config+Client和Consumer的业务代码，太久时间不写业务代码手就会很生疏，这种纯唯手熟尔的活真得有事没事干一干，不然工程能力就慢慢退化了。

10.设计模式新增组合模式：场景是后端树化表达课程结构。实际上是在Pojo部分抽象出一个接口，然后提供两种实现类：普通节点和叶子结点。普通节点维护List,叶子节点不维护。然后于接口定义add,remove,getList,getName等方法。整合代码+输出博客+输出视频+push到github的repo。

11.六级一份听力。

12.明日主要任务是继续复习RabbitMQ,这一块的知识不够体系化,需要熟悉。

# 12.1日报

1.LC一道medium：给定一个数组，找到最小的，相同元素包裹的长度。策略是哈希+模拟。针对每一个元素，都将其添加到map中，然后如果之前已经存在map，则将二者索引作差，且保证左右闭区间，从而取到距离，接着对距离不断贪心即可。

2.六级新增20，复习103

3.设计模式：单例模式的七种情况，输出博客+视频+代码和笔记同步到repo

4.学习OAuth2.0：这个概念先前看过，但是没有做过实操。常见业务场景：前端登录需要向后端微服务的UAA鉴权服务器发起请求，账号密码正确则返回前端一个token。接着前端拿着这个token访问后端具体的资源服务器，资源服务器拿着前端传过来的token询问鉴权服务器这个token的真实性，如果为真则放行。上述描述的是同一平台场景。但是更多场景是：类似网易云音乐使用QQ登录：点击第三方登录拉取第三方的登录框，这里的请求是发给QQ的鉴权服务器，接着QQ鉴权服务器返回一个token给网易云客户端，然后网易云客户端拿着这个token去找QQ的资源服务器获取部分用户信息，资源服务器询问鉴权服务器这个token的真实性，如果为真，则开放部分数据给网易云音乐使用。

5.RabbitMQ继续深化：四种交换机，topic和direct都是针对routingkey而言的，fanout是给这个交换机绑定的队列都发。Headers比较特殊，需要维护一个hashmap，发送者和Config中的Queue的HashMap不匹配则无法推送消息到指定Queue(通过.whereAll().match())实现。其他部分的掌握较好，不需要额外记忆。

6.GateWay启动失败：多数场景是WebFlux与Spring-web存在冲突，在yml中配置web-application-type: reactive即可

7.Seata学习：分布式事务是我的薄弱点：这一块主要涉及到2PC,3PC.AX.AT,SAGA。2PC的问题：TC如果挂了，子服务上锁资源无限等待。3PC问题：网络分区导致数据不一致。AX问题：只适合单节点，不支持分布式，事务都是原子性的，不支持回滚，从而无法一致性。AT：补偿事务复杂性高，容易导致不一致，其次是只能提供最终一致性，无法提供强一致性。SAGA：一个较优方案，但是最终一致性和补偿事务复杂性问题依然存在。

# 12.2日报

1.LC一道medium：给定二维数组，返回一个最小数量，描述的是：让二维数组中的一维数组彼此之间不重叠。这道题很类似面试150题中的打气球问题。策略是：先就每一个一维数组的end索引做升序排列，先设定一个合规数量为ans,接着设定一个right，初始化为0号一维数组的右边界。接着迭代所有的一维数组，只要满足当前节点的左边界值大于right，则说明不存在重叠区间，则ans自增，最后n-ans即可。

2.六级新增20，复习103

3.离散数学复习

4.概率论刷题

5.技术学习：

A.Seata-TCC-银行转账场景

B.MySQL单库-读写分离集群-分库分表集群-分片算法

C.大厂为何做垂直分表？将高频字段和低频字段分离

D.缓存：客户端->应用层->服务层&一致性

E.大表涉及到分库分表为何禁用自增主键？A.范围法扩展困难 B.自增主键分布式环境的顺序问题

F.布隆过滤器在亿级电商场景的应用：A.预防缓存穿透 B.先预热 C.已经集成在Redisson中 D.通过对key进行hash+多个比特位从0到1的情况判定 E.判定不存在一定为真，判断存在有可能为假(哈希冲突导致)

G.京东开发为何禁用IP直连？个人项目和企业项目的区分点。A.简单策略用DNS B.企业方案是自建注册中心，譬如Nacos来统一管理多台Mysql服务器

H.CAP真实场景应用：CP：银行用的多，用户时延不重要，数据一致安全重要；AP：互联网用的多，数据不一致问题不大，但是用户响应必须得快；CA：小公司用的多，因为项目规模小，不存在分区容错的问题。

I.负载均衡器-四层LVS-七层Nginx-负载均衡策略：从轮询/权重/IP哈希/url哈希/公平模式

# 12.3日报

1.LC一道medium：旋转链表。启示：对于链表类题目，第一反应不应该是重新构造一个符合题设的链表，而是将当前链表改造为符合题设的链表，这样开销更小。对于本题A.不用重新构建链表，开销大。在原有链表上改变指向关系,除去三个特殊节点外，其他引用指向不变，开销小。 且若k%n为0，则相当于没转，直接返回原head即可。B.关注三个特殊节点 B.1.新链表的头节点,是原链表的n-k号元素 B.2新链表的尾节点,是原链表的n-k-1号元素,且注意尾节点next为null避免成环 B.3新链表位于原链表头节点之前的元素：一定是n-1号元素。 C.n为链表长度 k为旋转次数

2.六级新增20，复习112

3.复习离散/概率论/计组

4.总结jwt在分布式环境下的网关请求鉴权+子服务申请鉴权场景，输出视频。

5.项目学习：

A.阿里规范禁用外键约束的原因

B.Canal+MQ实现异构数据同步(数据先存MySQL，再同步到ES和MongoDB)

C.基于MHA实现的MySQL高可用

D.基于Sentinel的Redis高可用方案

E.阿里Seata场景(TC协调,TM全局事务,RM子服务内事务干活)

F.京东金融保障接口幂等性的策略(redis构建幂等表+RestFul请求触发AOP)

G.京东金融乐观锁解决并发数据冲突:版本号+Spring-Retry

H.阿里规范：超过三表不可join。需要join的字段数据类型必须一致！多表关联时，被关联的字段必须有索引

I.存储过程：银行使用，互联网不推荐。银行项目比较老，存储过程已经大量耦合在特定数据库中，迁移风险高。互联网强调解耦合，技术发展快，迁移成本低。

J.JWT-分布式场景

K.无状态的JWT令牌如何实现续签（不改token-存redis/改token-双token）

L.公共表如何在分布式架构下访问(下沉共性表,上浮业务表,多表服务注册中心连接,注解RPC实现CRUD)

M.凭借DNS轮询+VIP漂移-组合多Nginx+KeepAlived+多Tomcat确保架构高可用

6.明天继续备考期末+项目学习

# 12.4日报

1.LC一道Medium：双指针+原地处理。给定一个链表，要求组合成奇偶链表。策略是改变指向关系而不重新构建新的链表。这道题和链表排序比较相似，都是双指针+原地操作。

2.六级新增20，复习119。要考六级了，没怎么刷题，有点焦虑了。

3.复习离散数学/计组

4.项目经验：

A.Redis Cluster集群模式(集群和哨兵二选一：前者分散存，后者集中存。前者Raft，后者Gossip,切记最多1024x16个槽)

B.MVCC解决幻读——(Innodb之所以能在RR阶段解决幻读,是因为针对快照读提供了MVCC,对于当前读提供了行锁+间隙锁.当然,MVCC比后者弱,不能完全解决幻读)

C.宜信的架构演化过程（单体->垂直拆分(每个垂直模块重复了基础服务如MySQL)->无注册中心的IP耦合RPC通讯->昂贵的ESB总线(总线压力大，要抗通讯和注册)服务阶段->微服务架构）

D.Docker构建+部署Nginx+3个App+MySQL应用集群

E.蓝绿/红黑/灰度发布(蓝绿和红黑都是全量,灰度是增量/蓝绿和红黑都是有两套业务环境,灰度是一套业务环境/红黑和灰度都是逐步切换,蓝绿是直接切换)

F.MySQL索引的选择性陷阱（少用尾匹配和低选择性字段+使用Canal+MQ把异构数据导出到ES等搜索引擎进行处理）

G.替代JDK序列化的方案：SpringBoot内置的Jackson/Dubbo内置的Hessian/Google的Protocal Buffers

H.MQ中间件通用消息投递过程/丢消息情况分析：这一块的逻辑是：强调ACK作用+Broker先存盘+通讯没ACK就重发+注意Consumer幂等性。

I.京东的CI/DI：持续发布集成的策略(代码push到GitLab,带上maven和dockerfile/配置管理员通过Jenkins使用mvn package打包并根据dockerfile构建镜像,镜像push到Harbor（类似Dockerhub但是公司内网中的）接着Jenkins定期发布到K8s中,k8s逐步通过：测试区,UAT区,生产区。测试区开放网关给测试，UAT区开放给产品经理,生产区进行灰度发布)

5.期末复习九门，还有三十天，压力有点爆炸了。

# 12.5日报

1.Lc一道medium：以x为分界点进行重排序链表。策略是设定两个dummy节点，然后双指针即可。

2.六级新增20，复习109

3.刷离散真题

4.项目学习：

A.为何表的主键用代理主键(自增编号)而非业务主键(..身份证)

B.生产环境的JVM与垃圾回收的配置策略(JDK1.8优先用G1-G1不用设置新生代大小/-x基本参数/-XX涉及到GC选型和stw时间和日志打印等高级参数,是虚拟机特异性的)

C.线上排查OOM问题思路(1.先jps看线程总数 2.jstat -gcutil 17038 1000 10 一秒一次输出十次查17038线程 3.重点看老年代相关的OC和OU以及FC全GC情况 4.jstack 17038可以用,但是输出太不友好,我们换Arthas 5.curl下载Arthas 并且jar -jar运行 6.选择线程,可以在命令行看到界面查询了 7.heapdump /tmp/dump-1.hprof 7.下载到本地,load到VisualVM 8.发现类只有1w个,但是实例有100w个,且大部分是HashMap,右键进去,查看Gc-Roots,看和哪些线程相关 9.发现都和阿里云的Oss相关,在代码中排查相关部分 10.发现原来是连接Oss的Client连接一直没有删除,导致时间堆积的对象过多,调整代码,排查完毕)

D.消息积压与死信队列：每日十点前台获取单据的速度远超信审系统处理单据的速度->引发消息积压->避免消息丢失->引入死信解决

E.主键不可用UUID：UUID随机性->新增row随机插入->B+树无法预测位置,需要重新IO,IO开销大->B+树比较UUID大小,寻找合适插入位置->UUID若在中间某个叶子节点插入,会导致页分裂问题,并且需要树的重新平衡->造成慢SQL和IO开销

F.KafKa为何快？（1.磁盘顺序读写 2.页缓存 3.零拷贝 4.批量处理）

G.Cassandra列式数据库的高性能原理(用磁盘的图来记->行式数据库是按数据行连续排列,而列存储是按相同的列连续排列/读快更新难/版本号机制更新+逻辑删除+空闲删除)

H.微博大V更新的消息推送：Push和Pull区别（微信用Push所以限定用户好友数量）

I.动静分离：京东抗单页10wQPS的方案（把静态资源丢cdn+将部分动态数据存Redis）

J.医渡云：医疗大数据场景为何拥抱MongoDB而非MySQL？（1.医生处方无结构 2.新增字段不需要重启服务 3.支持自动分片）

K.MySQL模糊查询：Ngram替换Like（5.7.6提供ngram简单场景）/(create fulltext index以及select * from xxx match(content) against('测试'))使用match against匹配；

M.复习JDBC流程，写crud保持手感

N.复习Mybatis和SpringBoot的工作流程

# 12.6日报

1.LC一道medium：给定两个用链表表示每位值的数，求和。策略是构建新链表。首先建立dummy节点以及当前位置的累加和t。接着赋值dummy的next给一个tmp节点,这里考虑t的值大于等于10，因此填入新节点的数值是t%10。考虑到进位：因此t在每轮遍历后都得t/=10。最后return dummy.next即可.

2.六级新增20，复习109

3.离散数学刷题+看书补齐知识

4.Web2知识：

A.Raft选举算法(Nacos和RedisSentinel的原理)

B.基于ZooKeeper的临时顺序节点实现分布式锁(粗糙版本,直接用ZooKeeper对象链接)

C.Curator集成ZooKeeper解决超卖问题：使用Apache提供的客户端，更优雅。

D.BASE最终一致性：BA实质是牺牲纯粹的C,促生基本可用的A（用户以为执行完毕了，但是后台会慢慢干活）也就是所谓基本可用。S是软状态：三个服务的订单状态在短暂时间内可以不同，E是最终一致性，这是S的结果。

E.更新缓存不可用update！而是先写库再删缓存(线程顺序不严格,可能线程1覆盖线程2的修改,导致数据库和redis的数据不一致)，因此得用旁路缓存，先写库，再删缓存。有请求来了再从库同步数据到缓存

F.既然有了Redis和ZooKeeper这种分布式锁，为何还需要Seata等分布式事务？前者只关注互斥，后者满足ACID和回滚补偿修复

G.秒杀业务：Nginx+Lua+预先准备好的Redis秒杀表+RocketMQ

H.Sentinel：替代Hystrix的分布式限流工具（Sentinel实现：拦截器+责任链模式slot+客户端只接入pom依赖/在UI面板配置具体方法的qps或者线程数约束）

I.SPI-服务提供者接口：为Sentinel新增Slot-通过接口来扩展已有框架的功能,在框架中定义自己的组件,不需要修改框架核心源码

J.复习SpringBoot的相关注解，以及启动原理

K.复习Mybatis的CRUD，很生疏了。

5.Web3：

A.不用Remix了,在本地搭好了Solidity环境和hardhat测试环境

B.学习了简单的合约写法,实现了一个简单投票合约

C.对区块链的认知新增：hash相关的算法被大量使用+非对称加密，这一块和token很像。

# 12.7日报

1.LC一道medium：找出循环链表的环首节点。考虑到每一个ListNode有val和next两个属性，是独一无二的。可以用Set存储已经走过的元素。第一次Set.add添加失败的节点就是环的首节点。

2.单词新增20，复习103

3.复习大物,高数

4.工程学习：

A.Sentinel：如何熔断保护避免分布式雪崩(慢调用/异常比例/半开状态-限流-降级-熔断)

B.Reids热门商品访问倾斜的解决：商品被分片到多个Redis，单台redis只能抗5w,现在有10w qps,则新建Redis集群,全量存储热点数据,走负载均衡访问,这样10w qps稀释到每一个商品是10w/n 只要有三台机器就能抗住/另外可以在前端的localstorage临时存储或者在前端应用进程内缓存)

C.从ELK到EFK-KEFK-日志更新沿革:

- 多服务内嵌LogStash+ElasticSearch+Kibana `内嵌LogStashCPU开销高`

- 多服务代码耦合LogStashTCPSocketAppender依赖+统一发给LogStash+ElasticSearch+Kibana`LogStashTCPSocketAppender代码耦合大`
- 多服务Beats监听+统一发给LogStash+ElasticSearch+Kibana`Beats监听的导出数据单一化,不可导出到多个中间件,于是先导到Kafka,大家从Kafka读数据`
- 多服务Beats监听+统一发给Kafka+分发给LogStash（以及Redis等其他数据中心）+Kibana`部署成本昂贵`

D.预处理零宽空格问题：切记rollbackFor="Exception.class",否则回滚的条件过窄。@Transaction的回滚默认是基于RuntimeException的,倘若是ParseException则无法回滚

E.Paxos算法：两阶段/提议者-接受者-学习者/Raft是Paxos的简化版本

F.索引覆盖：海量数据大页码MySQL查询优化思路

G.预防XSS注入：SpringBoot策略：HtmlUtils和CSP规范响应头

H.RocketMQ：角色/生产消费流程/Broker主挂了怎么办?/Broker主从都挂了怎么办/NameServer挂了怎么办/同步复制与异步复制之间的区别和应用场景

I.MySQL执行计划分析(索引结构/回表/关键看Extra的MRR和index-condition,type一定一定要避免All的全表扫描)

J.驱动表-多表关联执行计划-MYSQL-小表驱动大表-只有在外键建索引有用-在查询字段建索引不会走查询优化器-大厂禁用三表联查也是避免表链接太多查询寻优化器工作失败导致慢SQL

# 12.8日报

1.LC一道medium：求集合的幂集。策略是双重遍历，充分利用已有的幂集合。

2.六级新增20，复习119

3.复习大物

4.项目学习:

A.本地消息表+定时任务+MQ：保证分布式最终一致性

B.基于Prometheus+grafana+TSBD的指标监控架构

C.日志分析：从springboot内置到logback/slf4j是通用接口

D.CDN+ELK+多ECS+Redis解决高并发贺卡应用流量冲击

E.事务消息：RocketMQ优化先发消息再写库导致的(库回滚+消息影响下游)问题：发送半消息/根据事务执行情况将半消息转化为最终消息or丢弃半消息

F.APM(应用性能管理)链路追踪-分布式系统调用链跟踪(A.Sleuth+ZipKin基于日志 B.SkyWalking基于Agent代理)(单次调用同TraceID,不同SpanID)

# 12.9日报

1.LC一道easy：按数组的每个元素的二进制含1个数排序。策略是先bitCount而后*100000+nums[i]之后排序然后取模10

2.六级新增20,复习117

3.复习离散，大学物理

4.工程

A.并非用了索引查询就快：扫描行数+回表次数决定速度。聚簇索引树与非聚簇索引树/覆盖索引/回表/索引下推

B.快手红包雨：场景题回答思路

C.银行ETL架构(提取,转化,加载)：核心业务域通过sqlLoader导出csv,隔日传输FTP,定时任务XXL-JOB提取FTP中的csv,通过ETL传输到ODS（数据集市）三方业务通过数据集市获取银行上一日的交易信息，进行储存分析

D.微信手机端(Token登录,封装设备信息)PC端扫码阶段(封装PC端设备信息请求二维码+手机扫码根据手机的token+二维码id=临时token+手机确认登录,临时token转化为正式token+token转发给PC端->PC端带着正式Token请求API)

E.阿里为何禁用Java内置线程池（Fixed和Single的阻塞队列无界限，多请求OOM/Cached和Scheduled无队列直接创建线程，线程太多也OOM）

F.RocketMQ保证消息有序消费的策略：(序号取模分队列/消费者每次只能与一个队列建立一个链接)

G.MySQL主从复制：BinLog和RelayLog都是存具体操作。异步复制：从不一定能收到BinLog/半同步复制(至少一个从和主全量同步)/全同步复制(基于MGR)

# 12.10日报

1.LC一道easy：给定两个十进制数，要求判定两个数的汉明距离。汉明距离是指两个二进制数，位一一对应，其中位不同的个数。基于概念：我们利用Integer.bitCount()，对x^y这个整体进行bitCount()。这里借助异或的定义：不同则1。也就是说：统计两个数的二进制位异或后值为1的数量就是汉明距离。

2.六级单词新增20，复习402

3.备考学习：

3.1静电场：

A.在复习静电场之前，需要明确三角函数的罕见部分。我们已知正弦，余弦，正切。实际上构成五边形，存在正割(sec)，余割(csc)，余切(cot)。对于切而言：仅有一组对应，且tanx=1/cotx。对于割和弦，我们采取交错的策略。有sinx=1/cscx，有cosx=1/secx。

B.其次要复习微分的定义：当存在函数y，实际上存在dy/dx=y`。这一点在大物下被广泛运用。

C.在接触正式知识前，还需要明确lamba(线密度),sigma(面密度),rho(体密度)。以静电场为例：λ=q/长度；σ=q/面积 ρ=q/体积。这三个符号不提前了解，直接进入静电场学习，会一头雾水。这是我的亲身体会。

D.静电场的学习逻辑是：场强->(积分)->电势。在该过程中涉及到高斯定理。最后需要提及一个环流定理：在保守场中E*dL=0

E.静电场需要掌握线段模型/平板模型/球壳模型/球体模型

F.明确高斯定理：∮S E⋅dA=Q/ϵ。这一块的Q花样很多，实际题目中要和上述提到的三种密度做多样的变化。E往往是被表达的量。A是与密度对应的单位。如果此时考虑的是圆柱壳面(半径为r)的壳外一点R。那A应该是2πrl，而σ=q/πR^2。我们做线和体的变化也是这个逻辑。

G.需要记忆：高中的k在大学被展开为了1/4πϵ。

H.实际上：电势的表达中，分母的r比电场强度少一个次方。感性认识是：U=E*d

I.在涉及到球壳类型的电势题目时，需要先算出内，中，外的E，接着根据不同的距离做积分，将积分结果累加。

J.双层嵌套的壳模型，里层壳的高斯面围绕的部分没有电荷，因为电荷在壳上，因此里层壳的E应该为0。而外层壳的高斯面要小于外层壳，因此外层壳的E实际是里层壳提供的。

K.静电平衡：内无电场强度，电场强度垂直于表面。U=C。

3.2磁场：

A.电场有电通量，磁场有磁通量，自然磁场存在高斯定理。但是正如静电场的安培环路定理结果为0，磁场的高斯定理值为0。这是由于磁场是无源场（有旋场），而电场是保守场(无旋场)。

B.高斯定理可以粗糙的理解成：某种通量*通量覆盖的微元面积=内部的总元素/元素常数。比方说电场的高斯定理，这个元素就是电荷量，因此常数是相对介电常数。

C.恒稳磁场的安培环路定理有效，B*dl的线积分=μ点乘（I的累加）

D.毕萨定律：dB=μIdlsin角度/4πr^2。这一块会涉及到几何关系的三角运算。我们的目的是将dl转化为d角度。我们会用到上述提到的比较罕见的三角函数来完成这个过程。这里一般涉及到两个角度。我们会令一个为0，一个为无限大。从而得到一个2倍效果。

E.磁场力的计算：f=ILB。Pm=ISn

4.项目学习：

A.选型虚拟机：为何优先用G1?（A.传统SerialOld在32G内存下性能堪忧,会产生几个小时的STW,一旦老年代GC了应用基本就挂了,而G1不做物理分代,物理上分区逻辑上分代,并发回收速度快/B.PS+SerialOld是全量回收,不回收完毕就一直STW,G1不一样,G1是小步快跑,先把小的回收了，大的暂时不动。STW最多不能超过200ms）

B.Redis大key导致的线上事故：单个key>512k。(set存储读过某本书的全部用户id,这一块如果有100个用户读,那没有问题,但是如果有100w个用户读过这本书,那么redis就会出现集群的倾斜)解决思路：首先这个set集合要缩减,我们只规定查看前100名读过该书的用户,也就是set容积缩减到100。其次是redis6.0的本地缓存（高频且不易变动的数据）,在服务里面缓存一部分数据,不必每次请求都访问redis。最后是用go写的rdb_BigKey去定期扫描大key，定期定理。

# 12.11日报

1.LC一道Easy：给定两个数，要求出二者不同位的数量。使用Integer.bitCount()+异或即可。

2.六级单词新增20，复习500

3.记忆计组的零散化知识，看王道书，刷题。

4.计组大题知识：

1.IEEE转化：切记二进制部分包含：S+E+M。对于三十二位情况，S一位，E是8位，M是23位。S直接用数字的符号判别，0正1负号。中间的E满足E=e+127。其中的e是2的阶，E是移的码。比方说给定二进制数： 1.10101x2^3。这里因为是正数，所以s=0，因为有1.M存在，尾数取10101。因为2的阶码是3，因此满足E=3+127。将E转化为二进制的130，然后用0和1组成SEM即可。注意M需要在末尾补0到第23个位置。这一块一般给的都是十进制或者十六进制，十六进制就直接划四个位置，十进制你得用8421码进行一个转化。

2.双符号位判溢出：两个符号位就0和1有四种可能性，两个符号位做异或运算。异或为1的情况就是溢出。比如00,01,10,11。这里的01和10就是溢出的。这里01就是正溢出，10是负溢出。你可以理解成：首位是1就是负，首位是0就是正。这里我们经常遇到[x-y]补码。也就是[x]补+[-y]补。比如x=0.11 y=-0.111.我们先转化为双符号位的原码：x=00.110 y=11.111。然后求x的补码：因为是正数，不必取反，直接+1有x=0.111。然后处理y补：11.000->11.001。**接着要注意：-y补并不是对y做除去符号位的取反，而是要全部取反后+1**，也就是00.110+1=00.111。最后[x]+[-y]有01.101。这就是典型的正溢出。

3.存储容量扩展：位扩展类似串联，字扩展类似并联，字位扩展就是又串联又并联。

- 原有1k x 4的存储器 （k一般是横向扩展, 后面的4是纵向扩展 从图片来看的话）
  - 位扩展后为： 1k x 16
  - 字扩展后为： 4k  x 4
  - 字位扩展后为： 2k x 8
- 容量为1K x 8位的存储器，地址线和数据线有多少根
  - 因为是8位，所以数据线有8根
  - 1K，K是2^10，所以有10根地址线。
- 用32K x 8位 的芯片组成一个 128K x 16位的只读存储器
- 数据寄存器和地址寄存器都看组合后的结果，但是需要多少个芯片就得做除法
  - 数据寄存器：16。因为组合后的地址是读16位
  - 地址寄存器：128K,首先128是2^7  k是2^10 那总共地址寄存器就是17位
  - 需要芯片的数量：128k x 16 / 32k x8 =8
  - 画出存储器的框图：
    - 因为是将32k组合成了128k，所以横向是4个
    - 因为是将8位组合为了16位：所以纵向是2个。
    - 然后左侧接CPU的上数据，下地址，因为32K实际上只需要15x2根。你这多的1x2根做片选信号，用来确定何时选择某个纵列

# 12.12日报

1.LC一道easy：判定某个数组中是否出现过至少一次的相邻元素或运算的尾随零。策略是快慢指针遍历相邻元素，然后对二者进行或运算。判定或运算结果是否为偶数，如果为偶数则直接返回true。最后在外层循环return false即可。最近备考压力太大，LC刷easy保持手感即可。

2.六级新增20，复习1000个

3.项目学习：

A.OAuth2.0的理解：OAuth2.0是一个标准，这个标准规范的对象是AccessToken的请求与响应体部分。OAuth2.0是工作在三方应用调用主服务资源的场景下的。最简单的例子就是用QQ登录网易云音乐。

B.ElasticSearch聚合分析-Bucket与Metric：通过Restful请求让ElasticSearch处理数据。坏处：由于是Json嵌套格式的请求，阅读和维护非常不易。

C.不用MQ如何保障消息传递的可靠性？（核心思路：重试+补偿）-(Spring-retry做重试/本地消息表/确保接收的幂等性)

D..一致性哈希解决MySQL的扩容问题(A.传统Hash在扩容后,需要对多个数据库中的数据重新Hash,重新分配,更改的数据量太大了！B.引入一致性哈希->构建一个长度为2^32 -1的环,将服务器分布在环上,按照数据的hash将数据放到环上,并且按照顺时针顺序将数据归属到若干服务器 C.但是现实是:服务器分布并不均匀,可能有某台服务器需要接收90%的数据,但是余下两台只用抗10%,这是真实节点的弊端 D.引入虚拟节点，虚拟节点一定是均匀的,同时建立虚拟节点和真实节点的映射表 E.业界目前没有成熟的开源方案,通常Hash算法需要自己写,或者用Google的CityHash/没有现成的迁移组件,也得自己写/集群的节点不固定,需要添加前置代理，这里可以用京东的ShardingProxy)

4.计组学习：

A.存储器相关：划分/指标/主存分类/刷新方式/主存容量三种扩容技术/并行技术/并行启动的两种方案/模块化存储器的两种方案/外部存储器：SSD和机械的差异分析/Cache结构/三种映射关系/替换算法/一致性分析

B.指令系统相关：指令格式与分类/指令寻址/程序机器代码表示/X86汇编助记符/Mips相关汇编助记符/CISC/RISC

5.明日计划：

A.上午清完日常+把计组进度推到CPU功能

B.下午和晚上冲刺六级单词+翻译+听力

# 12.13日报

1.LC一道medium：给定a,b,c。要求：对于每一位：a|b==c。如果存在不满足条件情况，要对对应的位进行翻转，统计总共需要翻转的位数量。策略是循环i,每次右移i位，同时右移结果和1做&运算。记录单词的bitA和bitB = 0。接着分三种条件判定：若bitC为0，则sum=1时候需要翻转一位，sum=2时需要翻转两位。bitC若为1且sum不为1时必翻转一位。统计最终的翻转位数返回即可。

2.六级单词新增20，复习300

3.复习模版+翻译+听力。

4.计组复习到CPU结构

# 12.14日报

1.LC一道medium，给定十进制数组，譬如[3,2,3,3,3,3]。找出连续相与为1的最大子数组长度。由于是子数组，因此必须连续。又由于要求最大子数组，因此这个子数组中的成员应该为整个数组中值最高的元素。我们先迭代找出最大的元素。接着重新迭代数组，在出现三方变量与最大元素相同时让size自增，其他时候size置为0。每次for时候都计算maxSize。最后return maxSize即可。

2.单次复习100，新增20

3.看计组，刷题。知识面已经覆盖了考试要求了，但是细节掌握的很差，需要不断细化。

4.明日开概率论+计组刷题。

5.感觉六级要寄了，已老实，这就是平时不练听力+只背单词的后果。

# 12.15日报

1.LC一道Medium，给定一维数组，求其中所有元素彼此的汉明距离总和。我们分两步做，首先用双层for嵌套，第一层为i起点，第二层j=i+1起点，两层的终点都是末尾索引。然后我们用Integer.bitCount来解决汉明距离的问题。最后将汉明距离做累计即可。我们回顾一下汉明距离：给定两个十进制数，将其转化为二进制数，从右往左依次比较bit，如果相同则不记录，如果不同则记录。也就是求两个数异或的结果。

2.单词复习100，新增20。

3.计组：刷题，看ppt，继续复盘。计组的知识体量过于庞大了，还有半个月的时间查漏补缺，这一块还是以今年的题库为主，以刷题驱动知识点复习。

4.概率论：二维离散/随机变量数字特征/中心极限定理与三种分布(卡方/t/f)/参数估计/假设校验。今天把概率论的知识点和例题都速通完了，明天开始刷往年真题，感觉概率论的学习痛感还是不大，可以说是对高数下知识+高中概率统计部分的延伸，比较难受的一点的是需要记忆一些枢轴量+各种概率的相关E,D。

5.项目开发：

A.单体->服务化架构(SOA)->微服务：ESB粗粒度划分服务，且总线昂贵负载高。微服务细粒度划分服务，不依赖总线成本低。

B.ProxySQL实现MySQL读写分离-基于MGR集群(基于集群+monitor用户+节点视图表查询节点状态+避免在应用中硬编码主单节点,导致主节点挂掉后无法访问集群.)

C.高可用架构的脑裂问题，Redis的解决策略（主服务器挂了,应用还在朝着主服务器写入数据,Sentinel选举了新主,此时旧主变从,得接受新主的RDB和后续的AOF,同时清空旧数据，导致主挂后的持续写入数据丢失。）(解决策略：设置min-slaves-to-write为1,以及lag为3s)（前者参数的意思是：只有1一个从库才能写入,当主挂掉后,其无从库,无法写入,避免了数据丢失,后者参数的意思是：从节点延迟时间超过3s后主节点将失去从,失去从的旧主节点无法被写入数据。）

# 12.16日报

1.LC一道medium：双指针法-找出数组的乱序部分，返回一个区间索引集合。思路是左指针找出第一个出现单调递减的索引，右指针从末端找到第一个单调递增的索引。然后如果left>right说明数组有序，直接返回有序的{-1,-1}。接着就[left,right]遍历每一个元素，如果该元素比left左侧的元素小,那左边界就要左扩张。如果该元素比right右侧元素大,则右边界还得扩张。

2.单词新增20，复习119

3.备考复习：

A.刷计组选择题，把题库选择题刷完了。

B.高数把七种极限归纳总结了，特别记忆抬高法和万能公式这两个，用的太少容易记混。看了点数列放缩。

C.复习C语言：这一块归纳平时写码忽略的知识。比方说转义字符（\a是发出铃声,\b是退格符,\f是换页符,\'和\
"都是符号.\t是水平制表,\v是垂直制表 \r是回车符）以及字符串相关函数(strcmp,strcpy,strchr,...)，这一块的共性是，如果涉及到dest和src，那dest一定是第一个参数，src是第二个参数。以及用字符串给char数组赋值的情况只能出现在声明时，你是不能对一个已经存在的字符数组用字符串赋值的。还有就是切记把字符串放到字符数组里面，不要忘记字符串的\0，比方说"abcd"要用5个位置存。文件操作的：fopen,fclose,fseek,ftell(a是append后面继续增加,w是写,r是读,这一块和Linux管理文件的权限逻辑一样的)。还有就是scanf的返回值是成功读取的元素个数，而printf的返回值是写出的字符数量，切记是字符数量。scanf放在if语句里面通常用EOF判断是否结束...C语言这块真的很零碎啊，对于这种不常用的语言，很多语言特性记忆起来很不自然。

4.项目经验：

A.MySQL主从复制：数据一致性的延时问题。MySQL读写分离后，先写后查如何保障一致性?（问题：数据写到主库后,马上需要读数据,此时默认从从库读,但是主库写入的数据尚未同步到从库,导致查询的数据不包含刚刚插入到主库的数据,出现了数据不一致）(A.延迟查询,等待主从同步后再查,缺点是高并发性能差 B.利用ShardingJDBC的特性,要求插入后的下一条select必须走主库,绕开了同步问题实现了一致性查询,C.MGR全同步复制,强一致性数据同步,在没有完成主从同步之前,jdbc.insert方法无法得到结果,从而阻塞后续的查询操作.从而查询操作有一定查询的是已同步的数据.缺点是MGR架构需要在服务设计之初考虑,成熟项目迁移成本大。)

B.Redis6客户端缓存-解决多级缓存一致性问题（A.多级缓存指的是实例内存有缓存,也用Redis做缓存 B.Redis集群通过Sentinel解决了缓存一致性,但是多个业务实例中的本地缓存是不同步的 C.传统做法是用RocketMQ接收某个业务实例发起的变更，将其推送到其他业务实例和Redis集群中,这样做增加了系统的复杂性 D.Redis6提供了客户端缓存,让Redis替换RocketMQ的缓存同步功能,Redis监听实例的缓存,在Redis发生更改时通知实例某条缓存已经失效 E.我们通过lettuce来接入Redis）

C.如何优雅保存MySQL数据变更历史(网dai的订单明细表)(A.首先否决订单双写,太重量级 B.既然存MySQL不行,那就存到异构数据库中去.通过把MySQL的binlog传给Canal,Canal通过订单id%n将Json写入MongoDB分片(这一块需要Canal拿到订单id去MySQL回查全量数据并储存) C.反范式设计灵活,与业务不相关,只需要在主键和时间戳上建立索引,天然支持Json,分布式NoSQL支持百亿数据)

D.瞬时流量洪峰保障系统不被击垮：Alibaba-Sentinel：系统预热流控(某接口的平时单机阈值QPS处于低水位，默认为1000/3(冷加载因子)=333，如果此时有瞬时大流量，Sentinel会通过预热逐渐将QPS阈值拉到1000，这样就为系统留出了缓存时间)

E.几万行Excel批量导入库如何优化：(A.数据表给身份证号加索引,选择性强 B.多线程分段写入Excel,将数据按身份证号分段,每一段数据用一个线程去写excel C.采取SXSSF这种流式API逐行写入,避免Jvm的OOM问题 D.JDBC批量操作)

F.Redisson的分布式锁实现-分布式锁不止setnx：(Reddison的底层是封装了加锁的lua脚本用于生成key/Redisson采用hash类型,客户端持有的形如lck_acc_000是一串哈希码,value是持有次数,且这个key-value有生命周期30s/持有锁的实例会启用watchDog,每隔10s给锁续期,避免锁内代码还在跑，但是锁没了导致并发冲突/由于value是一个数,所以Redisson是可重入的,在这一块和juc的reentrantLock设计很近似/我们以value的计数器实现可重入锁)

G.使用MySQLBench中集成的Visual Explain做SQL性能分析

# 12.17日报

1.LC一道medium：状态机DP-买卖股票的最大利润+手续费

2.单词新增20，复习120

3.复习计组

4.看了点python的库,写了两个简单的脚本,把小时候爱玩的游戏的活动速通了。大致思路是用pyautogui来模拟鼠标操作，类似脚本精灵，实现拖拽/自动挖矿。游戏的话，边界case比较繁多，本身写脚本是出于学习的目的，没有做太多的优化，仅仅实现了基本功能，代码传github上。

5.效率实在有点低下了今日。还是太放纵了。明日必须进入战斗状态。

6.基因法和倒排索引优化MySQL分库分表(A.基因法就是哈希法,将每个元素的最后若干二进制位选取为基因,比如有4个库,就选择最后两位为基因,00就进第一个库,01就进第二个库,10进第三个库,11进第四个库.缺点是数据库一旦扩容,迁移成本非常之高.好处是：可以快速确定非uid字段到底在哪个库中 B.倒排索引法就是引入Redis,比方说就邮箱而言,把邮箱做Key,将邮箱所处的db服务器名和邮箱的ui做value,这样也能确定某个字段所在哪一台服务器上.坏处是对Redis内存需求量高，如果SSD性能好也可以用innodb替代,其次就是注意数据库和缓存的一致性,要当心软状态时的数据不一致。)

# 12.18日报

1.LC一道medium：逆波兰表达式，使用Stack，遇见数字就入栈，遇见运算符号就从栈中取出两个元素，先取出的是num2,后取出的是num1,执行num1 OP num2，将运算结果压入栈中。循环往复，最终从栈中取出最后一个元素即可。

2.单词新增20,复习119

3.复习高数上：隐函数求导/参数方程求导/对数求导/微分/连续性/第一类间断点：可去和跳跃，第二类间断点：震荡和无穷/可导和连续关系->刷题

4.计组：二轮复习数制部分+指令编码部分/刷题库

5.工程学习：

A.Redis在项目中的设计规范（A.业务名：实体名:id/B.key不要超过39个字节/C.很好记忆：把回收策略分为两个段：前者是要回收的范围，后者是回收的规则/回收的范围有volatile:即将过期的 allkeys:所有数据/回收规则是：random/ttl/lru））

B.MySQL文库表优化-利用Json特性(A.对于在一个表中存储非标准内容：譬如书籍有出版社,作者/期刊有刊号,发行日期,采用宽表是不可取的,因此我们使用Json来存储这些非标准信息/B.在MySQL5.7以后新版本使用SQL语句查询Json中字段默认性能开销很高/C.我们采取虚拟列来一次性提取Json字段中的某一项,避免每次查询重复解析Json字段)。

# 12.19日报

1.LC一道medium：先求GCD，再用GCD求LCM。接着双层for循环，第一层for表示要跳过的元素，从-1开始，意思是存在一个元素都不跳过的情况。第二层是遍历整个数组，两个数彼此求GCD和LCM。并且做乘积。通过贪心选出乘积最大的存储在成员变量中，最后返回最大值

2.单词新增20，复习97

3.高数上：不定积分：第一类和第二类换元法/设t法|渐近线：水平渐近线/铅锤渐近线/求y=ax+b形的渐近线。

术内幕》：梳理ORM框架发展历程，复习Mybatis原理，新增对XML的多种读取策略以及多种ORM框架的异同

5.计组：指令流水线的：加速比/吞吐率/流水线效率计算|CPI相关计算,这一块切记程序执行时间是n个时钟周期|波特率计算和比特率计算/虚存相关

6.马哲刷题1.5个单元

7.总体效率不高，娱乐时间较长，明日还是强化计组+高数上+大物+马哲。明日计组最后一节课务必要去。

# 12.20日报

1.LC一道medium，埃氏筛求范围内素数个数。策略是先设置一个长度为n数组，然后默认数组所有元素都是素数。接着i*i<n遍历做为桩子的数，每一个桩子内，用桩子的平方为起点，用桩子的大小为步长，所有包含在步长内的数字都设置为非素数。最后遍历整个数组，在元素为素数的值遇见时做count自增即可。这里要切记：最小的素数是2，因此你得先判断n<2情况，一旦n<2就得直接return 0。

2.复习计组：波特率原理/复习数值计算/总线相关机制计算

3.复习离散：把一二三单元的书和例题看了一遍，增加对数学归纳法和2^n是n长度集合的子集数的认识(用01特征集合)

4.大物：干涉相关/光程计算/相位差计算/干涉图样判别(偶数亮,奇数暗)/算平均光强,式子就是两个光强按照矢量方式叠加(这里相位就决定了是`(A1-A2)^2还是(A1+A2)^2`，也就是所谓的亮和暗)/可见度计算(V=Imax-Imin/IImax+Imin)所以Imin为0效果最好，Imin=Imax基本就不可见了。I的计算也是矢量加法

5.马哲刷题

6.C语言细节知识点：A.switch可以用int long char 以及enum/B.switch中case1：case2:printf("");情况下，出现case1情况因为没有遇见;所以会执行case2的命令/C.C语言中char是一个字节，务必不要和Java弄混/D.p[-1]是绝对的未定义行为，哪怕p是&arr[5]。也不能用负数的形式去查询前一个元素/D.C语言文件有：二进制和文本类型

7.今天娱乐时间过长了，这是堕落的开端。要复习的课程太多了，工程知识完全被落下了，只能寒假拼命冲进度了。务必清醒，保持战斗状态。

# 12.21日报

1.LC一道easy。判断一个数是否是2的幂次方。两个策略：A.比较对n和n-1进行与运算，如果结果为0则是2的幂次方，这是通过观察规律得出的。第二个策略是遍历n的所有因数，判断除了1之外的因数是否都是偶数，如果有一个数不是，则判定n不是2的幂次方。

2.单词新增20，复习119

3.复习大物 ，刷了四节习题：二次复习静电场相关

4.复习离散：刷了两章习题：齐次递推公式/入度出度图求法/布尔矩阵求法/关系相关

5.复习高数：把不定积分的第二类换元法看了看，复习了六个三角函数的转换关系。关于第二类换元法涉及到的代换：很好记忆，a^2开头的就是弦和切，遇到-，-小就匹配x=asint 遇到+，就匹配大的x=atant。剩下一个x^a开头情况，弦和切都有了，还有个割，因为之前都是正，所以现在用余割 x = asect。然后还有正切方+1=余割方 余弦方+1=正割方。以及相关的一些做题技巧。

6.复习概率论：这一块就是纯把之前过了一遍的概念和例题又过了一部分，没什么好陈述的。

7.工程训练：RocketMQ消息存储与检索原理(A.RocketMQ使用CommitLog存消息,一个log文件存1GB,顺序写盘。B.检索消息有两种策略，一种是用发送者决定的MessageId查,这种是精准索引查询,另一种是用消息的Tag查,这种是分类筛选过滤 C.了解RocketMQ文件结构,以及消息通讯时,相关中间文件的转化)

# 12.22日报

1.LC一道easy：给定一个数组，将数组中所有的0都移动到数组的尾部。通过这题复习了冒泡排序。这段时间太忙了，只能写easy保持下手感了。

2.单词新增20，复习97

3.复习大物：写了两节习题，一节静电场介质，一节恒稳磁场。

4.复习高数：继续不定积分，刷题。

5.复习离散数学：二轮复习了函数的定义部分，以及相关的矩阵运算，以及对称/传递/闭包/自反等概念。

6.复习计组：二轮复习存储器部分的记忆性知识，复盘了几种经典计算题。

7.复习概率论：二轮复习到一维连续部分，主要是看题+刷题。保持记忆活性，避免学过的知识在考试前遗忘。

8.工程训练：

A.细化了RocketMQ关于消息有序消费与死信队列的实现策略。（技术内幕这本书的质量真的很低，如若不是没有更好的原理书，我是绝对不会去读一本错字颇多的教程的。）

B.顺序消费相关：1.全局顺序[同一个消息队列中的消息按发送顺序消费,无论来自哪个生产者]2.局部顺序[基于类似消息键值的条件,相同的消息被发送在同一个队列,确保在该队列内的顺序消费]。具体来看，RocketMQ是确保相同消息键的消息路由到同一个消息队列。底层是根据Key来计算哈希值。齐次需要考量消费者，顺序消费情况下，一个队列只能有一个消费者处理。避免多消费者同时读取并消费该队列信息。最后就是消息的Offset，消费者得定期给Broker回报当前消费偏移量，确保每个消费者消息偏移量是顺序的，避免错过消息和重复消费

C.死信队列相关：首先明确消息是存在CommitLog和ConsumeQueue中的。其次消费者对死信队列的消费有两种策略，前者是Pull，后者是Push。终点都是消费者，区别在于这个消息是主动拉取的，还是被动推送的。这一块和RabbitMQ差异性不是很高。

# 12.23日报

1.LC一道midium，三色排序问题。用快排做。A.先写swap函数 B.快排的精髓就在于写partition函数实现基于某个pivot的分区，比pivot小的元素放左边，比pivot大的元素放右边，这一块用双指针写，最后返回pivot的索引。C.写一个递归，从0到nums.length-1进行类似前序遍历的操作，先用partition求出pivot节点，接着对pivot左右两侧的段继续切割细分。

2.单词新增20，复习97

3.离散复习：格与图相关，WireShall算法，刷题

4.计组：看存储器相关记忆性知识点，手搓连线ROM字位同时扩展框图。A.用8位片合成16位，在数据线部分，得分高位片和低位片，连线这一块得注意。B.在地址线部分，每一个小片都得连单片的所有地址线 C.合成新片的多余地址线是接译码器的，比如2-4,3-8。然后这个用来做片选信号，每一个片选信号对应一个合成芯片。D.不要忘记每一合成芯片都要链接上A/W线。

5.大物：恒稳磁场部分，刷了两章节题。主要是温习安培环路定理和求磁力矩。

6.概率论：二轮复习一维和二维的连续和离散。

7.工程：RedLock相较于setnx的优越性(A.setnx设置的锁在主从复制时无法被查询,此时有额外请求设置新锁,会导致锁被重复获取,产生并发冲突 B.RedLock本质是让多个Redis实例同步保存一把锁,每一次的查询和新增锁都需要半数以上的实例同意,借鉴了选举算法.其中锁的key为uuid+数字,支持可重入.C.锁的释放分两种情况,一种是hincrby-1这是针对可重入锁做的释放设计,另一种是直接del,这是针对仅单次持有做的设计D.Redisson提供了RedissonRedLock的API,只需要在创建的时候传入若干个RLock即可,至于tryLock和unlock和setnx锁没有太大差异

# 12.24日报

1.LC一道排序，手撕堆排序。题目需求给数组做升序排列。A.先构建大根堆，堆本质是完全二叉树，且存储在数组中。因此根节点索引是0，每一个节点的左子结点是i*2+1，右子结点是i*2+2。B.通过递归+交换局部堆中元素，保证在局部堆中父节点值最大。C.在解题方法中从i/2-1位置，也就是第一个非叶子结点处开始从下往上构造堆。D.构造堆成功后，此时整个数组已经降序排列了，且整个堆是在整个数组上有效的。因为我们需要升序排列，因此不断交换0索引和一个右指针索引，每次交换后右指针左移，这样堆的有效部分不断变小，但是左侧堆有效就保证了0索引一定是这个堆中最大的元素，从而实现不断的交换，最终数组升序，堆完全无效。

2.单词新增20，复习110

3.离散看了偏序格的判断：代数格是用析取和合取对应的LCM与GCD来判断是否格存在。而偏序格是看最小上界和最小下界。容易出错的是：误以为在上方就是代表大于，实际上：你得看两个元素是否相连，如果A元素在B元素的上方，但是二者不直接相连，二者是不可比的，这种不可比就造成了偏序格的不存在。

4.C语言看结构体和文件部分的API细节，这一块差异性太大了，C语言用的太少，真就死记硬背。

5.计组补充虚页和实页转换->通过页长取出虚页实页共有的页内偏移量，用页大小和存储空间大小做除法来算有多少个页，然后根据页是2的多少次方判定需要多少个位。把页的序号和页内偏移量组合就是页的地址格式。

6.马哲没看多少，模考了几次都是80多分。看来高中政治底子还没忘完。

7.工程实战：Docker五种网络模式与应用场景(Bridge(默认)-(外界8080:容器内8081)/host(构建单服单机)/container(构建网关应用合适)/none/自定义)

# 12.25日报

1.LC一道medium，需要在O(nLogn)计算相邻元素的最大差值。使用桶排序完成。A.寻找M和m两个元素 B. 计算d=M-m+n-2/n-1，将桶的理论宽度计算。C.根据d计算桶的个数：根据桶的个数构建二维数组，第一个维度是索引，第二个维度长度为2，用于存储该桶内最小值和最大值。D.填充数组元素进桶，同时根据其值与已存在元素的比较，填充桶的最大元素和最小元素，这一块预先给最大位置设定了min值。E.使用ans记录最大差值，从0索引开始计算上一个桶最大值和本桶最小值的差，不断贪心最大值。

2.单词新增20，复习101

3.课业：

A.大物：完成四章习题，主要覆盖电磁感应部分，复盘公式

B.计组：硬布线和微程序。值得注意的是：【CU】是核心，【节拍发生器】和【操作码译码器】与【形如EX的触发器】都是围绕【CU】工作的。/而存储控制器是微程序的核心。简单来说，可以理解成解谜游戏。第一个抽屉拿到一张纸，这张纸说你要开第二个抽屉，并且其中有密码，你需要输入密码按下按钮。这张纸就是机器指令，人脑就是控制存储器，我们翻译纸上文字成若干个微指令构成的微程序，然后逐个执行微操作。

C.概率论：刷题/题写少了。

4.工程：

A.对Optional的认识提升，写了简单demo。

B.短连接的本质是：建立一个【长连接】和【UUID前x位】的映射，每次请求短连接都从Redis中取出对应的长连接部分并拼接，然后走302重定向到具体服务。这里可以用Hutool的UUID生成器取前8位。比如http://test.com/shop/sku1 可以通过http://test.com/edfegh1访问。这种技术在站外分享应用比较广泛。

5.我的复习还是太眼高手低了，具体落实在做题能力上，发现还有很多不足，幸好还有时间，可以弥补。

# 12.26日报

1.LC一道medium。一道01背包问题。场景是将数组分割成和相等的两个整数部分。A.先判定原数组和是否为偶数，若是奇数则return false，因为奇数没法拆成两个整数部分。B.用DP做，维度1是当前遍历到的数字，维度2是截止到当前的子数组累加和，dp的类型是boolean。C.dp开始前初始化s为s/2。因为子数组的终极目标就是确保自己的累加和为s/2。D.状态转移方程：`dp[i+1][j]= dp[i][j]||(j-nums[i]>=0&&dp[i][j-nums[i]])`意思是i+1状态满足子数组和为j，且只有两种情况可以转移过来，一种是在i就满足子数组长为j，摆烂一轮直接转移过来，另一种是恰好在i位置还缺nums[i]就能让长度到j，加上这个长度就转移过来，这类是比较勤奋的。E.最后return `dp[n][s]`即可,切记此时s是原始s/2。DP初始化为true记得做。

2.单词新增20个，复习97个

3.课业：

A.从下午两点到晚上十二点一直在看概率论，之前速成的概率论还是太草率了，得认真把教材的定义和推导过程理一遍。这一轮下来，把先前许多死记硬背的点给逻辑化了。

B.休息时间看了点计组，聊胜于无。

4.工程：

AT/TCC/SAGA/XA四种分布式事务模式差异性分析（ AT模式：轻量级，适用于传统关系型数据库，自动生成 undo/redo 日志，适合简单的事务场景。TCC模式：通过分阶段的 Try、Confirm 和 Cancel 操作来管理事务，适合复杂的资源预留和回滚场景。SAGA模式：将长事务分解为多个小事务，并使用补偿来保证一致性，适合长时间运行的分布式事务。XA模式：基于两阶段提交协议，适合严格一致性要求的场景，但实现较为复杂。）

# 12.27日报

1.LC一道medium。手撕LRU。LRU就是双向链表+Map。这题我手写了双向链表，主要实现【头部添加】【删除】【删除尾部】【移动到头部】四个辅助函数，接着就是查询元素，如果命中则移动该元素到头部。新增元素or修改元素值也移动元素到链表头部，然后判断当前新增是否导致size>capacity。如果大于就删除链表尾部元素。

2.单词新增20，复习97

3.把概率论又过了一遍，从两点到十点。

4.工程：

A.100.[图书查询场景-Redis查询图书+记录用户查询行为到MySQL:写速度慢造成了抗QPS能力低]同步转异步，单条转批量：QPS优化从2000到8000

B.从计数器到令牌桶，四种经典限流策略(A.定长窗口有毛刺(秒的间隙同时发生200次请求-原本设定1s内只能有100次访问)现象B.滑动窗口通过细分定长窗口,减小毛刺现象概率,但是内存开销高C.漏桶算法,将请求放到队列,后端按1/qps时间消费,问题是均匀消费导致突发流量无法处理D.令牌桶算法:后端均匀                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  生成令牌,空闲时的令牌可以供高并发的请求用.)

5.明天得把大物进度推一推了。

# 12.28日报

1.LC一道medium：复数乘法。涉及到两个点：A.使用`//+|i`对字符串进行split，得到纯数字数组。B.(ac-bd)+(ad+bc)i计算即可。顺带复习了Integer.parseInt方法。对我提升最大的一点是：复习了正则and复习了复数公式这个零碎知识点

2.单词新增20，复习103

3.期末：

A.把微积分上册的知识整体梳理了一遍，将一些考前需要记忆的公式温习了，做了部分题。

B.将概率论的知识点和题目进行了温习，这个学的时间太近了，没有时间沉淀，需要保温。

4.工程：

A.实例端负载均衡器相较于服务器端负载均衡器的优点：实例前套一层Nginx集群，维护比较困难。一方面是集群扩容不是动态的，得全部停机改配置文件。另一方面是Nginx自身不支持集群部署，你得结合KeepALived实现Master和Backup之间的转移，然后你还得租用DNS，将你的若干台机器的虚拟ip都填到DNS里面，让用户通过某个域名来轮训你的多个Nginx节点。架构设计太复杂了。实例端负载均衡就是Ribbon之流，先去注册中心拉取一个所有注册的实例名单，对着这个名单去Restful调用就行。在低并发环境下，比较节约成本。

B.把KeepAlived的部署做了学习。

C.把滑动窗口限流的思路又重新学习了一遍。

5.总结与展望：

A.大物明天必须继续动工了，目前的进度是到电磁感应，但是题目和模型并没有高掌握度。

B.把离散数学根据老师划得新范围进行整理。

C.时不我待，效率低下啊今日。

# 12.29日报

1.LC一道medium：判定`a^2+b^2==c`双重for会超时，于是更改策略：单层for(用Math.sqrt(c-a^2)表示b)同时修订a*a<=c/2作为新的for区间，实现时间复杂度的降低。
2.单词新增20，复习97。

3.期末：

A.看光学：效率非常低，写了两版练习册+整理模型推导过程。大体来说：杨氏双缝与加玻片的题目变式/等倾干涉/等厚干涉/迈克尔逊干涉仪相关的模型，以及涉及的计算量推导。我对这一块的知识接受速度很慢，居然只学了这么一点。

B.看电磁学：把磁场+电磁感应部分的模型回顾一遍。高斯/安培环路/毕奥萨伐克/磁矩与磁力矩/矢量叉乘V x B的应用->判定电流源方向/感生和动生->感生这一块就是E在l上的积分和磁通量在时间上的变化量相等，要切记磁场的范围半径r和积分L中的R不一定相等，如果这是一个圆的话

C.把概率论的矩估计和最大似然估计复习了，后面那部分得每天看看，不然真容易忘记。矩估计左侧是μ，最大似然在ln后求导==0。目的都是求出(类似角度的符号)/看了点前面的三大分布。

4.工程：

A.认知了minio，拓展了对-对象存储系统的认知。(A.1:高可用+弹性伸缩+分布式确保数据冗余和高可靠 A.2类似云存储体验，但是价格低廉，毕竟本地搭建 A.3涉及：对象，对象桶，端点，AcessKey和SecretKey,A.4写相关的工具类干活即可)。体验感和阿里云的oss差不多，胜在自己搭建没什么开销，小规模的访问量，性价比是很高的。这个点可以拓展到视频平台上，用户上传的视频传递到minio中，用户的获取也是调用minio的API进行获取。对于存储非结构化数据是高效的。

5.明天就要课设了,真是屋漏偏逢连夜雨啊,沟槽的考试周.

# 12.30日

1.LC一道medium，二维数组-排序-排队-LinkedList。第一个维度是身高，第二个维度是前面有i个比其高的人。我们先对身高做降序排列，然后就第二个维度做升序排列。接着在LinkedList中按照第二个维度插入一维数组即可。这里切记：我们一定是先做身高的降序排列，再做前面有i人的升序排列。且在此之后方可list.put(i,p[i])。这是因为如果list为空，你put(i,p[i])进去，查无此i，会报错。

2.单词新增20，复习113

3.备考：

A.微积分：变上限积分的求导：将上下限函数分别放到原函数的自变量中，再将原函数乘上一个其导数。注意：上限为正，下限为负。/无穷小判别：等价无穷小-同阶无穷小-高阶无穷小-低阶无穷小。都是f(x)/g(x)在x趋近于0取极限。我们只看分母部分，如果极限为0，则g(x)是低阶，如果极限为无穷，则g(x)是高阶，如果极限是1，则g(x)和f(x)等价，如果极限是C，那g(x)和f(x)同阶。

B.大物：单缝衍射/光栅衍射/光的偏振计算/牛顿环/斜陂/电磁感应计算题/磁场强度or磁感应强度相关/双反射与光轴...and so on.

4.工程：

A.RBAC场景：电商平台的权限分层设计。A.用户表，角色表，权限表。两两之间设计关联表。实际判定某用户是否可以执行某操作时候，应该是通过userId先去关联表查其所在的role，接着遍历其role内的若干permission，判定有无符合要求权限。

B.API错误码设计：（traceId|模块错误码|错误信息）整合Sleuth(用于生成TraceID)-实现分布式-多模块之间交叉调用过程中-快速定位异常模块。

5.总结：效率较低，大部分精力在复习物理。

# 12.31日

1.LC一道medium，给定八个值，共四个二维坐标，分别表示两块矩形的左下和右上。要求出两块矩形的面积之和。这里需要考虑两块矩形的面积相交部分。由于在二维平面坐标系中，矩形的x或y坐标可能出现在负数位置，且因为覆盖矩形的每一条边都要“靠近原点”因此对于正半轴的x或y，必须取较小值，对负半轴的x或y，必须取较大值，目的是让两个点构成的线段尽可能短（通过两个端点尽可能趋向于原点来实现）。这里相当于是二维容斥原理，也就是两个集合的并集减去两个集合的交集。

2.单词新增20，复习97

3.期末备考：

A离散数学：树/图相关的习题，看书刷题。

B.微积分：二轮复习极限部分，这一块之前的资料提及较少，需要强化。

4.工程实践：

A.基于Java与ES7实现多条件复合查询：复盘ES的添加/查询等操作,同时复习相关Java客户端的API-以博客平台的推文管理为例：新增推文/删除推文/按tags推文查询/关键词推文查询/分词器相关

B.使用EasyExcel实现将数据库数据-【商品SKU】与【销量数据】导出到excel文件，用户通过RestFul请求来下载该文件。延伸一个思考点：如何优化导出性能？解决策略：多线程处理+单次读取中，数据 存入List，充分利用实例运存做数据缓存，减少读写时间。

C.学习jira操作，对开发人员在项目工作流中的工作流程有了新认识。

5.复盘与展望：

A.总体来说，今日效率处于均值之上。但是晚上效率较低，娱乐时间较长，这一点是和我备考期末的状态相悖的，明日需纠正。

B.微积分部分,还有许多细节需要挖掘

C.明日需要将马原和思修进行复习,马原问题应该不大,吃高中老本没看书,选择题能做个80分,但是还得稳一稳,唤醒一下沉睡的思政记忆。

D.辞旧迎新,过往的一年半中,我近乎放弃了所有的娱乐,运动与爱好。通过卷绩点从教技转到了计科，在确保科班身份的基础上，我将更多的时间投注于工程知识，也取得了一定的增量。但是过往的竞争与沉淀，都是局限于一所双非院校的。更残酷的竞争会发生在25年的实习投递。我想，在接下来的一年中，我需要稳定心态，心平气和的面对每一场面试的失败，从中汲取经验教训。就目前的状态来说，我的心态是欠缺的。我需要更坚韧的心灵去直面一次次技术面的拷打，我需要更清醒的大脑去实现现场代码的手撕。新的一年，保持情绪稳定，准备进入战斗状态。

# 2025年

# 1.1日报

1.LC一道medium。给定一个数组，求该数组的幂集。形如[1,2,3]，输出为[[],[1],[2],[3],[1,3],[1,2,3],[2,3],[1,2]]的状态。我们尝试使用回溯来完成。回溯方法入参分别是：数组，当前所在的数组索引，子数组，用于存储幂集的集合。回溯的核心思路是复用子数组。我们会从当前数组索引开始for到数组最后一个元素，同时做三件事，第一件事：将当前数组指向的元素添加到子数组中，第二：我们直接递归调用这个方法，同时传递进去的索引+1，第三：程序运行到递归方法之后，则删除掉存储幂集的集合的最后一个元素。同时在for外部要将上一次的子数组添加到存储幂集的集合中。这样：我们最开始是拿到[],然后是[1]，然后是[1,2]，然后是[1,2,3]然后发现不能往后走了，于是执行在递归后的那行删除元素代码，也就是实现回溯，从而[1,2],发现2可以往后走，于是就[1,3]发现3不能往后走，于是就删3，删1，接着成为[2]然后[2,3],然后删3，删2，然后[3]。这样就完成了，回溯的本质就是不断的修改子数组，对齐复用。

2.单词新增20，复习113

3.备考：

A.复习微积分：主要是看极限和连续以及求导部分的题目，刷题巩固。

B.复习马哲资料，这一块以复习高中知识为主，开销时间较小

4.工程：

学习某分布式电商平台的项目源码，有如下几点启发：

A.对传统的三层架构再细化：

- VO
- DTO
- BO（Business Object）：业务对象，内部业务对象，只在内部传递，不对外进行传递。
- Model：
- Controller：主要是对外部访问控制进行转发，各类基本参数校验，或者不复用的业务简单处理等。
- FeignClient：由于微服务之间存在互相调用，这里是内部请求的接口。
- FeignController：主要是对内部访问控制进行转发
- Service 层：相对具体的业务逻辑服务层。
- Manager 层：通用业务处理层，它有如下特征：
  - 1） 对第三方平台封装的层，预处理返回结果及转化异常信息，适配上层接口。
  - 2） 对 Service 层通用能力的下沉，如缓存方案、中间件通用处理。
  - 3） 与 DAO 层交互，对多个 DAO 的组合复用。
- Mapper持久层：数据访问层，与底层 MySQL进行数据交互。
- Listener：监听 `RocketMQ` 进行处理，有时候会监听`easyexcel`相关数据。

B.文件上传：通过分配token给前端，让用户直接上传给minio,比走后端更节约流量

C.防止Xss攻击的思路：common模块设计Filter，对前端传递的参数进行转译，让其从标签转化为文本，失去脚本功能。避免将恶意注入的js代码直接存库，并且直接渲染到前端的页面上，导致用户信息被窃取。

D.我们通过封装Jsoup(解析html文本)实现特殊字符的过滤。一般来说：Filter主要干两个活：一个是AuthFilter，对用户权限进行判别，其次是XssFilter：对可能出现的注入信息进行转译，消除其script标签，让其无法作为js脚本工作。

E.一个管理外部接口的小巧思：比方说Search模块，肯定是要关联MySQL和ElasticSearch的。那就会涉及到异构数据转化，那必然涉及到es客户端和canal。那就可以用Listener包来囊括这些中间件的通讯。同样的道理，下单模块的功能需要异步执行，那为了削峰填谷的考虑，肯定得上MQ，那MQ的接口也可以包在Listener中。再考虑到一些埋在每一个实例的监视器，比如做日志收集(不是最佳策略)得用LogStashTCPSocketAppender，这种和外部LogStash通讯的类，也可以包在Listener中。

# 1.2日报

1.LC一道easy：给定数组，找出仅出现一次的数字。哈希法计数+统计即可

2.单词：新增20，复习98

3.课程：

A.上午继续看高数：把求导和微分部分看了，中值定理与泰勒公式。发觉做等价无穷小替换的展开，可以用公式推，可以减轻一些记忆量了

B.下午计组课设验收，折腾许久

C.晚上复习三小时概率论，二轮2/3

4.工程：

A.关于Java工程接入本地大模型，有两种思路。前者是SpringAI：需要升级JDK到17。考虑到大部分商业项目的JDK版本还是8，可以考虑用AI4J来接入api。

B.了解部分知识，使用PineCore部署模型，通过调用Service将本地文本，形如【法律条文】转化为向量，存储到pinecore。并且通过AI4j接入pinecore服务，实现搭建简易的AI问答平台。这是一个ETL过程。

C.了解RAG：相较于通用模型而言，RAG更安全，通过增加本地知识库，实现局限领域的高效回答。

D.关于Embeding：将文本/图/视频转化为浮点数数组->矢量。计算两段文本向量的数值距离来确定相似性。

E.自定义模型思路：微调/Prompt Stuffing/函数调用(更新陈旧知识)

5.总结与展望：

A.备考复习效率不高。

B.对类gpt模型的认知较少，寒假需要摄取更多的模型自定义知识，本地知识库可以作为一个加分点缝合到项目上。

C.今天算是实现了对大模型的扫盲认知了。本来计划阅读更多，考量到期末备考压力，只好搁置了。

D.mujica第一集怎么这么爆。哎，可怜小祥。

# 1.3日报

1.LC一道medium：找出第k个丑数。A.先用优先队列构建堆，凭借堆的特性让最小的元素排在堆顶，我们每次取堆顶的元素，就是按照顺序元素取元素。B.设计Set实现去重，每次从堆中取到的元素，分别x2 3 5构建新的丑数，如果set尚未找到重复元素，则添加该元素进堆，让堆将这批元素中最小的丑数放在堆顶，周而复始。最后我们return最后一次取出的堆顶元素，这元素就是丑数。

2.单词新增20，复习95

3.课程学习：

A.高数：定积分应用/不定积分的求解->刷题

B.离散：复习重点，今年离散的考点太生僻了吧。

C.计组：复习笔记。

4.工程：

A.读llm-cookbook。对LLM的工作机制有感性认识，学习一些prompt思路。

B.一些值得记录的tips:

- a.ChatFormat/tokenizer/systemMessage以及userMessage
- b.LLM可以朴素分为BaseLLM和指令微调LLM。前者通过"预测",存在更多的"联想",会产生与问题无关的回答。后者经过训练，更适合任务导向会话应用：提供一份菜单给system,system基于预先的指令,对user服务。
- c.关于LLM的预测：LLM并非重复预测下一个单词，而是预测下一个token。生僻词会拆解为多个token。但是分词器是不可控的,我们希望更稳定的输出,于是在字母之间用\来区分token。英文的token占单次长度的75%。中文对应半个~一个词。模型的token上限指的是：prompt和completion总和，这点很重要。
- d.Helper Function主要体现在：区分用户消息和系统消息。这一点具体字面量无严格规定，主要学习思想。
- e.评估分类：给定一些业务类别，让system根据user的输入，判定其提问属于哪一个类别。这一点是我疏忽的。
- f.Moderation：避免用户输入不合当地法规的信息。我们主要调用OpenAI的ModerationAPI。如果我预设的system指令是按意大利语回答，那当我以意大利语提问时，无法绕开这个预设。但是如果加一句，用中文回答，那我的userMessage就绕开了预设。这是Prompt注入，是预设时需要避免的。我们首先获取userMessage，接着在程序部分删除用户输入的间隔符，这样用户输入的间隔符无法进入模型，自然注入就失败了。另一个好主意是：预设好样本和坏样本。
- g.思维链推理：prompt包含：形如 A B C D的输出规范即可。同时，在程序中，可以将prompt存储在json里，逐步加载到模型去执行。这是考量到模型的token上限做出的妥协。这点对我影响比较大。
- h.有时间应该看看LangChain的。愈发觉得用Java接入API是一个很愚蠢的选择，Python提供的库太丰富和全面了。我应该将这个agent模块整合成一个子服务的。毕竟服务通讯并不care语言。

# 1.4日报

1.LC一道Medium：找出第k个符合要求的数。A.先用优先队列构建堆，凭借堆的特性让最小的元素排在堆顶，我们每次取堆顶的元素，就是按照顺序元素取元素。B.设计Set实现去重，每次从堆中取到的元素，分别x2 3 5构建新的符合要求的数，如果set尚未找到重复元素，则添加该元素进堆，让堆将这批元素中最小的丑数放在堆顶，周而复始。最后我们return最后一次取出的堆顶元素，这元素就是符合要求的数。

2.单词新增20，复习113

3.课程：

复习大物

4.预期：

后天考计组，明天上午早起，先把马哲复习了，再把计组过一遍。单词和算法还坚持一天，六号到十号就不做了。毕竟四天考十门还是很紧张。

今日早睡，两天养成睡眠习惯。

# 1.9日报

1.LC一道EASY。给定两条链表，求出二者链表的相交部分链表头结点。策略是使用双指针，每一条链表都提供一个指针，只要A指针和B指针没有相遇，那二者就继续往后走。这里要考虑到边界问题，比如A指针走到A链表尽头，下一步可以走到A链表的头结点，也可以走B链表的头节点。我们一般让其走B链表的头结点相遇会更快。这里可以理解成：A链表的共有段前长度比B短，所以A在共用段中是比B快的，那我为了让AB尽快相遇，那我得阻碍A进入共有段，所以让A去走较长的路。

2.考试：

A.概率论：感觉还行

B.C实验：十道题，mark只有88.5。D题有20%的案例没通过，精度受限。J题太活了，我起初试图打表，但是时间超限。这反映出我目前算法学习的问题：训练过于僵化，我只擅长去做暴力的题/有明显解题思路的题。也就是只背面试的板子。在遇到比较创新的情景的时候，很难找到数量关系。这一点是我需要优化的，我对这种纯粹的数学思考知之甚少。

3.工程：

A.基于OpenAI依赖和DeepSeek开放的API，写了一个python的调用demo，输出了博客。寒假有时间可以好好学学LangChain，我对RAG还是挺有兴趣的，毕竟这可以作为项目的一个很好的加分点。不过LangChain似乎不是很支持DeepSeek，别家的token还是太贵了。

4.复习：

A.复习C理论：这一块真的非常杂

5.展望：

A.明天中午就可以回家了，希望不要挂科。寒假得把分布式这一块的理论，中间件的原理，共识算法这一块狠狠的强化。为了复习这期末，将近一个月没有正经学习过项目知识了。

# 1.10日报

1.LC一道medium：给定两个版本号，字符串格式。形如："1.2.10"和"1.2.11"。要求判定哪个版本号大。这就是典型的字典序问题，我们用双指针来做。首先用split切分"."，化成两个String数组，分别存储对应的.左右数字。然后开两个指针，分别指向两个数组的头节点，一点点往右边移动。在每次移动的循环里面标记两个值，如果当前的位置，在数组中有索引，这个值就是数组中的值。接着就是比较数组中的值，如果数组中的值，前者大，则说明前者版本号大。具体逻辑就是字典序比较

2.单词：复习168

3.工程：

A.分布式订单业务的状态共享：FlinkCDC+仅展示双写状态字段：-保证MySQL与ElasticSearch双写一致性：这种双写一致性是"伪一致性"。因为本质是：只展示同步后的数据行,对于尚在同步过程软状态的数据,进行屏蔽。在CAP中，实现了A，但是仅仅是最终的C，不能保证时刻的C。

B.工行储蓄卡存储与查询[卡类型+发卡地址]：bitmap优化10^7条数据查询-从300ms到21ms：主要思路是：不同类型的卡和不同的发卡地区，分别创建位图。位图的某个位为true，代表该卡/该地区新增了一个用户。想要查询某地区的某种卡用户，只需要对两个bitmap做与运算。

C.日30w订单量业务：分库分表+读写分离-MySQL高可用：MHA还是MGR？目的：读写分离+分库分表。日均30w订单场景。解决方案：A.选择MGR B.按年份分库,按月分表 C.每一年对应一个MGR集群,一主两从,均存储十二张表(十二月) D.不选MHA原因:D.1部署复杂,需要额外添加节点,属于第三方方案,和MySQL原生不一定完全切合,且内置脚本编写复杂 D.2.MHA监控报警机制不够,得配合Prometheus和Grafana,架构复杂

4.额外学习：

A.Python语法/相关数据结构/与Java的差异

5.复盘与展望：

A.在家的学习效率需要高起来，这个寒假的主要任务是继续攻克分布式的场景题，加深对不同组件和原理的理解。在同时需要双开Python,做一些LLM方面的机制学习,要延伸到RAG部分。

B.相较于钻在书本里背诵知识与拿起纸笔做题,Coding无疑是非常快乐的,这种"创作"所带来的雀跃,是任何其他形式的学习都无法带给我的。

# 1.11日报

1.LC一道medium：给定一个有向无环图，使用DFS对其遍历。DFS思路：A.首先判定传入的节点u是否等于最后一个节点(n-1,n是图的一维数组长度),如果是,则将当前的cur完全添加到ans中,并且return。B.然后遍历u对应的二维数组中的第二个维度数组,进行三个操作.B.1添加当前元素到cur中 B.2DFS(当前元素) B.3.cur.remove(cur.size()-1);这就是典型的递归+回溯，实现公用cur集合。

2.单词复习120个

3.工程：

A.基于下单+扣减库存业务：分布式XA的优越性与Seata对其的支持

B.REST接口多层嵌套JSON如何解析？形如天气预报(数据项结构变化大,后端写死实体类,无法完整匹配json)：(Gson+OGNL(对象图导航语言)表达式)：Gson负责将复杂Json转化为Map,而OGNL负责在Map中找到具体的字段:比如"location.city".Gson顶层转化的Map泛型一定是<String,Object>是因为对于嵌套Json而言,Object里面还得填一个Map.而对于最内层的嵌套,泛型应该是Map<String,String>,当然,泛型中的第二个String实际上是对Object强转出来的.我们用于转换json的map是<String,Object> 

C.RestFul设计实践总结：URL分级/返回体设计Data和Pagination储存数据和分页状态。

D.JDK17新增的密封类：限制子类和子接口的范围。父类sealed permits/final。子类必须final！毕竟限定只有被permits的子类可继承,倘若子类可以被继承,那就不够"密封"了。

E.背了点八股文,发觉好久没背八股,许多知识又生疏了。

F.Flink集群的部署+流处理代码demo

4.复盘与展望：

A.明天暂定做三个场景，然后把Spring和Springboot的八股完整复盘一遍，距离我上一次复习这一块内容已经过了很久了，这种基础性知识必须要扎实掌握。

B.把mujica第二集看了，哎，小睦真的很可怜吧。怎么感觉全团都是压力怪啊。

# 1.12日报

1.LC一道medium：给定一个矩阵，要求输出新的矩阵，新的矩阵每一个元素的值为：该元素距离最近的0的距离。我们规定上下左右移动一位代表一个距离。策略是使用BFS：首先收录所有值为0的元素进入queue，其次是设定距离值dis初始为0。遍历queue中的每一个元素，对于每一个遍历到的元素，先设定一个dirs数组，规定上下左右的位移，让queue中元素根据dirs数组完成位移。判定位移后结果是否在矩阵内且是否为1，如果为1，则将1转化为0，且记录该点的值于新矩阵中为dis值，同时将为0的该点的x和y坐标作为一个一维数组添加到queue中。当queue遍历完一轮后dis自增。最后返回新的矩阵即可。

2.单词复习120个

3.工程：

A.学习阿里开发规约，学习命名规范，值得注意的是：关于布尔值，不应该用形如isDeleted的形式，因为is容易被部分框架错误识别，导致判定字段为Deleted。因此我们的pojo应该去除is，同时在resultmap部分做好和数据库中含有is字段的映射工作

B.剖析Minio与Spring Boot集成的细节：从API到实现

C.Integer还是int?浅谈在RPC调用与POJO设计中包装类的优越性

D.BigDecimal的入参为何必须是String?原来Double值是近似值

E.0.1+0.2!=0.3 ？——用BigDecimal来替代Double

F.[项目拆解]基于Redis的双加密Token实现

G.[SpringBoot]启动流程详解：从入口到应用的时间线分析

H.[SpringBoot]Spring如何启用依赖？@EnableAutoConfiguration与SpringFactoriesLoader

I.[SpringBoot]@Enable前缀API太多学不过来？底层原理是@Import+@Conditional

J.[SpringBoot] 巧用 @PropertySource：在 Web 应用中的灵活配置注入

K.[SpringBoot]巧用@Import——配置类的模块化

4.复盘与展望：

A.今天效率尚可，但是感觉知识的吸收率不是很好，需要对今天的笔记做反刍，否则学习效果比较差。

B.明日继续看项目，要从复杂项目中提炼关键的技术栈，打通逻辑链路，总结面试话术。下学期开始就真正进入战斗了，项目尚未完全成型，焦虑是难免的，保持心态，稳步前进。

# 1.13日报

1.LC一道medium：给定一个数字，要求求出其中和为goal的子数组的个数。策略是前缀和+哈希表统计。哈希表统计 nums[j]-nums[i]=goal的子数组数量。

2.单词新增120

3.复习项目话术.

# 1.14日报

1.LC一道medium：给你一个整数 `n` 。如果两个整数 `x` 和 `y` 满足下述条件，则认为二者形成一个质数对：1 <= x <= y <= n``x + y == n` x` 和 `y` 都是质数。策略是先打表，使用boolean数组记录下每一个数是否是质数。然后从2开始遍历到n/2。如果布尔数组中的i和n-i都是质数，那就可以把这两个数添加到临时tmp中，然后把临时tmp添加到总tmp里。

2.单词复习120。

3.工程：

A.写项目，把API网关和微服务的布局搭好了

B.配好了本地虚拟机环境

C.继续优化面试话术

D.Redis分布式锁相关

E.进程通讯与线程通讯相关。

4.复盘与展望：

A.身心俱疲。

# 1.15日报

1.LC一道medium：反向层序遍历。关于树的BFS，我们是维护一个Queue，并且对于每一层，维护一个名为tmp的List，对于整棵树，维护一个名为Ans的List。对于Queue中的每一个元素，都会判定其左右子节点是否存在，如果存在就添加到queue的尾部。且每次循环会圈定"一层的元素"进行新增节点和添加节点值到当层的tmp中，并且将tmp添加到Ans里。最后返回Ans即可

2.单词复习120个

3.工程：

A.配好了虚拟机里面的Docker代理，配好了Redis，MySQL，RabbitMQ的环境

B.把昨日项目文档里的表结构从图转化为SQL，按照2库4表的规格做好了分库分表

C.主要学习ElasticSearch的相关知识，从分词器到构建Index，自定义字典和违禁词字典，使用Mybatis-plus OR RestClient集成到Springboot中，以及更深层次的相关度打分，地理位置搜索。做了一些扩展和了解，输出了博客。

D.看Es原理，吕老师讲的很透彻。从飞花令入题，引申出倒排索引的概念，分析数据压缩的策略(就是让倒排索引对应一个主键id,而非是完整的主键内容,通过倒排索引确定主键id,根据这个id正向查找)，结合Google和百度搜索的"停顿词"过滤引出分词器。讲到这里，我们会思考如何自己设计一款搜索引擎(爬取内容,进行分词,建立反向索引)。令人开心的是：业内已经有成熟的轮子了！Lucene！不过Lucene只是一个库，需要懂得搜索引擎原理方能高效使用。能否再封装一层，让它用起来更亲民呢？ElasticSearch！ES好就好在将对Lucene的操作封装为restful的api，并且提供分布式架构。从而进入(索引/文档)，索引就是就是一张表(描述表结构)，文档就是一行数据，field就是一个具体的类型。这儿有一个关键点：Keyword和text，Keyword直接建立反向索引，text得先分词再建立反向索引。考虑考虑分布式架构！ES也是主从架构，建立索引的请求先发给master，master建立完索引后将集群状态同步给slave。值得注意的是：只有建立索引，建立mapping的过程是直接写主节点，写文档还是routing到集群的子节点的。接下来就是老生常谈的ELK了。Logstash+Es集群+Kibana可视化。

4.总结与复盘：

感觉今天学习效率很低。

# 1.16日报

1.LC一道medium：中序遍历BST树。无需多言了，这种题感觉刷了N遍了。先判定节点是否为空，然后左根右递归就行。

2.单词复习106个

3.工程：

A.对分库分表做了比较深入的学习，从逻辑库，逻辑表，物理库，物理表。到具体的分库分表案例。水平切分是对大数据量做处理，垂直切分是对不同业务做处理。切记使用shardingJDBC时候，application里面的datasource得指向classpath中的具体分库分表的datasource。其次就是使用mp时，pojo类对应的表是逻辑表，比如user。至于如何映射到user_0这种真实表，就得靠写groovy的表达式来完成。

B.复习了AQS。

C.实操了SpringDoc，相较于自己一个一个的在postman里面导入测试url，直接代码上嵌入注解，在Swagger界面测试功能效果更佳。

D.修复了项目的jwtUtil的功能异常。

E.复习了ThreadLocal的知识：A.Spring的事务实现中，TransactionSynchronizationManager类声明了多个ThreadLocal类型的成员变量来将事务执行过程中的各种上下文信息绑定到当前线程，such as:事务链接的对象，是否可读，事务名称，隔离级别。B.SpringMVC的RequestContextHolder类是持有上下文Request的类，内部实现也是用Threadlocal去存储请求对象数据。OpenFeign朝下游传递header的过程就用到了这一点。C.Threadlocal替代Session，用户请求头的token会被拦截器拿去redis查信息，如果是jwt，那查到的信息就放到ThreadLocal里面。上述主要体现ThreadLocal的隔离性。Threadlocal里面有ThreadlocalMap,一个线程对应一个Map。ThreadLocal的get实际是map的get,map的key是threadLocal对象.map中的Threadlocal对象是强引用,value是弱引用。

4.总结：

A.起得太晚，玩的太久，基本没怎么学习。

B.明天是绝对不能这样下去了。

# 1.17日报

1.LC一道medium：LogTrick寻找或运算结果至少为k的最短子数组。策略是先遍历i作为右指针，如果右指针遍历过程中拿到的单独元素就>=k，则直接return 1，代表该元素就可以作为子数组返回。若单个元素无法>=k，则从j=i-1开始往左走，同时做判断，如果nums[j]|nums[i]==nums[j]，则直接break，因为往左走或出来的结果和不走一样，没有必要浪费时间。然后就是nums[j]|=nums[i]; 接着如果nums[j]>=k，则贪心ans（数组长度）为i-j+1。最后返回贪心值即可

2.单词新增20，复习63

3.工程：

A.Validation依赖：有@Constraint。里面需要传入一个校验类，这个类需要实现ConstraintValidator<校验注解,要校验的值>，然后要校验的值会存储在全局变量中，同时提供isValid方法，这个方法的入参值来自被修饰的元素，我们判断传入值和泛型中的若干值是否有重合项，如果有，则return true。这个思路用来设计：状态是否在指定范围内(用户状态用Integer表示)

B.复习Mybatis的动态SQL：形如foreach，需要传入collection(@Param在dao层修饰)，至于item，index，separator都是自己在xml中指定的。#{}中放变量与jdbcType。这种半ORM写起来真的挺痛苦的，还是mp好用啊！

C.学习Mybatis的插件机制，先前仅是在表层上应用MP。今天了解到所谓的"分页"，本质是通过一个JDK动态代理的拦截器，检测实现Executor接口的query方法，然后若方法的PageSize和PageNum为空，则将入参传入，然后生成limit和offset。这一块输出一篇博客，还是得深挖一些常用知识点的底层原理。

D.学习一种古老的id自增写法：先用<selectKey>取到插入操作后的自增主键值，通过给其绑定insert的parameterType中的id为keyProperty实现。有两个缺陷。A.ID顺序自增,泄露数据增长趋势 B.未使用分布式全局ID,后期业务量大,做数据迁移和分片时,不同库的id会冲突。

E.分析Springframework.data.redis这个包的代码逻辑，输出博客一篇。整合了常见的封装Redis客户端的操作。

# 1.18日报

1.LC一道medium：给定形如"46""61"的数，询问重新组合后是否可以为2的幂次方。我们考虑到有"64"和"16"，因此上述都可以。实际的判定是：构建一个check方法，方法内声明char类型的哈希数组，下标表示每一个位的数字，值表示出现的频率。我们确定："46"和"64"中的4和6出现的频率是一致的。因此判定46可以调换位置得到。我们得到的对于46得到的哈希数组是[0,0,0,0,1,0,1]。我们将这个char数组化为String，后续在主方法中比较String即可。其次是打表，就题设要求的数据范围，将2的幂次方所有数都进行打表，并且走check存入set。之后用要判定的数转化String后尝试添加到set，因为set去重，如果失败则说明该数是2的幂次方，则return true，反之return false

2.单词新增20，复习63

3.工程训练：

A.从Zuul到GateWay：响应式编程在网关设计中的优势，补充了WebFlux和传统MVC架构的差异细节。了解了Reactive模型在高并发场景下的应用(网关)。最直接的表征是：网关服务的依赖为何不用web，而要用WebFlux。

B.基于Spring-Data-ElasticSearch和Mybatis的商品搜索功能实现。主要是做从MySQL插入数据到ES，以及在ES中做复合查询(相关性,热点词,用户推荐)的具体实操,这一块我吃的不是很透,只是简单做了了解,还需要深度挖掘。

C.复习MySQL的innoDB和MyISAM关于锁的知识。看到表锁首先想到MyISAM，且MyISAM自动上锁，其写操作默认比读操作优先，且单线程阻塞，写时其他线程不可读。看到行锁首先想到innodb，这里需要补充：记录锁是对某行记录的索引加上锁，倘若你的sql不涉及到索引，那记录锁是失效的。间隙锁，锁的是空白区域。邻键锁是gapLock+RecordLock。其实可以把间隙锁的范围理解成去心邻域，而记录锁是锁的具体的"点"。后两个锁的失效都有可能导致幻读。Record锁容易引发死锁和隔离性问题。这一块记忆消散太多了，今天算是捡了一些回来，同时也深刻了认识。

4.复盘与展望：

A.我的知识广度已经触及应用开发的边界了，但是深度远远不够，对于许多技术，我仅仅有名词上，以及肤浅应用上的浅薄认识。对于其底层机制毫不了解，带来的恶果是：在配置环境时，经常遇到依赖冲突。在写代码时，经常出现莫名其妙的bug。我认为当务之急是对常用技术栈做深化挖掘，比如Redis和MySQL,Mybatis,Spring,分布式基础设施(网关,Auth,搜索)。

B.最近的学习状态不佳。我明显感知到自己假期过得太松弛了，这是一个非常不好的兆头。

# 1.19日报

1.LC一道medium：香槟塔问题。给定k杯香槟，第i层有i个香槟杯，每个香槟杯只能容纳1杯，剩下的部分会均分给下面的左右两杯。我们规定dp(i)(j)是流过在i,j位置的杯子的酒量。有状态转移方程:`dp[i+1][j]+=(dp[i][j]-1)/2 dp[i+1][j+1]+=(dp[i][j]-1)/2` 最后return一下入参要求的某个坐标的杯子结果即可。

2.单词新增20，复习103

3.工程：

A.深挖了Mybatis框架原理，这一块能谈的太多了，日报里写不下。

B.把Linux的权限管理语句,管道语句,ssh连接相关,常见的文件操作符命令都复习了一遍。这一块值得注意的是：在chmod时候 d是文件夹 -是文件 l是符号链接。然后后面的数字：rwx记忆就行，从右往左分别是124，就按二进制记忆。 然后三组分别对应：所有者，所有者在的用户组，其他用户。比如 chmod 777 就是给所有者 所有者所在的用户组，其他用户。都拥有读，写，执行的权限。还有就是做文件夹删除的时候记得rm -r 表示递归删除。做cp的时候也要注意 cp -r 递归思路一定要记在脑子里面。

4.总结与复盘：

A.今天效率还行，看Mybatis的原理还是挺爽的。就是得把这种常用的框架原理挖深入。像是一些高并发架构设计，这种东西实习生进去也没法实践，纯纯的背方案，面试的时候被问到的概率还是太低了，毕竟都知道在校生没法实践这种架构。与其花大力气在这个上面，不如把涉及到单体的细节尽可能学明白。还是要打牢基础才能行稳致远，能做好CRUD是最基本的。能当好crudboy再去研究架构才是正道吧。

# 1.20日报

1.LC一道medium:分汤DP。给定AB两种汤，每次都可以对A和B分配。有四种方案。我们规定`dp[i][j]`是i份A汤和j份B汤的复合概率。设计dp为四种状态概率相加/4.0即可。需要考虑到一个上限情况：A汤分配的期望大于B汤，在某一个值会导致概率趋于1。

2.单词新增20，复习83

3.工程学习：

A.复习Mybatis流程

B.复习SpringBoot启动流程

C.复习Netty基础知识

D.着重看了HashMap和LinkedList,ArrayList,ConcurrentHashMap的源码。把树化，反树化，扩容阈值，树化阈值，CAS，传统锁，锁的升级。这些知识都进行了复习，并发编程这一块上次学习还是在去年十一月份，现在记忆淡忘很多了。

E.对Dubbo做了简单了解。

F.把学习项目的RabbitMQ部分着重看了一下，感觉这个项目的创新点太少了，就简单使用了队列+Es+Redis。然后鉴权简单使用了sa-token，剩下的全部都是CRUD，各种CRUD，这创新点和独特优势几句话就讲完了。明天得抽空把这个具体商城业务的逻辑理清楚，常见中间件的多种复杂数据结构都得利用上来，不然太单薄了。

4.总结与归纳：

A.效率尚可，主要以温习旧知识为主。适当拓展了一些对旧知识的实践校验。

B.明日需奋斗啊，发觉自己完全没有进入战斗状态，学习效率真的不高，没有那种火烧眉毛时，背水一战的魄力。

# 1.21日报

1.一道Medium：给定形如[7,1,3,5,4,2,6]的乱序数组。要求将整个数组处理成元素一样的状态，且操作的次数最少。这里的操作指的是对一个数+1或者-1。我们先对整个数组进行排序，然后取整个数组的中间元素为锚点。对其左右的元素做+1和-1即可。我们实际是计算某个元素的值和中位数的差值，然后遍历，记录总的差值绝对值。

2.单词新增20，复习97

3.工程：

A.电商平台,接入支付宝API的pojo,config,service看了,梳理了一遍逻辑

B.把电商业务的相关概念理清了,sku,spu.以及pms,oms,ums,sms,cms,对整个业务做了切分。这一块花的时间是最多的，先前对电商系统的业务逻辑是很不了解的。今天还是归纳出一套看开源项目的方法论。先读pojo,读完pojo看service,看完service看controller.最后再看mapper层.想要读的效率高,就得把业务逻辑和查库逻辑给分开.一会读持久层的SQL,一会又读服务层的业务逻辑,很容易把脑子看晕.在读业务的时候,应该把具体的的查询操作理解成一个封装好的黑盒,暂时不考虑内部的构造,而专注于整体的业务流程.

C.复习maven生命周期：其中Defalut为validate->compile->test->package->verify->install->deploy.在此之前还有clean,在此之后还有site.clean和site都有pre和post两个phase。然后就是插件是挂在到生命周期的具体phase上的，生命周期的phase相当于一个占位符。

D.复习RabbitMQ相关知识.

E.看minio相关的业务逻辑：我先前对文件上传的认知是很浅薄的，今天深入挖掘了一些细节。首先是将文件通过Http请求(content-type为`multipart/form-data`)发送给后端服务,SpringMVC自动解析请求体封装成MultipartFile对象。这儿得@RequestPart("file")修饰上传接口的入参.其次就是初始化Minio的客户端,连接服务器等一些老生常谈的话题.接着将MultipartFile中拿到的文件信息，传输到存储桶中。这涉及到存储路径(日期+文件名)以及参数对象，以及一些细节判定。

4.总结和归纳

A.对项目的理解更深刻了,我发觉:真正难以理解的不是技术,因为技术可以通过使用框架来降低学习成本.真正复杂的是业务,应该让业务来驱动技术发展.比方说电商业务,涉及了大量行业内名词,我得将更多的时间用来学习行业内知识,再整合这些知识到具体的业务逻辑中,从而实现代码的理解.

# 1.22日报

1.一道medium：0-1背包问题。这类问题给定一个容量为m的背包，与一个可选择列表，每一个物品的体积是nums[i],价值各不相同。我们定义形如`dp[i][j] i表示选择了几个物品 j表示当前背包的体积 而dp表达:在当前容积上限下,我遍历到第i个物品,所带来的总价值`.我们遍历i和j,在满足j-nums[i]>=0的部分,进行贪心。最终返回`dp[nums.length][m]`这个数就是装满背包,且遍历完整个列表,背包的价值

2.单词新增20,复习67

3.工程向:

A.复习了SpringAOP的xml和注解配置

B.复习了Minio的Java客户端配置,整合了SpringMVC关于文件上传的注解,以及前端配套的实现

C.新增了基于Redis+Lua脚本实现用户登录多次失败-封锁IP的场景题储备,学习了在jedis客户端执行lua脚本相关的参数知识。

D.复习了SpringMVC：实现自定义拦截器。@Bean一个方法,返回InterceptorRegistery生成的对象即可。该对象装饰器内包裹一个实现了HandlerInterceptor接口的类，我们在这个类中preHandle，postHandle,afterCompletion,切记,第三者是在整个DispatcherServlet完成后工作的。这一块是查漏补缺，当初头回学的时候有遗漏，还好今天补充了。

E.复习了分布式ID设计：常见场景题是`链路的traceId,幂等性处理的请求id,MQ异步通讯的msgId,短连接系统的全局Code`我们不能局限分布式id只在分布式系统中重要。任何强制全局唯一的场景，都需要分布式ID。A.UUID(32位,五个-,基于MAC和IP和时间戳,不适用分库分表,因为随机的ID会导致索引树频繁的页分裂) B.基于中间件(Redis和ZooKeeper生成id,相较于把生成器放在java服务,吞吐效率更高)C.Twitter的雪花算法(标准答案,1bit符号位+41bit时间戳位+10bit工作进程位+12bit序列号位/由于雪花算法和时间戳强相关,要避免时钟回拨问题:使用逻辑时钟而非物理时钟(检测到物理回拨,用最后一个id的时间+1ms))

F.学习了接口设计规范：A.注释 B.日志的内容要详尽,日志输出不能在跑批的循环里面,否则容易导致接口执行缓慢 C.单体项目,请求入站自动生成全局唯一id,塞到MDC中即可 D.考虑跨域问题,使用@CrossOrigin或者写一个Config,通过实现WebMvcConfigurer来配置跨域(本质都在相应头里面塞字段) E.身份鉴权和接口签名,这一块用Sa-Token可以解决F.写接口一定要注意做资源隔离,特别是涉及到线程池的业务.

# 1.23日报

1.LC一道medium：不使用除法来实现整数除法：使用位运算的减法和乘法来完成。我们尝试用2^i次方做为基数来测试被除数是否能被整除。也就是(a>>i)>=b则让a-=b<<i，同时res+=i<<i。

2.单词新增20，复习47

3.工程知识：

A.学习EasyPOI和EasyExcel：读Excel表主要涉及到：@ExcelProperty,@ColumnWidht,@IgnoreExcel,以及注意表字段的merge.在EasyPOI中使用@ExcelCollection和@ExcelEntity实现复合读取和写入

B.复习反射：1.从method.invoke(obj,args)开始,通过JNI调用本地方法,遍历Klass（调用次数超过15次则生成GeneratedMethodAccessor1类,绕开反射API）2.Klass(方法表+字段偏移量+父类指针)是DNA,Class是前者的镜像 3.通过反射修改字段值,Jvm需要计算内存偏移量 3.Klass是核心,方法表和偏移量是定位方法和字段的钥匙,动态字节码生成是救星,将反射调用转换为普通调用,性能提升十倍(一般反射调用比普通调用慢10倍左右)

C.复习：虚方法/虚方法表/如何通过反射从对象头中获取对应的类地址/通过类地址+偏移量找到该类的虚方法表/虚方法是非static,final,constructor,private的方法。是运行时的具体类型,而非引用类型.比如是Dog而非Animal.

D.学习栈式虚拟机/寄存器式虚拟机区别:Java/Python/.NET都是通过模拟操作数栈(以及局部变量表)来实现计算的(简单加法就要经过七次总线传输,效率比较低),而安卓和Lua5.0采用寄存器式,效率比较高,但也依赖于特定的硬件.

E.复习：类加载子系统/执行引擎子系统/运行时数据区/GC子系统/JNI部分，这一块繁琐且容易混淆，这应该是第3到4次反刍了，仍然发现许多知识被遗忘了。

# 1.24日报

1.算法：基于HashMap和Deque实现了LRU，如果希望更难一些，就是手写双向链表+map来实现LRU

2.单词：新增20，复习67.

3.工程知识：

A.复习JVM的执行引擎部分：JIT/解释器/方法分派(静态分派与动态分派)/虚方法表

B.登录场景题：(用户输入断线数据留存/短信接口通过滑块验证(附加数字签名)+Redis维护计数器实现限流/用户注册敏感词处理(用es来分词)/用户记住登录(颁发持续性token))/接口的幂等性问题(用户由于网络/恶意攻击提交了多次请求/通过在Redis中维护幂等表(1.用户进入表单,前端向后端请求一个幂等token,2.前端存储幂等token在cookie中,3.请求携带该token,后端先判定该token能否在redis成功删除,成功删除则第一次调用接口,删除失败说明该请求为重复请求,应该被丢弃))

C.复习四种限流算法：简单计数器（通过划分时间窗口，每个窗口只能执行n个请求，但当i窗口和i+1窗口的分界线集中了窗口内所有请求时，会产生毛刺现象，导致并发量过高，因此需要通过滑动窗口来优化）；滑动窗口（让简单计数器的窗口动起来，使用Redis的Zset实现，当前时间为分数，每次取当前时间，member为IP等标识符，通过删除过期请求来控制，若窗口大小为1分钟，那么每次请求到达时，删除当前时间戳前1分钟的数据，通过ZREMRANGEBYSCORES删除过期请求，通过ZCARD获取Zset中剩余的请求）；漏桶算法（请求必须被放入桶中才能被处理，超出桶容量的请求会被丢弃，桶中流出请求的速率是恒定的）；令牌桶算法（Redis的Hash维护某一个逻辑名称的tokens剩余数量以及最后补充token的时间戳）。

D.继续学习项目：1.对Redis常用操作封装 2.Redis应用：用户登录缓存(登录状态/短信验证码)/交易订单号缓存 3.下单业务流程学习(收货地址/购物处理/优惠卷处理/积分处理/发货处理/超时订单延迟消息(订单流程一定send一个取消订单的消息,但是取消订单的实现中得判断该订单是否被支付,如果被支付就不取消了)/本地锁)

E.消息队列复习：1.三个核心(异步/解耦/削峰) 2.为何使用消息队列 3.消息顺序(Kafka:一个topic只能有一个partition么?--让queue和消费者对应即可/消息重试-例如微博的：发微博/写评论/删除微博) 4.消息积压(业务增长,消费不过来怎么办？--新建partition为原来10倍的topic,临时建立原本10倍的queue量/十倍机器部署comsumer) 5.消息丢失(生产者收到写入成功响应后,消息真的投递成功了么?--RocketMQ生产者使用事务消息/Broker尽量采取同步刷盘而非异步刷盘/消费者等业务逻辑跑完再给Broker ack) 6.重复消费(高并发场景下保障不重复消费/唯一ID,类似幂等表策略) 7.消息的可靠性保证方法 8.三种常用消息队列的架构选型比较

F.学习六种经典包装策略：六种经典包装策略(1.降低耦合(比如md5策略更换,只需要修改一处,而非是在每一处使用到之前策略代码进行修改)2.远程代理(通过proxy封装具体的调用,这样从本地调用升级到Client的RPC,只需要修改内部引用即可,不需要处处修改)3.安全实现：使用装饰器来对某个类做增强4.反向代理：客户端通过Nginx（隐藏后台细节）反向代理到若干到Tomcat5.读写分离：通过ProxySQL，客户端对后续的读写分离操作无感知6.分库分表：通过ShardingProxy，如5所示，都是我们的Java服务无感知，通过一层代理来做包装。456都是架构层面的）

# 1.25日报

1.算法：简单计算几何：给定四个xy坐标组，判定能否构成正方形。策略：计算任意两点的距离平方(两点距离公式)，并存入Set中，凭借去重特性。合理的产出：set中只有两个非0值，分别代表edge和对角线。最后判断edge*2是否等于对角线即可。这里乘2来比较的原因是：因为存储的"距离"实际是距离的平方。

2.单词：新增20，复习91

3.工程：

A.要对服务模块做内外网的拆分：授权/biz/分布式id生成/店铺对内/订单对内/平台对内/商品对内/rbac/搜索对内/用户对内模块，拆分到api模块中，这些服务比较敏感且重要，RPC只在内网中工作。

B.Saas(多租户/软件即服务)：1.一套程序实现多用户数据的隔离(三种隔离级别：独立数据库/共享数据库,独立Schema/共享数据库,共享Schema,共享数据表(加上字段区分具体租户))2.mysql的schema==database/oracle的schema是某个用户数据库对象的集合.3.多租户架构考虑：(隔离or共享) 4.Mp提供了TenantHandler，可以就第三种共享级别的CRUD自动插入租户约束(租户设计为字段,通过拦截和修改SQL,让租户的选择从业务代码中抽离)

C.用户上传的img可用@JsonSerialize(using = ImgJsonSerializer.class)序列化为String，存储在数据库中。其他格式图片同理。用的是jackon

D.复习FeignClient：value指向服务名，contextId表示同服务的多个可区分的Client，具体方法和入参也用MVC的注解，注意封装RPC调用的统一地址前缀为魔数。

E.抽象工厂：云服务接入场景-OssFactory-返回OssImage和OssVedio两个接口(抽象工厂返回抽象接口)/然后实现抽象工厂,实现具体产品(具体的得实现抽象接口)/比如具体产品是AliyunImage和Vedio,QiniuImage和Vedio：这样后续我添加新的oss厂商，只需要针对OssFactory和两个抽象产品做拓展即可,实现对增加开放,对修改关闭.

F.Git发版是用分支还是标签？分支是动态的,标签是静态的.发版只能用标签,tag一旦确定,被打上tag的代码不可修改(打tag是重量级操作,基本都是leader干)

G.MetaData认知：(1.描述数据的数据：比如博客的发文时间/修改时间/作者/标题/访问权限组and so on.)(2.业务元数据/技术元数据/操作元数据)

H.命名空间理解：核心是隔离(1.Namespace的职责：隔离不同的资源2.k8s通过NameSpace来隔离不同的部署环境(Dev/Test/PROD)3.nacos通过NameSpace来隔离不同的配置环境(Dev/Test/PROD)4.xml使用Namespace：隔离不同的标签资源：用aop: sharding:这种前缀来分割不同的资源，避免在同一个xml中使用了两个相同的名字而导致报错)

I.使用SPI+事件监听器：消息服务-代码零修改实现监控埋点:ServiceLoader是核心,文件名是接口全限定名,文件内容是要加载的,该接口的实现类的全限定名.因此我们会遍历ServiceLoader执行加载后的结果来拿到某个实现类的实例.SPI这一块在JDBC,ShardingJDBC中被频繁使用.我对其的理解是很浅薄的，API 中的接口是更像是服务提供者给调用者的一个功能列表，而 SPI 中更多强调的是，服务调用者对服务实现的一种约束。

# 1.26日报

1.算法：正方形框，左下角入射光，三边界点接收器。判定在不同的正方形边长和第一次抵达右边界的距离下，光线会落在哪一个接收器上。策略是GCD+取模。分类讨论三种情况(根据正方形边长和第一次抵达右边界在竖直方向距离的奇偶性(0/1))偶数则算折返一次，奇数则算抵达右侧。

2.单词新增20，复习119

3.工程训练：

A.云环境的IAAS,PAAS,SASS区别：提供服务器/提供服务器和中间件/提供服务器和封装好的服务-PAAS只需要写业务代码,不需要关注中间件的架设,SASS只需要注册和登录,不涉及太多技术.

B.gitLab-jenkins-Habor-Helm Museum-K8s：发版工作流程梳理

C.git commit和rebase的区别：feature/hotfix分支可以考虑rebase，但是为了日志可追溯，主分支修改最好还是commit

D.封装加密类-自定义SpringBootStarter：spring.factories+application.yml+@ConfigurationProperties(prefix="")+@EnableConfigurationProperties+ConditionalOnProperty修饰其中的Bean

E.SSO与OAuth2.0：前者是内部验证，后者是三方授权。前者Session-后者token，前者是服务器-后者是标准。特别关注OAuth2.0从开放平台返回给UA的是code而非token，具体原因是因为：UA向第三方传递code的时候是基于重定向的，但是重定向时数据是暴露的，如果此时给token，则可能被中间人劫持token，导致数据泄露。因此我们只能让code+appId+appSecret作为整体来获取token，并且只把token给第三方平台，让第三方平台来查询，避免中间人从用户浏览器获取token，造成数据泄露。

F.方法引用：基于函数式接口,能够智能推断类型，与stream结合紧密。形如sorted(Person::compare)前者是类名,后者是静态方法。这个语法糖平时用的太少了，很生疏，需要熟练。

G.SpringBoot接口的QPS与响应时间监控方法：actuator+prometheus+grafana

# 1.27日报

1.算法训练：LC一道medium：复习矩阵的BFS，相较于二叉树BFS，需要预先设计上下左右的位移量数组，根据题意需要抽象出虚拟的"层"，比如所有值为0的元素在一层，而非像传统二叉树的物理意义上的层次。需要构建辅助的visited矩阵和res矩阵(结果)

2.单词新增20，复习121

3.工程训练：

A.Nacos作为配置中心：网页端导入的yml实质是存储在某个db的config-info中.这个content字段的类型是longtext,同时需要加入换行符等符号.

B.Nacos的表设计：config-info/config-info-aggr/config-info-beta/config-info-tag等表结构的认知，拓宽对nacos理解。

C.复习(spu,spu_attars,sku)，复习电商库存字段(可售卖存量=实际存量-锁定存量-避免订单未支付导致的超卖)

D.IO阻塞时CPU分析：(无DMA则PIO,效率低,有DMA则走DMA-上下文切换有开销-nodejs高效是因为单线程任务循环,(无上下文切换)+用户条事件调度/Tomcat用BIO,但限制池子大小+切换就绪线程+epoll也可以令BIO媲美AIO)

E.预防SQL注入：前端表格name和后端sql查询的column不能相同,避免在使用${}表达字段时,被注入令where无效的语句,导致数据库泄露.牢记前端数据是不可信的！

F.复习CAS操作的ABA问题(无锁栈的出栈问题：A->B->C：线程1读取A，准备更新B后挂起，线程2读取A和B，写入A，此时栈中仅有A->C，但CAS认为栈顶元素未改变，但缺失了B，栈被破坏，这就是ABA问题)，以及通过版本号机制解决的实现

G.ES的四种分页方式：（1.from和size(对高from的深页性能差,只适合浅分页)/2.search_after+排序值(深分页效果好,但只能按顺序分页)/3.ScrollAPI(不适合实时搜索,保持某个在线时刻快照,处理数据量大,适合迁移和数据分析)/4.Point in time(一致性好,占用资源多,是基于时间点查询,多个分页请求维持一致性视图)）

# 1.28日报

1.算法训练：LC一道medium：计算三角和：给定一维数组形如{1,2,3,4,5}计算四次nums[i]=(nums[i]+nums[i+1])%10即可，最后return nums[0].需要关注题设的几何关系

2.单词新增20,复习90

3.工程训练：

A.复习项目的Es业务部分：

B.复习项目的Redis业务部分：梳理业务逻辑/学习了SpringCache的@Cacheable和@CacheEvict等通过AOP方式来将缓存处理从业务中抽离的方式(这点很重要),复习了延迟双删

C.复习项目的RocketMQ部分,重新读了一遍文档，整合看了公共RocketMQ模块的设计逻辑。

D.学习项目的分布式ID实现：Leaf-segment:**Segment** 通过预分配内存段实现连续ID和高吞吐，但依赖数据库且需配置段大小；**雪花算法**去中心化且高效，但依赖时钟且ID趋势递增不连续。今天主要学习：Segment的双buffer实现。

4.总结与复盘：

今天的学习和项目的结合比较紧密，进度还是太慢了，感觉很难在开学前把业务项目和轮子项目准备好，只能加快进度了！

# 1.29日报

1.算法训练：LC一道easy。给定数组,要求找到两个元素相等且索引不同的数,且这两个数的距离要<=k。最初尝试双重for暴力求解和双指针法，时间都超限。解决思路是：Set集合存储每一个元素，每轮循环先判定该元素是否在set出现，如果出现则return true。之后于set中添加当前nums中元素，最后判定当前set长度是否超过k，如果超过则从set中删去nums[i-k]。这实质是维护一个滑动窗口，淘汰最左侧的元素。上述代码如果执行完毕后，还没有RETURN TRUE，最后return false即可。

2.单词：新增20，复习108

3.工程：

A.新增知识：Orika实现VO和DTO等类型转换。核心(1.MapperFactory/2.MapperFacade/ 3.mf.classMap(A.class,B.class),4.filed("Name","Na_me"),5.mapAsList和map)

B.润色简历,严谨表达,删去冗余口水话,补充定性和定量依据.

C.SpringCloud做模块解耦用到的工具,拆解模块的思路

D.复习Nacos服务发现和配置管理的细节操作

E.复习Nacos和其他AP和CP的服务发现工具差异

F.Redis做业务支撑和架构支撑的缓存设计-这里特别补充一点Zset的妙用：1.记录历史数据：比如订单数据曾经是Pending 后来是Success。我们将状态:时间戳这个value存入Zset。这样就可以实现某个商品状态的可追溯。2.实现层级结构，比如做前端数据的分层展览时，用value的:后数字表示父子层级,:前的串表示产品类型.

G.深度研读基于RestHighLevelClient做ES的复杂分页查询代码逻辑,这一块对我太陌生了,阅读起来比较吃力.需要投入更多精力。

# 1.30日报

1.算法训练：LC一道easy：找两个nums数组的并集。策略是用hashmap统计第一个数组的每个元素出现的次数，然后遍历第二个数组，判断当前这个数为key,map中有没有元素,如果有就在map中把对应的value扣减1，同时将这个元素添加到list中，最后用stream转化为array

2.单词：新增20，复习92

3.工程训练,按照简历项目预设面试官拷打内容：

A.Redis在你的项目中是如何实现架构支撑的？

B.你如何使用ElasticSearch实现商品搜索功能？怎么用Canal做数据同步的，能详细讲讲具体的实现吗？

C.ElasticSearch如何支持商品搜索的多维度筛选和分类展示？/ES的聚合操作：桶聚合/度量聚合

D.Leaf-Segment分布式ID是如何实现分布式ID生成的？为什么选择这种方式？

E.你如何使用Seata协调分布式事务？能举一个具体的例子说明吗？

F.你是如何在项目中集成RocketMQ的？它是如何处理异步消息的？

G.RocketMQ在订单处理中的作用是什么？能详细描述一下它的流程吗？

H.RocketMQ时的消息顺序性和可靠性:MessageQueueSelector/setMessageListener(消息重试：ConsumeConcurrentlyStatus.RECONSUME_LATER)

I.详细分析RocketMQ：事务消息-生产者绑定(TransactionListener),先发半消息,本地事务执行成功后,半消息成为全消息,投递到Consumer

J.深入解析 Canal 组件：MallCanalBinLogEventParser、MallCanalBinlogEventProcessorFactory 和 MallCanalGlue

# 1.31日报

1.算法训练：LC一道easy。给定一个数组，每2k个元素，翻转前面k个元素。策略是for循环遍历每一个元素，定义一个reverse方法。每次传入一个left和一个right,left是当前的索引,right是left+k或者数组的边界，实现翻转即可。

2.单词新增20，复习92

3.工程知识：

A.通过Canal和RocketMQ实现MySQL到ElasticSearch的数据同步:Canal配置文件中绑定具体的MQ和topic以及producerID,配置好相关的parser和factory,消费者接收String,通过Json解析工具解析String内容,设置到Es的BO中,然后提交到ES中

B.MySQL变更日志(CDC)-二进制日志/恢复日志/回滚日志

C.Feign原理分析：

D.Feign和RestTemplate的差异分析

E.基于RPC的Dubbo与基于HTTP的Feign差异分析：前者二进制协议，后者文本协议(Json,HTTP)-具体分析Dubbo基于Hessian的序列化操作

F.SpringCloudGateway：路由/全局过滤器/局部过滤器

# 2.1日报

1.算法训练：

A.LC一道medium：将一个单调有重复元素的数组从某个索引截断，将后者拼接到原数组0索引之前，实现翻转。要在该数组中搜索target元素。策略是二分查找：先判定左右两段哪段是有序数组，接着做二分即可.

B.周赛

2.单词新增20，复习92

3.工程知识：

A.读RPC博客：RpcServer,RpcClient,RpcProxy,RpcInvoker,RpcProtocol,RpcConnector,RpcAcceptor,RpcProcessor,RpcChannel/自定义协议...关于多态,需要注明对象名.不同机器上的进程是允许相与调用的，当机器A上的进程调用机器B上的进程时，A上的调用进程被挂起，而B上的被调用进程开始执行。调用方可以通过使用参数将信息传送给被调用方，然后可以通过传回的结果得到信息。编程人员看不到任何消息传递过程。这个方法就被程为远程过程调用RPC.

B.读尼恩高并发-GateWay部分：

- 基础配置：
  - Filter
  - Route=ID+URI(要发往的地址 lb://message-provider 为配置中心注册的服务名)+一组Predicate+一组Predicate
  - Predicate（返回布尔结果）：匹配HTTP请求内容,形如Headers,入参为ServerWebExchange(上下文)
  - Gateway收到请求->在HandlerMapping寻找匹配路由->发送到GatewayWebHandler->过滤器链
  - Predicates: `-Path=/gate/**,/rule/** `一定保持key-value格式
  - 断言工厂：datetime/Cookie/Header/Host(限定主机名)/Method/Path/QueryParam(实际上是Query=XXX,正则,面向在uri中带?xxx=123的类型)/RemoteAddr （- key=value,正则）比较常用,比如(-Cookie=sessionId, test)就是接收 `curl http://localhost:8080 --cookie "sessionId=test"` 
  - 过滤器：
    - `\- PrefixPath=/mypath` 访问/hello的请求被发送到https://example.org/mypath/hello。
    - `\- RedirectTo=302, https://acme.org` 重定向，配置包含重定向的返回码和地址：
    - ` \- RemoveRequestHeader=X-Request-Foo`去掉某个请求头信息：
    - 针对：请求头,跳转的子路径,状态码,请求参数等Request信息进行修改
  - 熔断降级：hystrix的集成是在filter中实现的：集成Redis服务

C.Minio和RAID相关学习：RAID/纠删码/分布式文件存储和单体文件存储/冗余思想

- RAID0:连续数据分散到不同磁盘上存储,并行读取
- RAID1:数据完全复制到另一个磁盘,磁盘空间利用率50%
- RAID5:折中方案：使用校验位，安全和IO速度居中

D.复习装饰器模式：核心在于-装饰器被装饰的物品都实现同样的接口/继承同样的抽象类，并且通过构造函数做传参：比如基于已有的Handler，在外层装饰Logging和Auth，层层嵌套即可。

# 2.2日报

1.LC一道medium：给定会议的开始时间数组，会议的结束时间数组，活动时间上限值，移动会议上限值。通过维护一个长度为( 移动活动上限值-1)的滑动窗口,不断获取相邻会议的空闲时间,累加到变量s中,并对s做贪心,贪心结果为ans.s在窗口内元素上限达到后,减去一个(i-k)号会议之前的空闲期,这就是滑动窗口对旧数据的淘汰.

2.单词新增20，复习92

3.工程知识：

A.monitor对线程同步的实现：synchronized修饰代码块时,括号中填入的对象就是monitor

B.线程的Synchronization和Mutex：前者令多个线程按顺序工作,比如写入文件需要按顺序进行,否则文件内容错乱,后者是保证同一时刻只有一个线程能访问资源,比如账户扣款的操作.复习：synchronized,Lock,ReadWriteLock,Semaphore,Atomic

C.线程通讯-生产者-消费者模型(a.wait()和notify() b.ArrayBlockingQueue的take和put c.CountDownLatch和CyclicBarrier)

D.线程之间资源共享：volatile/锁/形如ConcurrentHashMap的集合类

E.`Thread.interrupted()` 是一个静态方法，检查当前线程的中断状态并清除标志。`线程名.isInterrupted()` 是实例方法，检查指定线程的中断状态但不清除标志。`线程名.interrupt()` 是实例方法，用于请求中断指定线程，并设置其中断标志。

F.复习线程生命周期(new-runnable-blocked-waiting-TimedWaiting-Terminated),复习线程名.stop(将线程从blocked或者waiting转为terminated)但是stop过于强制风险高,现在用线程名.interrupt(线程)

G.线程优雅关闭(优雅是指关闭线程不产生负面影响)：1.volatile修饰的标志位+改变标志位的方法,代码只在标志位为true情况下工作 2.ExecutorService的shutdown().3.在提交异步任务时候,executorService.submit(task)拿到的future,可以用future.cancel(true);来关闭当前线程

F.开始写MQ轮子项目了，这一块对上学期学的Netty依赖比较高。整体思路还是仿造RocketMQ。这一块查漏补缺了先前Netty学习的遗漏之处。

# 2.3日报

1.LC一道easy：判定字符串是否回文，且允许跳过一个字符。策略是先写check方法，check方法是对left到right数来判断回文。然后在不允许跳过字符的代码基础上，增加判断：如果发现有左右指针元素不一致情况，return check(s,left+1,right)||check(s,left,right-1); 即可

2.单词新增20，复习92

3.工程知识：

A.Executors.newScheduledThreadPool(1).scheduleAtFixRate(线程名,初始延迟时间,间隔执行时间,时间单位)：补充作为一种定时任务方案。但要注意Executors的局限性，比如无法自定义七大参数。

B.复习枚举类定义：先定义字段,再注入/构造初始化,再在上方大写字母,括号内填入对应字段值,记得写getter.注意一点！形如A(1,"你好"),B(2,"再见"),;最后是有`,`和`;`的。这一块太久没复习了，遗忘的很彻底。

C.对Netty相关的bootstrap,EventLoopGroup,channel,option,childOption,ChannelFuture等概念做了回顾，整理了知识体系，输出了博客。

D.梳理Broker细节：MethodType细分(生产者的注册和注销,生产者消息单向发送和回传发送(批量),消费者注册/销,消费者订阅/取,消费者主动pull,消费者心跳,消费者ACK状态(批量))。Broker的本质是一个线程，在run方法中注入Netty的组件以及和(生产者/消费者/持久化)相关的业务类。我们想启动Broker，在Test项目中新建一个Broker线程，并start()即可。业务功能是通过pipeline中的某个Handler实现的，这个Handler中注入了和生产者，消费者，持久化，以及消息重试/消息推送等相关的Service。

E.梳理Producer细节：Producer仅涉及(发送),因此用Bootstrap();梳理Consumer细节：涉及到(接收)的服务就应该用ServerBootstrap(),涉及到向Broker拉取信息的服务应该用BootStrap();所以关于"发送"的channelFuture我们可以封装到commons中。

F.优雅停机的设计：传统dubbo上线新功能需要在业务流量低的半夜做，因为rpc调用入口关闭时，当前业务没有处理完。这个场景类似JUC中thread.stop()的困境。我们认为：能够处理完当前业务再关闭自己的策略是优雅的。因此引入钩子函数：先判定当前业务执行时间是否小于(当前时间-开始时间),如果小于则停机,不小于则等待自定义时间再重试。

G.消费者心跳检测：消费者5s给broker发心跳包，broker连续1min没收到心跳，则移除消费者。具体实现还是依赖Netty的channelFuture+定时任务(比如Executors的scheduled池),Broker需要记录心跳的最新访问时间,同时维护和最后一次心跳时间有关的定时清理任务。

H.负载均衡设计：(生产者可以发送给任一Broker/broker可以推送给任一消费者/消费者成功后的ack回执给任何一个broker/特殊消息用shardingkey保障有序性-消息粘连问题)

# 2.4日报

1.LC一道easy：将一个数组转化为-奇数下标指向奇数元素，偶数下标指向偶数元素。策略是维护i=0和j=1分别作为两个子数组的下标，每次都是+=2。当遇到i指向偶数且j指向奇数时候进行i和j元素的交换，同时i和j做+=2

2.单词新增20，复习92

3.工程：

A.MQ的consumer：IMqConsumer接口有subscribe和registerListener两个方法，这里的事件驱动模型=观察者模式+回调模式+策略模式。消费者用subscribe订阅broker的某个topic，消息抵达消费者后触发已注册的Listener(这里的异步触发体现回调),Listener中维护策略集合,根据消息中的策略类型调用对应的handler.handle().

B.SO.BACKLOG和SO.KEEPALIVE的理解：前者是服务端的消息积压队列(服务端监听套接字相关)，比如服务端只能同时处理4条消息，那某一秒钟来了五条消息，余下一条会被积压在该队列中，该参数的值表达可排队等待的最大消息数,比如128。后者与具体的TCP连接相关：某条连接idle了2h,则会尝试向其发送消息,超过11分钟无回应则关闭该条TCP连接。

C.对Handler,ChildHandler,Option,ChildOption做区分。Child的都是和接收的客户端请求相关的组件(SO_KEEPALIVE/SO_RCVBUF)。不带Child是这个端本身的配置(BACKLOG/REUSEADDR/CONNECT_TIMEOUT_MILLIS)，比如服务端本身的配置，客户端本身的配置。DelimiterBasedFrameDecoder这个Handler用于解决粘包问题。

D.RpcMessageDto存储于Broker中：主要：methodType(形如生产者注册，消费者取消订阅，持久化)/Id/时间戳。dto的工作是接受请求并且存储响应。Dto工作的场所是IInvokeService(添加Req,添加Rep,获取Rep)。这里的Rep和Req都在其实现类中维护为ConcurrentHashMap(这样就在内存中实现了消息的存储-我们发现map真的很好用-spring本质就是一个大map-我们的broker想于内存存消息也得用上map)。细节：通过超时检测Thread来定期从Map中移除req。map里存的本质是dto，区分不同的dto到不同map的是dto中isRequest这个布尔值。

E.ShutdownHooks认知：Runtime.getRuntime().addShutdownHook(实现Runnable的对象)，将其封装在ShutdownHooks类中，传入DefaultShutdownHook这个自定义对象。Hook中需要设置invokeService，destroyable，statusManager。然后在doHook中循环等待当前执行的请求执行完成（检查Invoke），之后再调用销毁(执行destroy)，并且设置关闭成功状态（status）。也就是借助JVM的关闭钩子。

F.学习了Fluent风格：在这种风格中，方法通常返回实例本身（`this`），并在返回之前完成将入参赋值给属性的操作。这样可以实现链式调用，例如 `Person p = new Person().age(12).sex("Male").telephone(13822829373);`。因为每次返回的结果都是实例本身，所以可以继续调用实例的方法，从而形成链式结构。需要注意的是，Fluent风格与建造者模式有所不同。Fluent更像是一步一步向奶茶店店员表达需求，而建造者模式则像是填写一个表单给店员，店员按表单内容制作奶茶。最大的区别在于 `setXXXX()` 和 `builder()` 与 `build()` 的使用。Fluent风格中实例一开始就创建好，而建造者模式是先创建一个建造者实例，只有在执行 `build()` 后才会生成最终的实例。因此，建造者模式可以比作是填写表单，只有提交后才能生效。

# 2.5日报

1.LC一道medium：给定一个数组，求其幂集，且数组有重复元素。在传统递归+回溯的基础上做剪枝。具体来说：先给数组排序，然后当相邻元素为相同元素时，for循环continue即可。其他操作与传统的求幂集一致。就是维护一个ans结果集和一个share共享集合。通过在share共享集合上递归和回溯，将中间结果存入ans中，从而完成工作。

2.单词新增20，复习92.

3.工程知识：

A.mq的commons模块：Message字段。从发起者角度有groupName，从broker角度有topic,tags，从消息本身来看有payload数组，bizKey以及shardingkey。

B.学习ChannelFutureUtils：入参为brokerAddress(多个broker地址则需要拆分到List中),channelHandler,check(布尔值：检查broker是否可用)。总的来说：针对每一个拆分出的address：新建一个bootstrap，并且配置对应的channel和handler以及option，完成connect，同步非中断地拿到对应的channelFuture。将其封装到自己设计的rpcChannelFuture中,再将rpcxxx添加到List里。

C.封装ChannelUtil：给定Channel或者ChannelHandlerContext，去取对应的channel的id。

D.封装DelimiterUtil：在Netty中，消息通常会被分割成多个部分进行传输，每个部分之间需要有一个分隔符，以便接收方能够正确地识别和解析消息。`DelimiterUtil`类中的`getByteBuf()`方法接受一个字符串参数，将其转换为一个`ByteBuf`对象。`DelimiterUtil`类中的`getMessageDelimiterBuffer()`方法接受一个`RpcMessageDto`对象，将其转换为JSON字符串，然后添加分隔符，最后将结果转换为一个`ByteBuf`对象。

E.封装：`InnerAddressUtils`类的主要作用是解析一个地址字符串，并将其转换为`RpcAddress`对象的列表。这个地址字符串是一个以逗号分隔的字符串，每个部分都是一个地址信息，地址信息由主机名、端口号和权重组成，它们之间用冒号分隔。`InnerAddressUtils`类首先将地址字符串分割成多个部分，然后对每个部分进行解析，将其转换为`RpcAddress`对象，最后将所有的`RpcAddress`对象添加到一个列表中并返回

F.RandomUtil封装：选择一个服务器进行处理。如果`list`为空，则返回`null`。如果`key`为空，则直接使用`loadBalance`的`select`方法选择一个服务器。否则，使用`key`的哈希码对`list`的大小取模，得到一个索引，然后返回`list`中对应索引的服务器。这个方法在Netty中用于选择一个服务器进行处理。

G.负载均衡复习：

1. **轮询（Round Robin）**：通常通过一个原子类（比如 `AtomicInteger`）来确保线程安全。每次请求到来时，该原子变量自增，取模操作计算出当前请求应分配到哪台服务器。例如，`currentServerIndex = (currentServerIndex + 1) % totalServers`，这里 `currentServerIndex` 负责记录当前轮到哪个服务器，`totalServers` 是服务器的总数。原子类确保了在多线程环境下的并发安全。
2. **最少链接（Least Connections）**：在每个服务器上维护一个连接计数器，当新的请求到达时，选择连接数最少的服务器进行分配。可以通过对每个服务器的连接数进行比对，选择最小连接数的服务器进行请求分配。代码实现中，通常会有一个 `List<Server> servers`，每个服务器对象有一个 `connectionCount` 属性，在请求到来时，遍历所有服务器并选出最小值。
3. **权重轮询（Weighted Round Robin）**：这种算法的核心是结合了每个服务器的权重（Weight），并通过求最大公约数（GCD）来调整轮询频率。具体实现中，通常会用到类似 `gcd(weight, totalWeight)` 来计算权重的比例，`totalWeight` 是所有服务器权重的总和。服务器的轮询次数按照其权重比例分配，权重较大的服务器会被分配更多的请求。例如，`weightRoundRobin(currentIndex = (currentIndex + weight) % totalWeight)`，通过 `weight` 动态调整轮询的频率。
4. **权重最少链接（Weighted Least Connections）**：这是结合了最少连接数和权重的策略。首先计算每台服务器的连接数，然后结合其权重来选择最合适的服务器。伪代码中，通常会是 `server = findServerWithLeastConnectionsAndWeight()`，其中 `findServerWithLeastConnectionsAndWeight` 会优先考虑最少连接的服务器，同时权重大的服务器会更有可能被选中。
5. **源地址哈希（Source IP Hash）**：这个方法使用客户端的 IP 地址进行哈希运算，以此确定请求应该被路由到哪个服务器。常见的做法是取客户端 IP 地址的哈希值然后对服务器数量取模，例如 `serverIndex = hash(clientIP) % totalServers`，这样能确保相同 IP 地址的请求总是路由到相同的服务器，从而保持会话的稳定性。

# 2.6日报

1.算法：力扣一道Medium。使用回溯+递归+剪枝处理有重复元素的全排列问题。策略就是维护两个实例变量，一个套Integer的List,一个套List的List。剩下就是在题设方法中完成初始化。实现swap函数和dfs函数即可。

2.单词新增20，复习120

3.工程：

A.改简历，优化简历描述

B.OIO->NIO的复习：OIO是用while去监听端口有无请求，会阻塞后续请求。用Connection per Thread来优化：虽然后续请求不会被阻塞了，但是线程太多，资源占用太大。NIO就是用Reactor模式：一个线程对应一个selector,一个selector监听多个channel。这样就相较于CPT节约了线程。reactor有点dispatch的意思

C.Netty的主从Reactor模式：BoosGroup维护一个Selector监听ServerSocketChannel接受client请求，新连接被封装为NioSocketChannel,注册到WorkGroup中的selector上，然后走WorkerGroup的Handler

D.EventLoop==TaskQueue+Listener+循环机制。**TaskQueue** 就是订单列表，存储待执行的任务。**Listener** 就像是监听厨房的铃声的服务员，它监控着任务的触发条件（例如事件发生），并在事件发生时，通知并将任务提交到 `TaskQueue` 中。**EventLoop** 就是负责从任务队列中取出任务并执行的服务员，执行任务完毕后，继续等待下一个铃声。

E.复习Jvm：三种年轻代GC器，四个老年代GC器。三种回收算法。三种对象探测方法。用饼和川和吐饼来记忆。CMS是延迟特性,G1是均衡。S和Z(蛇和贼不分代)。

F.复习类加载的七个阶段，复习双亲委派。有效防止自定义String类被成功加载。

G.复习直接映射-内存文件映射-零拷贝技术：本质就是用户态和内核态，用户态有应用程序，内核态有PageCache和Socket缓冲区。

# 2.7日报

1.算法：力扣一道medium：螺旋数组。策略是维护l,r,t,m四个边界，在一次where循环中执行四个for循环，分别填充从左到右 从上到下 从右到左 从下到上 以及每次填充完一行或者一列后得向中间压缩范围。

2.单词新增20，复习82

3.工程：

A.复习SQL：三个窗口函数(1.rank() over (order by xxx 顺序)2.dense_rank() over (),3.row_number over())：很好记忆：rank和dense_rank都是相同排序值的并列,前者允许1 2 2 4,后者允许 1 2 2 3。row_number就是值一样也不会并列,而是按顺序1 2 3 4。

B.复习SQL的函数语法/考虑null值情况则写嵌套select/复习from多表和join区别,前者生成的是笛卡尔积,应该少用。/复习分组查询：对于查找某个参数>某个量的情况，常见策略是自连接，或者分组用having来查。

C.学习大表的SQL优化：导入dump耗时较长，20w行数据的导入时间约莫在30s左右（16G运存）。

D.explain的参数学习-阅读执行计划：type很重要：要尽量避免all。index表明查询使用了整个索引但还需要扫描所有索引。不走索引肯定慢，所以ALL是最低级的。走非唯一索引得分三种情况，走完全部索引就是index，因为走完了，所以也慢。 Range是对索引列范围查询，只走了部分索引，所以会快一些。Ref是对索引列做等值查询，比Range还快。而Eq_Ref是走唯一索引的关联查询，因为关联所以有一些开销，但是因为是唯一，所以比Ref快，而Const是唯一索引做等值查询，而且还不关联，那就更快了。所以就速度来说：All<Index<Range<Ref<Eq_Ref<Const

E.复习：innodb的存储结构：聚簇索引树/二级索引树/回表/索引下推/覆盖索引复习。

# 2.8日报

1.算法：力扣一道medium：从左上角走到右下角的路径总数+存在障碍物情况。使用二维DP，只考虑从左边转移和从上面转移。使用虚拟列将起点的情况统一到全局算法中。如果起点为障碍物，则起点为0，如起点不是障碍物，则从虚拟列转移一个总数1过去，从而完成初始化。

2.单词新增20，复习98

3.工程：

A.SpringWebFlux：Handler/RouterFunction/HandlerFunction/Mono和Flux相关API/响应式编程的异常捕获处理

B.复习：（Connection来源：DriverManager/DataSource）(Statement的execute获取ResultSet,getMetaDate()可获取Set的字段数量，字段名称，字段数据)（Wrapper/CallableStatement/PreparedStatement）（框图：Connection到三种statement分别是createStatement,preparedStatement,prepareCall,且三种stmt都可以执行execute,且stmt为爷,pstmt为父,cstmt为子）

C.Druid连接池复习：直接的conn是150ms,连接池是5ms.内存开销如果前者是1G,后者大概200m.性能瓶颈是前者的二十倍.

D.Mybatis回顾：Mybatis回顾：首先读取`mybatis-config.xml`到内存，并利用其配置创建`SqlSessionFactory`。然后通过`SqlSessionFactory`的`openSession()`方法获取一个新的`SqlSession`，接着通过`SqlSession`的`getMapper()`方法加载对应的`Mapper`接口。执行`Mapper`接口中的方法后，通过`sqlSession.commit()`提交事务，最后关闭`inputStream`。
E. 读SqlSession源码，复习以下方法：selectOne、selectList、selectMap、selectCursor，了解其作用与实现；插入、更新、删除操作方法，如insert、update、delete，以及事务控制方法，如commit和rollback；掌握getMapper、getConnection、getConfiguration的使用。理解SqlSessionFactory与建造者模式的关系，分析mapper的代理类实现与mapper标签解析过程。

# 2.9日报

1.算法：力扣一道medium。给定数组，去除重复元素，每个元素最多保留2个，要求空间复杂度为O(1)。策略是：原地操作+模拟栈。我们先设定stackSize=2,然后for循环从2开始,如果当前nums的i号元素与stacksize-2号元素相同，则不允许进入栈，反之则压入栈中(nums的stackSize号元素设置为该元素)，同时让stackSize自增。通俗来说：就是不断的在数组中移动i+1号元素到i号元素上，且i+1要满足nums[i]!=nums[stackSize-2]。

2.单词：新增20，复习92

3.工程：

A.复习传统定时任务：ScheduledExecutorService以及Spring集成@Scheduled(fixedRate = 1000)+配置类@EnableScheduling，复习corn表达式。理解Rate和Delay区别。

B.复习Redis的常见命令-(info/client list/save/bgsave/lastsave/bgrewriteaof/flushdb/flushall)/复习lua脚本的定义与执行,multi和exec的事务/复习数据结构的crud(string/set/hash/zset/geo/streams/list/HyperLog/bitmap)/save产生rdb文件/恢复数据将rdb安装目录即可,config get dir来获取安装目录/bgsave后台跑

C.Redis八股复习：

- Memcached弱于Redis：结构单一/无持久化/无原生集群/用阻塞读取而非Redis的reactor模型/value值是redis的1/512MB
- ZsetVsList：后者基于链表,访问两端快中间慢/前者基于散列和跳表,访问均是LogN/前者可以简单调整元素位置,前者更消耗内存
- Redis内存优化：多个key-value尽量存hashes中,hash的内存开销较小.
- keys与scan：由于redis单线程,前者导致线程阻塞,后者渐进式,每次O(1).但后者无法保证遍历所有key,因为考虑在遍历时有新增key
- redis事务不保证原子性,没有回滚,有事务内命令失败,其余命令继续执行
- RDB存的是内存中的key-value,AOF存的是具体的命令内容。RDB不能实时持久化,且bgsave每次都得fork子进程,重量级操作不能频繁执行.且RDB用二进制存,Redis不同版本的RDB不兼容/AOF自动30s一次/Redis重启会重新执行AOF中命令-AOF解决实时性,AOF默认不开启(appendonly)-开启后朝着aof_buf写数据,缓冲区30s同步一次
- 单机/主存/Sentinel/Cluster
- 缓存预热/缓存击穿/穿透/雪崩/双写一致性/RedLock/大Key和热Key处理/ClusterSlot的分析(16384)

# 2.10日报

1.算法：LC一道medium：维护短连接。本质是维护两个hashmap,分别表示从长连接到短连接的映射关系以及短连接到长连接的映射关系。我们维护一个`a-zA-Z0-9`的string,通过random与长度为k的char数组来随机生成k位后缀.同时设计prefix在前构成短连接的url,形如`https:asthenia.com/tags/ewr2dw`。使用两个map确保每一个LongAddr对应唯一一个短连接(避免hash冲突)

2.单词：新增20，复习119

3.工程：

A.写简单项目，基于Spring的@Scheduled+cron的定时任务与Spring对SPI的封装。开发了支持application.yml读入内容的定时任务starter,在测试项目中实现功能,输出了视频与博客,上传仓库，积累了依赖开发经验。

B.Auth模块：着重梳理Auth部分业务逻辑。1.复习orika的MapperFacade，实现RefreshTokenDTO入参在续约成功后,转化为RefreshTokenVO并包装返回给前端。 2.@Valid是触发javax.Validation对入参约束的依赖,入参约束例子：@NotBlank直接修饰在dto的字段上 3.登录和登出都切记要清理菜单权限缓存 4.复习双token(AToken短,重要信息多,RToken长,重要信息少.后端告诉前端Token过期,前端先不告诉用户,而是拿RToken去找后端要Atoken,RToken没过期则要到,则实现无感刷新-核心还是权衡用户登录体验与敏感信息网络传输)

C.订单模块：1.RocketMq的延时消息-订单30分钟不支付自动取消/Seata全局事务与回滚/锁存消息

D.支付模块：1.Feign调用segment服务就支付业务生成id 2.Feign调用Order查询订单金额 3.订单如果还没有关闭(30min内)则生成支付信息，返回给前端，前端根据支付信息调用支付宝or其他平台的API。

4.效率较低，看不进代码，精神比较疲惫，能力不及预期，知识和实战经验的积累速度太慢了，会被淘汰的，休息吧，明日再看，会赢的。

# 2.11日报

1.算法：LC一道链表。给定单链表，要求删除结点，仅保留左侧无比其更大的结点。策略是dummy结点+ArrayDeque维护的单调栈。单调栈的核心是：while判定新元素是否比栈顶元素大，如果大，则删去栈顶元素，直到栈顶元素比当前元素小，从而压入当前元素，并且建立当前元素与先前栈顶元素的链表联系。这里相当于从栈顶到栈底单调递增。循环对不符合要求的栈内元素出栈是关键

2.单词新增20，复习119

3.工程：

A.修订简历项目的细节描述

B.学习Python语法：元组，列表，集合，字符串，数，字典的相关API，做较多的Coding练习形成肌肉记忆。学习Python的推导式语法糖

C.学习ThreadLocal、InheritableThreadLocal与TransmittableThreadLocal：线程池场景下的数据传递实战。要从单个线程和线程池复用的思路来看待三种容器的优劣。1->2优化了子线程不能共享父线程context内容的缺陷,但是线程池复用时仍然会导致两个子线程共享相同的context内容。2->3的优化：先建立线程池，只要分别在两个线程开始前对context做不同的set，两个子线程的context就不痛。2->3的优化解决的痛点是线程复用导致的context污染。

D.BigDecimal：从实现机制分析入参为何得是字符串&&CompareTo与Equals：回顾浮点数的定义，在二进制中的0.1和十进制中的1/3一样,无法被准确表达,导致3.14的实际值是3.1400000000000000000000000000012。而BigDecimal实现高精度的本质是：3.140化成中间值3140,显然对于上面的值,产生的临时变量比2^63 -1还大,导致BigDecimal不准确.因此定义时应用字符串入参,而非纯数字入参。然后就是compareTo的源码加入了精度的校验,强于equals.3.140显然在精度比3.14更高

E.电商业务场景下的HTTP状态码深度解析：这一块主要补充1xx为协议升级，比如websocket全双工。以及301永久重定向和302临时重定向

F.电商SEO优化：重定向的秘密与Spring Boot实战。301和302两种重定向的原因：从用户角度，对于用户已经保存的网页，随着商品的迭代删去旧的网页会导致用户流失，从搜索引擎爬虫来看，频繁删去网页会导致搜索权重降低。因此通过重定向来解决。301一般是做永久的商品重定向，302常用于活动重定向。比如某个页面在圣诞节重定向到圣诞促销，在儿童节重定向到儿童促销。复习相关的RedirectView和ResponseBody的header中的location与redirect

# 2.12日报

1.算法：LC一道medium。给定数组，nums[i]表示第i个袋子中的小球个数，给定k为最大操作次数。允许你将nums[i]按照某个整数值做拆分，要求最终拆分结果：每一个nums[i]尽可能小。策略是写check方法。传入nums,k,mid值。mid值来自对nums中初始最大值和最小值的二分。累加（nums[i]-1/2）/mid累加到总和。走完nums若总和<=k则return true,允许二分右边界压缩到mid位置，最终返回右边界值。这题抽象之处在于：被二分的不是数组，而是数组的最大值和最小值之差。

2.单词新增20，复习119

3.工程：

A.Python的装饰器,方法,类，模块化部分。以及做较多的代码训练熟悉python语法

B.HashMap源码再读：死环问题、源码设计与面试高频考点

C.复习Synchronized锁升级与ReentrantLock/AQS原理

D.复习ReentrantLock源码：从组合模式到AQS

E.复习AQS，以及其衍生出的ReentrantLock、Semaphore与CountDownLatch的源码差异

F.复习Redis缓存淘汰策略源码，做了LRU、LFU与TTL的实现分析

G.学习线上故障排查思路：从跳板机到日志分析

H.学习SSH-SCP-TAR。这一块强调：脱离finalshell，用纯命令行方式连接远程服务，需要依赖OpenSSH。以及通过SCP命令来进行本地和远程服务器的数据交换。复习tar的-v -c -x -f -z等参数。

# 2.13日报

1.算法：一道medium。在[a,b]中生成数字,将数字重组为各项之和,作为一个小球投入之和的篮子.问球最多的篮子中的球数.形如101和110会投入一个篮子,因为计算结果都是2.策略是先写辅助方法,通过/10和%10计算各项之和,再用hashmap建立数和频率的关系，通过打擂台找出最大的频数

2.单词：新增20，复习108

3.工程：

A.重新复习MQ项目，梳理项目结构，完善简历关于MQ的项目描述，做第六版简历

B.学习Python的异常处理，学习自定义异常，比较其与Java的差异。学习Python的输入输出。

C.复习Java 线程池：参数、拒绝策略与常见问题

D.复习Java Stream ：去重计算、CollectToMap 冲突解决与常用操作

E.学习电商秒杀场景下的布隆过滤器与布谷鸟过滤器实战：特别是学习布谷鸟过滤器

F.学习排序算法的稳定性定义：冒泡/归并/插入是稳定的，其他是不稳定的。

# 2.14日报

1.算法：一道medium：一道二分。策略是通过二分找到mid,mid作为某个场景的参量x,通过对x的true或者false,决定left和right的变化。对于闭区间[l,r] l=m+1 r=m-1.最后返回r或者l-1即可。

2.单词新增20，复习119

3.工程：

A.复习SQL解析执行顺序

B.Jedis,Lettuce,Redission的API复习与RedisTemplate对其的抽象

C.HashMap1.7的死环问题-没太看懂,下回继续看,原因主要在头插法

D.XA-AT-SAGE-TCC四种分布式事务复习

E.写SQL题

# 2.15日报

1.算法：一道medium。给定二维数组,每一个column对应一颗小球,每一个小格值为1则将球导向右侧,值为0则将球导向左侧.且导板构成V时小球不可到达底部。规定只有到达底部的小球可以用col为返回值，否则为-1。返回数组,索引为小球序号,值为小球抵达之处。策略是先遍历小球,再逐层遍历,针对V型和左右越界情况赋值为-1,其他情况推进col,最后将col存入数组

2.单词：新增20，复习110

3.工程：

A.Numpy学习-Python的文件流学习

B.读姜宇的Seata书,这本书还是令我受益颇多。其一是来源很明晰，从阿里早期的GTS到后来的Seata，对这个中间件的迭代过程做了较为详细的介绍。同时从业务出发，逐步思考如何设计一款低耦合,侵入式低的分布式事务方案。这种思维方式值得学习。余下的精力主要用于理解Seata的架构设计,以及代码的具体实现,读起来还是颇费时间的。

4.总结：

开学了，课时冗余多。应当将上学期购置的许多技术书籍进行阅读了。两本大juc书上学期只是草草略读，Seata这本今日读了几章。另一本Raft共识的书还尚未翻开过。寒假的学习更多是针对面经做高频考点的复盘，但单点的知识是不成体系的。相较于阅读零散的博客，阅读成体系的书效果更佳。上学期将太多课程堆积在期末复习，并不可取，现在应当每日温水煮青蛙的积累，当合理调控备考时间和项目时间了。

# 2.16日报

1.算法：一道easy。给定乱序一维数组，要求原地修改，数组元素修改后结果为其右侧最大值。且若右侧没有值,则修改该元素为-1.看到侧和最大值，第一思路是单调栈，第二思路是打擂台+双层嵌套O(n^2)，第三思路是从右往左打擂台(On)。显然第三思路合理。则初始化max=-1,每次循环分别存储当前nums[i],将nums[i]赋值为上一轮循环产生的max,用存储的修改前本轮nums[i]和max进行贪心。

2.单词：新增20，复习121

3.工程：

A.复习TCC和AT的机制

B.复习MySQL索引失效的二十种场景，归纳为：1.索引顺序性被打破 2.索引被修改(在where中用函数,使用隐式转换) 3.优化器的选择(is null导致全表扫描,or连接索引与非索引字段导致全表扫描等) 4.联合索引的性质(最左匹配,联合索引出现范围查询导致后面的单索引失效..)

C.学习传统%x%的弊端,引入FullTextIndex,分析其数据结构

D.学习Innodb选择B+树原因，分析红黑树和传统B树的弊端。

E.复习MinIO+Vue+SpringBoot实现前后端文件上传的逻辑，复习了相关的代码细节。形如MultipartFile和http头文件的格式，形如Java对MinioSDK的集成（MinioClient）。形如在Linux上通过docker+镜像代理的方式部署Minio服务。

F.预习明日操作系统课程书籍。

# 2.17日报

1.算法：一道easy。给定一维有序数组，返回第一个元素出现次数>数组长度1/4的元素。策略是维护HashMap,然后用Entry的value找到对应key,返回key即可。

2.单词：新增20，复习109

3.工程：

A.Linux命令复习：文件/文件夹/用户/用户组/解压缩/三种权限设置/内存与储存查询/shell基础/服务器巡检脚本设计/

B.Redis数据结构复习：SDS/ZipList/链式哈希

C.学习Vmware的桥接模式/NAT模式/仅主机模式,切记默认为NAT,内可访外,外不可访内

4.总结：

整体效率非常低下，陷入了细枝末节的死胡同。明日继续看redis和mysql的原理。

# 2.18日报

1.算法：一道medium。给定一维数组ans，查询数组。查询数组分别为[left,right,target]。目标是在ans中查出在[left,right]之间有多少个target值。策略是map+二分。二分的返回结果是下标，然后对下标做类似前缀和的作差，求得结果。

2.单词：新增20个，复习118个

3.工程：

A.SpringBoot与Spring的原理复习：补充Secruity的细节/复习@ControllerAdvice+@ExceptionHandler的全局异常处理机制/复习Springboot的启动原理,以及Autowired相较于构造注入的劣势/复习Spring的scope,补充session,request,servlet三种级别,以及prototype和singleton在生命周期上的区别/复习SPI与类路径and类加载器

B.Mybatis的启动机制/分页插件的配置/JPA的API复习/#和$/

C.MySQL的binlog/redolog/undolog复习/mvcc/事务隔离级别...

D.电商项目梳理业务模块：RBAC模块+Products+user模块做了一轮梳理。

E.Python-Pandas

# 2.19日报

1.算法：一道medium。给定二维List，其中有m个List<Integer> ，任意两个List中的任意两个值的距离为|x-y|，且一维List有序，求最大距离。策略就是取出每个一维List的最大值和最小值，然后拿pre和cur的min和max进行差值运算，然后重新设置pre的max和min,就是纯粹的贪心

2.单词：新增20，复习109

3.工程：

A.学习操作系统：内核态/用户态/虚存和物理内存/Linux与Windows内核比较/段页式

B.JDK动态代理/cglib相关

C.复习MySQL执行流程/记录的存储结构/BST->AVL->RedBlack->B->B+/B+树的页存储结构等/explain参数分析,type分级(all->index->range->ref->eq_ref->const)等/索引失效原理->特别注意>=在复合索引中不会因为(a,b)中的a出现范围而导致b不走索引,between and同理也是闭区间。

D.项目整理：platform,payment,order,multishop业务梳理。

# 2.20日报

1.力扣：一道easy。给定一个十进制数n，如果分析其二进制数，且索引0在最右侧，将其二进制位构成一个数组。问其中值为1的奇数位和偶数位分别为多少。策略是维护hash数组,key为奇数or偶数,value为累计值。然后key用初始化为0，每次循环都对key做异或，保证在偶数为0，在奇为1。并且让value为1&n，然后不断做右移。

2.单词：新增20，复习89

3.工程：

A.复习MySQL的索引结构+MVCC+ReadView+事务隔离级别的原理

B.Elasticsearch的DSL复习

C.SpringBoot的拦截器和过滤器原理

D.SpringMVC原理复习——SSM配置复习

E.Jvm参数复习，常见的Jvm调优参数，Jvm日志收集和生产环境要注意的增强参数

F.项目集成GC日志输出分析。

G.梳理电商项目的支撑结构

H.简单了解了codespace，学会在vscode下部署springboot服务和配置maven。

# 2.21日报

1.力扣：一道medium。CodeTop的频率最高一题。最长无重复子串。策略是左右指针维护滑动窗口+map存储值和下标。只有当某一个值对应的下标存在于map中，说明此时有重复的值，则让左指针移动到值+1的位置,注意此时需要做贪心,让左指针尽量往右走。对滑动窗口的理解是：一般是右边先动，右边遇到特殊情况左边界动。

2.单词：新增20，复习92

3.工程：

A.复习MySQL：全局锁/表级锁(表锁,元数据锁,意向锁,auto-inc锁)/行级锁(record,gaplock,next-keyLock,插入意向锁)

B.写C课设

C.项目经验：IDEA编译不支持发行版本7——修改maven的 `project.compiler.level`到1.8+,升级maven-compiler-plugin到3.11+。切记clone的项目会因为pom中预设的jdk版本过旧，导致无法和本地的jdk协同工作，出现问题。

D.url输入后操作复习：域名解析(浏览器->系统->路由器)/递归查询（根-顶级-权威）

E.整理轮子项目的面试预设：Producer的消息重试实现，shardingkey保证batch消息的顺序性和一致性，以及callServer细节分析。Consumer的Pull模式分析，这一块整理的不多。

F.学习Nginx对图片资源的缓存：通过 location /路径 在其中add_header：实现Cache-Controll和Immutable管理。学习协商缓存的"Last-modified和If-modified-Since"以及"Etag与If-None-Match"。前者是按资源的修改时间来判定是否需要重新拉取缓存，后者是看资源的hash指纹是否一致，不一致则拉取缓存。后者优先级高。数据未变更都是返回304。整体复习了Nginx的功能。

# 2.22日报

1.力扣：一道medium。排序返回第k大元素(数组)。做计数排序即可，时间复杂度在On。策略是利用哈希表索引的有序性，让原数组的值做哈希表的索引，哈希表的值记录该元素出现的次数，然后累加器累加出现次数即可，累加器值>=k就返回索引，注意下标考虑负数情况，数组要覆盖给定的数据

2.单词：新增20，复习89

3.工程：

A.C语言课设完结

B.复习SpringIOC容器：IOC完成初始化，我们完成实例化。

C.复习循环依赖与三级缓存相关

D.学习Aware(BeanName,ApplicationContext,Environment,BeanFactoryName)以及等价@PostConstruct和@Predestroy的两个接口：InitializingBean和destroiedBean

E.复习守护线程

F.复习Linux和Docker部署Nacos单机，关于配置管理的实践

4.总结：今天涉及的知识点较少，挖的比较深，效率一般。

# 2.23日报

1.力扣：一道easy：翻转链表：分别递推和递归两种写法。前者使用pre和cur两个指针进行相邻翻转。后者的recur方法中分别传入pre和cur，并提供一个cur为null时return pre的递归出口

2.单词：新增20，复习79

3.工程：

A.复习缓存一致性：旁路缓存/写穿and读穿/写回

B.复习缓存击穿的解决：逻辑过期的功用

C.复习SKU和SPU的表结构设计：预制面试题

D.复习SpringMVC的V部分：复习ViewAndModel以及ViewResolver与Jsp的功用

E.复习购物车的实现——Redis中的String结构，同时采取Json的方式存入String

F.复习FastJson,Jackson的差异，以及前者的不足。复习在SSM中如何配置指定的conventer

G.学习对Jackson封装：(对objectMapper的封装)形如Json.parse()。复习RedisTemplate中对keyOrValue序列化器的处理。

# 2.24日报

1.力扣：一道medium。给定一维数组，你可以任意划分连续的子数组，要求找出值最大子数组的累加值。策略是维护临时sum和全局ans。如果当前sum比0小则用sum替换，若比0大则sum+=num,每一轮都在ans上做贪心

2.单词：新增20，复习119

3.工程：

A.学习操作系统：malloc对内存的分配策略/内存满后的处理方式/4GB机器申请8GB内存的结果/预读失效问题(innodb是yound_old连续lru,linux是active-inactive两个lru)

B.Mybatis复习——具体的crud与动态SQL标签：choose,when,otherwise/if/set/trim/foreach等.....。上手crud了较多的案例，增强熟练度。

C.Mp复习，Wrapper的crud

D.复习Springboot:使用的设计模式/自动装配原理/常见starter复习以及自定义starter/mybatis启动流程

E.学习Spring事务传播与失效机制：这一块考频太低了，去年的二月份有涉及，但是遗忘太多，平日里很少在面经看到这点，今日算是补上了。

4.总结：效率极低。

# 2.25日报

1.力扣：一道medium。岛屿数量：DFS是朝着四个方向递归，递归出口是当前为海洋orx或y超出边界。每走过一个位置，则该位置从陆地变为海洋。

2.单词：新增20，复习109

3.工程：

A.JavaSE的八股背诵——从基本语法到集合细节

B.复习Lambda与Comparator中的比大小规则

C.学习Mybatis,PageHelper中自定义PageUtil的逻辑

D.学习Myabtis拦截器细节——实现基于注解的Leaf分布式ID与符合阿里规约的公共字段自动填充

E.学习Mybatis拦截器参数——Invocation相关

F.学习MySQL查询具体语句的执行时间：通过配置general_log。

4.总结：效率一般，主观上比较焦虑，客观上无可奈何。

# 2.26日报

1.力扣：手撕LRU：关键点是使用hashmap存储key-DLinkedNode以及构造双向链表，并且实现其中的：头部插入/尾部删除/中间删除。在业务层的put和get方法：需要考虑：当一个元素被get或一个已存在的key要更新新的元素，则需要调用先前自行设计的链表方法，将当前元素从当前位置删除，并且插入到头部。在put中特别要考虑：如果是新增元素，则要考虑淘汰LRU末尾元素，这个淘汰伴随着map中的缓存删除。在构造双向链表时：切记使用head和tail两个dummy节点。以及以"礼貌"的思路去增删双向链表和周围元素的指向关系，切记是自己先示好，左右节点方会回礼(以左右节点为主体指向插入元素/这里无法表示右节点,则左节点的next表达应该滞后些)

2.单词：六级裸考顺利通关，但是专业相关的技术博客对英文要求较高，还是需要继续保持单词记忆。单词新增20，复习119

3.工程：

A.完成业务项目的Seata部分与Leaf-Segment的表述重构，增加在一定QPS下接口的响应时间/回滚时延结果，实现量化表达。同时着重复习项目的上述两个部分，输出博客。

B.学习：就Setea提供的RootContext获取当前线程的XID，并通过RequestInterceptor添加到Feign调用的具体Header中，切记：该部分需要避开鉴权接口。

C.复习八股文：集合_ArrayList和LinkedList,HashMap和HashTable。线程安全的容器类相关。这一块花费时间较久，主要是定期refresh记忆，确保记忆不出现偏差。

D.复习八股文：JUC相关：从多线程到并发安全/多种同步器比较/AQS与Sync的底层原理.这部分的学习同C项，温习时间较长。

E.复习操作系统：DMA技术与零拷贝技术的实现。

4.总结：

今天的学校课程较多，具体就代码来学习的时间较少，只能做更多的原理性知识学习。明日课程较少，需要继续优化简历描述，量化成果指标。算法停止做新题，开始重点复习Hot100常见题型，目标是做到抓牢，抓实，胸有成竹，倒背如流。

# 2.27日报

1.力扣：层序遍历：ArrayDeque+双重List解决

2.单词：新增20，复习109

3.工程：

A.背八股：并发安全/线程池/场景题

B.MQ项目接入Retry的实践总结：构造器模式+命令模式+模板方法模式

C.学习Jemeter+SpringAOP实现指定接口在高QPS下的响应时间统计。

D.完善MQ项目：Producer的Retry一集单条发送，批量发送的笔记归纳/Consumer的Push和Pull模式的实现

E.修改简历：量化描述

4.总结：效率比较低，看复杂工程代码看的头晕，封装太多了，层层包裹。感觉八股还是不太扎实。

# 2.28日报

1.力扣：medium：手撕快排：A.实现数组内通过索引交换元素的swap方法 B.实现partition方法：随机选择基准元素，基准元素和left元素交换位置，设定i为left+1,j为right,i往右j往左。在i<=j的情况下，只要i指向元素小于基准元素，i就自增。j则是j指向元素比基准元素大则j自减。余下的情况则交换i和j的元素，因为此时基准左侧有大元素或基准右侧有小元素。C.实现quick递归方法，首先取一个idx，然后idx左侧和右侧分别quick即可。quick中的idx通过partition获取-拿到基准元素的索引

2.单词：新增20，复习129

3.工程：

A.复习MySQL的Innodb层+三种日志的实现细节

B.修改简历的MQ项目细节，做一些增删

C.整理MQ的Topic+tag二级消息过滤实现——复习Regex+预设项目重难点-转义考虑不周全

D.整理消费者心跳功能：需要从Broker和消费者两端来分析

E.整理消费端ACK机制：结合Retry：整合命令模式/构造者模式/模版方法模式

F.整理Broker消息持久化——本质是维护concurrentHashmap,同时对消息继续做封装,存储消息消费状态等元信息，且存储在一个List中,该List和从消息中获取的topic共同构成map。也就是topic为key，该topic涉及的消息的包装对象都存储在List中。

4.总结：早上睡到九点半，连着两堂课结束已是下午四点。匆匆刷完两道算法，吃个晚饭，整理项目细节。今天整体来讲没什么系统化的知识输入，上午的课上倒是吸收了点理论知识，体育课就纯浪费时间了。中午背个单词50-60min就过去了，我的时间利用率还是太低了。三月份了，时不我待。

# 3.1日报

1.力扣：三数之和：需要考虑重复情况。A.先做排序B.先定k元素,且k元素不可大于0,否则break,注意重复情况。接着双指针相向靠近,考虑一下重复元素情况即可。然后分sum大于，等于，小于考虑。

2.单词：新增20，复习109

3.工程：

A.MQ：消费者的subscribe和unsubcribe场景梳理

B.MQ:appKey和appSecert鉴权实现

C.MQ:Broker为消费者Push模式提供的超时响应和最大推送次数设计

D.MQ:methodType做Dispatch实现解耦+基于scheduledExecutorService的心跳检测

E.复习网络分层：OSI七层+TCP/IP四层

F.复习TCP/IP的网络分层与数据包封装，基于微信发送图片的例子

G.复习TCP,UDP,IP协议的设计思路,从朴素到复杂,先预设简单版本,再根据实际需求增加成分

H.复习垃圾回收策略：标记-清理/标记-复制/标记-整理/分代收集

I.复习Jvm和GC相关的参数

J.复习基于Mybatis->Interceptor和TypeHandler的公共字段填充实现

K.学习Mybatis-plus和Mybatis就公共字段填充的差异

4.总结：效率一般，MQ项目基本一轮总结的差不多了。明天开始总结业务项目，这一块难度是很高的，保持心态，稳中求进。

# 3.2日报

1.力扣：全排列：回溯+递归。记得使用布尔数组记录某个元素是否被释放/占用。dfs调用之前为回溯，之后为递归。dfs内注意递归出口与for循环即可

2.单词：新增20，复习119

3.工程：

A.复习ArrayList的两种初始化：Arrays.asList和new ArrayList<>()：如果都是传入num.length且nums.length==16。前者是capacity=16 后者才是size=16。

B.复习RedisTemplate和Jackson的配置细节

C.复习RBAC与Redis的关联

D.复习AntPathMatcher在实现RBAC中的作用

E.学习使用anji-captcha给项目接入验证码功能

F.学习将图片放入jwt中进行传输：png可以用base64编码，这是新知识点

G.学习Mapper接口不需要实现类的原因：JDK动态代理

H.学习Mybatis的插件定义，以及自定义插件策略
I.学习MapperXML拆分为Java代码的操作，譬如BoundSQL，同时复习相关的SqlSession组件，譬如三种Executor，ParameterHandler,ResultSetHandler,StatementHandler.

# 3.3日报

1.力扣：锯齿遍历二叉树。层序遍历基础+奇偶判别+Collections.reverse()即可ac，100%的板子套路题。

2.单词：新增8，复习129。六级词汇结束了，没想到六级词汇的结束是在六级通过之后。继续复习这一块吧。

3.工程：

A.刷操作系统面试题：用户态or内核态/进程管理/锁/内存管理

B.刷Jvm面试题：内存模型/类的初始化与类加载/垃圾回收/

C.补知识漏洞：List.add(new ArrayList<>(ans))与List.add(ans)：前者是深拷贝，后者是浅拷贝。这一点一直疏忽

D.学习银行家算法：从朴素的分配模式推衍其弊端，从而逐渐迭代出银行家算法

E.复习CMS：从可达性出发，对CMS的理解更深刻了

F.复习G1：从简单的标记清除到分代策略与记忆集-理解更深刻些。

G.系统化梳理：从朴素到具象的思路学习Linux中的匿名管道和命名管道。

H.学习Linux文本处理命令：形如wc awk，进行了较多的练习，同时复习了cat与tail head grep等常用命令。

4.总结：我仿佛时刻处于一场对抗遗忘的拉锯战中。去年的今天，我似乎也在学习相同的内容，偶然瞥见飞书文档里2024年3月的PDF记录，才意识到已经过去整整一年。距离敲下第一行Java代码，也已一年半有余。这一年半，我吸收了太多太多的知识：从语言的基础，到框架的原理，再到架构的设计——尽管其中不少只是纸上谈兵的技巧。这一年半，我刷了四百多道算法题，可如今大多已忘得一干二净，只剩下零星而琐碎的题感残留脑海。我发现自己的人生仿佛被困于一个圆圈，周而复始地复习着同样的东西，连第几轮都记不清了，只是机械地重复，在一个既定的知识体系里反复游荡。偶尔，能惊喜地捕捉到某个曾被忽略的细微要点，这或许是唯一的慰藉。我认为最危险的心态莫过于自满，而我现在显然已深陷其中。我停滞于八股文的机械学习，却迟迟未能投入足够的时间，去逐行深究框架的代码。然而，我时常又陷入一种纠结：究竟是背诵现成的八股文，还是钻牛角尖地研究那些性价比未必高的代码本体？权衡是一门艺术，而纠结则成了生活的常态。

# 3.4日报

1.力扣：ACL问题：两个节点的最近公共祖先：先考虑p和q在祖先两边，再考虑p为祖先或者q为祖先（left为null则return right）因为p和q一定在树中。这个递归有点难想到。

2.单词：新增89

3.工程：

A.学习在Debian中安装Vscode：解决dpkg的Path问题，学会使用gcc

B.学习select,poll,epoll的系统调用以及对应的lib，就基于三种系统调用的服务器代码做了剖析

C.复习Linux监听系统资源和网络变化命令：(ps aux/free -h/df -h/top/netstat -tuln | grep :80/watch -n -2 "命令")等。做了一些实操训练，塑造常用命令的肌肉记忆。

D.复习Jvm中对象的结构以及内存对齐的原因：以Boolean类型为例。内存对齐需要补到8byte倍数：便于jvm寻址。

E.复习String.intern()：注意"+"的底层是StringBuilder的链式调用

F.复习栈帧的结构：这一块的记忆得和用"复杂的方法"加固。比如某个"存在递归调用虚方法行为且需要捕获异常的方法"。就能让人被动记住：局部变量表+操作数栈+动态链接(#3这种符号引用通过动态链接变成0x314124这种直接引用-事实上这个过程往往伴随多态,比如eat()这个方法的符号引用是#3,在具体执行时要根据调用者的类型,是cat还是dog,来决定调用#3对应的eat()的哪一种实现,是吃骨头还是吃鱼)+方法正确返回地址。

G.整理项目Leaf-Segment部分原理+测试数据。

H.复习数据库连接池：核心就是一句话，包装DataSource(@Bean注入)，然后将其传到SqlSessionFactoryBean的setDataSource()入参中去。看到DataSource马上想到连接池。

I.整理项目Seata接入部分：对涉及XID字段的Feign调用统一添加XID头信息，对于TM的事务异常定义全局捕获机制，触发回滚，完善简历该部分描述，修改量化指标。复习Seata配置文件，理解tx-service-group、vgroup-mapping、data-source-proxy-mode差异。

4.课程：

A.写数据通讯作业

B.Py课：看numpy的文档，跑demo和记api。

# 3.5日报

1.LC：最长递增子序列：把握子和序列。通过dp实现。定义dp[i]为以i索引结束的子序列长度，dp+贪心即可。

2.单词：复习109

3.工程：

A.复习JavaSE之数组与字符串：String源码分析/如何定义一个不可变类

B.复习JavaSE之OOP部分：native方法demo/instanceof/零散知识

C.复习JavaSE之集合框架：整理List,Set,Queue和Map的UML结构/学习LinkedHashMap,TreeMap,ArrayDeque,PQueue的原理/Iterator和Iterable区别/原生集合在Foreach中的remove陷阱/Comparable和Comparator

D.复习JavaSE之IO：概览/File的三种构造与常用方法/Apache和Hutool/Fis和Fos与Buffer写法/字符流(字节流中文乱码问题)/缓冲流/转换流

4.课程：

A.编译原理CFG相关题目

5.总结：看了较多JavaSE，这一块零散知识点的记忆很碎片了，需要定时复习。

# 3.6日报

1.LC：删除链表倒数第k个元素。使用快慢指针：让快指针移动到尾结点时，慢指针的下一个元素就是要删除的元素。

2.单词：复习89

3.工程：

A.复习序列化机制：Serializable与Externalizable

B.复习StreamAPI与懒加载

C.复习从HashTable到ConcurrentHashMap的锁的使用演进

D.学习DHCP，学习Linux配置DNS操作

E.复习JSP：Servlet和Filter相关，以及复习相关的API

4.面试：

A.初面某小厂，比较紧张，面试官态度尚可，更多时间是在给我介绍业务，完全没有拷打我的简历，一面仅问了基础的se知识，随后约线下二面，遂拒。算是刷了次经验。

5.课程：

A.写头歌Py作业：题量疑似有点大了，写了三小时还没写完，明日再写吧。

6.总结：今天的时间看似很多，但是被切分的很稀碎，没有精力集中看八股和项目预设，这是需要警醒的。

# 3.7日报

1.LC：一道medium：给定两个字符串，求最长公共子串的长度。策略是二维dp。定义`dp[i][j]`为第一个和第二个字符串的指针分别处于i和j索引时此时最长的公共子串。状态转移方程：`dp[i+1][j+1]= t1[i]==t2[j]?dp[i][j]+1:Math.max(dp[i+1][j],dp[i][j+1])`。然后做时间复杂度为O(m*n)的双重for遍历i和j即可。好久不写二维DP了，真的生疏了。

2.单词：复习99个

3.工程：

A.整理了 项目MQ的Topic 划分：整理归类为锁存/释存、下单/取消订单、Canal五类。其中下单触发锁存，取消订单触发释存。
B.整理了消息队列 (MQ) 中DefaultMQProducer的设计思路，以及相关的retryTimes和最大超时时间,以及复习Spring提供的RocketMQTemplate细节。
C.整理了在创建 MQTemplate 时设定 MessageConverter 的方法，以及 Pojo 在网络中传输的过程和转化的具体方式。
D.整理了消息队列 (MQ) 发送消息的具体方式，以及接收消息的方式：生产者：消息对象->Json->字节数组，消费者反之亦然。
E.学习了从架构配置角度对 Canal 概念的阐述。整理Adapter和Deployer的区别，以及在Linux上配置MySQL的conf的细节。
F.学习了 Canal 具体接入某一个表的方式：基于胶水层对BO进行注解修饰。
G.学习了 Canal 中涉及的相关业务对象 (BO) 以及相关业务的内容。Order/SPu/SpuDetail/category/brand/shopDetail
H.学习了在 Canal 的 Adapter 中用于监听 Deployer 变化以实现对 Elasticsearch (ES) 同步的 Listener。
I.学习了 Listener 的核心支柱 CanalBinLogResult，它记录了数据变更前后的状态、操作上下文，并支持多种操作类型。
J.复习了阻塞队列中 Array 和 Linked 的实现方式，以及它们与线程池的有机结合方式。
K.复习了 JWT（JSON Web Token）涉及的 HSA 和 RSA 的内容，并理解了对称加密和非对称加密的区别与应用。

L.修订简历的Canal部分和Redis部分描述，迭代版本。

M.复习JavaSE的Throwable以及其子类相关的八股文。

4.总结：效率一般，更多时间是在梳理业务项目，没有花太多时间整理八股，明日周末得早起，过往的周末早上睡得还是太放纵了。

# 3.8日报

1.LC：编辑距离。二维DP：考虑t1和t2两个字符数组中在i和j指向情况下是否相等，状态转移方程为直接转移or i-1,j-1 i,j-1 i-1,j三种状态转移。二维DP写多了发现有个规律：先把矩形图画出来，当前的位置一般就三种情况转移，要么是从上面，要么是从左边，要么是从左上角。每道题的区别就是这三个方向到当前为止，是选择贪心继承，但是选择前者+一个参量

2.单词复习79

3.工程：

A. Linux文件操作：探讨当Linux系统中打开的文件正在被写入时，若使用命令删除文件会发生什么。通过工具先行，深入分析这一场景的实际影响。

B. JMM的应用：从并发安全的角度出发，分析`volatile`关键字的使用，探讨粗锁、细锁的区别，以及原子类在实现并发控制中的关键作用。

C. Volatile原理：深入解读`volatile`关键字的底层机制，重点讨论读屏障和写屏障的原理及其实现方式，揭开其背后的技术细节。补充Happens-befores复习

D. Java线程状态转化与线程方法总结：总结Java线程的状态转化过程，梳理`Object`与`Thread`类中相关的线程管理方法，更好地理解线程生命周期的变化。

E. 从零开始搞懂 MySQL的EXPLAIN：详细解析MySQL中`EXPLAIN`命令输出中的`type`与`select_type`字段的含义，深入理解查询优化的原理和方法。

F. 为什么Redis的SortedSet使用跳表而非二叉树：探索跳表和二叉树的区别，分析为何Redis选择跳表作为SortedSet的数据结构。

G. 分布式ID方案盘点：对比和分析常见的分布式ID生成方案，如单机自增主键、UUID、SnowFlake、Redis、ZooKeeper和Leaf-Segment，分析它们各自的优缺点与适用场景。

H. HTTP版本演进：回顾HTTP协议的演进过程，从0.9、1.0、1.1、2.0到3.0，了解各个版本之间的主要特性变化及其带来的影响。

I. HTTP/3的奇效：学习HTTP/3的显著优势，重点分析QUIC协议、零RTT建连、以及分类别建流等技术如何有效解决HTTP中的队头阻塞问题。

J. HTTPS原理解析：理解HTTPS的工作原理，研究对称与非对称加密技术的应用，解析中间人攻击的风险与防护机制，以及CA证书的作用与原理。

4.总结：早上果然还是没起来，效率一般。今天主要是梳理一些常见八股文，然后复习加固已有知识，没有对项目知识做总结。发现很多八股细节，头回学的时候是没有往深处推敲的，比如Https的迭代过程，去年十一月学习时，并没有理解非对称加密和CA证书的本质，没有理解性记忆升级迭代的流程。这种类似的问题还有很多很多，之前的学习还是太浮躁了。

# 3.9日报

1.力扣：合并区间。A.先用0索引元素排序 B.用List存合规的int[] 当int[]不合规时,通过引用，贪心修改其值

2.单词：复习79个

3.工程：

A.复习线程池的生命周期：

B.复习Redis和MySQL协同：旁路缓存机制

C.复习项目鉴权部分集成的验证码机制-后端生成验证码图片-通过base64存储在json中传递给前端-详细分析base64原理

D.学习TCP阻塞控制：无控制随便发/固定窗口/慢启动+阻塞避免/快恢复/TCP Cubic/BBR

E.梳理项目话术，梳理项目的难点和解决方案，开场白修正。项目笔记复习Redis部分相关

4.工程：今天的工作量很不饱和，没有太大进展。就当好好休息一场了。

# 3.10日报

1.力扣：给定硬币数组，要求判定给定amount最少需要多少硬币。使用DP即可。记住一维DP套路。先找到两个关联量：硬币数和金额数。本题选择硬币数做dp[i]。金额数做i。这个i的范围是0到amount的闭区间。然后由于要求最小的硬币数。所以得先把除了dp[0]以外的dp都初始化一个最大值，99999也行。接着双重for遍历，只要i>coins[j]都贪心试一试。最后通过DP的累加，返回dp[amount]的值即可

2.单词：复习79

3.工程：

A.复习Stream流相关API

B.复习Optional操作

C.读ElasticSearch教材，深化理解，复习相关概念。

D.复习和整理电商项目的ES客户端代码部分。这里补一个细节,7.x的API和8.x有较大差异。

4.总结：一天四节课，严重影响学习进度。

# 3.11日报

1.算法：二叉树的右视图+01背包问题。前者是BFS+取每个List的最后一个元素就结束。后者注意是二维DP，`dp[i][j]`是第i个元素重量为j的情况下的最大价值。

2.单词：复习79

3.工程：

A.修订简历的Es部分，强化OrderSearchManager和ProductUpdateManager的描述。

B.复习Es-就Java客户端的SearchRequest->SearchSourceBuilder->QueryBuilders->boolQueryBuilder->相关的filter方法与should/must方法。做了相关性算分的事件(非Filter)。将元信息字段归类到Filter，商品涉及到模糊搜索的相关性算分部分归类到should/must。

C.复习Es-SearchResponse->SearchHits相关API->以及和项目相关的分页封装策略。

D.整理项目思路：SearchRequest的SearchSourceBuilder中：优化搜索效果的策略，以及如何充分利用相关性算分来提高搜索精准度的方法：增加算分变量！默认是通过TF（词频），而我加入了销量因素，以及优化标题的权重来优化用户搜索结果。

E.学习场景题：选课系统表结构设计：谨记解耦合的思路。学生/老师/课程/课程拓展表/学生-课程表。结合大学选课的特殊性：课程日内时间不固定,因此使用varchar。课程周内时间固定：使用枚举。

F.复习NIO和OIO相关知识：补充DirectByteBuffer和MappedByteBuffer相关。

4.课程：

A.Python的Pandas+Numpy+头歌作业完成部分。

5.总结：项目有进展，效率很一般。刷了几篇面经，发觉自己的知识还是太稀薄了，完全经不住拷打啊。得加把劲了。

# 3.12日报

1.算法：计算二叉树所有可能路径的和+最长无重复子串：前者DFS，每层向下传入累计的值，判定在叶子结点时候将其添加到总和中即可。后者是通过map来建立某个元素和出现位置的关联。不断右移左指针，同时记录期间的最大子串长度，这一步贪心即可

2.单词：复习97个单词

3.工程：

A.整理项目的SQL表结构，梳理十二个数据库的模块内容。

B.复习NIO与IO/NIO和BIO,AIO的区别/Buiffer和Channel的区别/Paths和Files/JavaIO模型

C.复习Java命名规范/中文乱码之UTF-8和GBK差异/装箱和拆箱机制,Integer的缓存区间/深拷贝与浅拷贝(在对象中存在引用时工作,深拷贝通过层层实现Clonable或者用ByteArray和Object流序列化实现/重写Hashcode重要性/Java无法实现真正泛型原因+泛型集合与对象数组的差异+泛型擦除与协变性差异/Java反射-Method调用本质-MethodAccssor的两种Impl,Native与Generic,升级阈值)

D.复习并发编程概念/Java线程六种状态/线程组与线程优先级

4.总结：今天主要是复习琐碎的细节知识，以及整理项目的SQL表结构部分。整体上没有太大进展。

# 3.13日报

1.算法：计算给定字典序排列的,下一个字典序略大的排列情况。策略是从右往左寻觅第一个 阻断 单调递增情形的idx，然后重新从右往左找到第一个比idx大元素的idx2。交换idx和idx2的元素，并且对idx+1到最后进行排序。就形如[1,2,4,3] 中的[4,3]构成了一个2元素最大字典序排列。那我们可以先交换成[1,3,4,2]，但是由于当前不是略大于的情况，因此对idx1后的元素翻转，成为[1,3,2,4]。这样就恰好比[1,2,4,3]大一点点。

2.单词：复习37个

3.工程：

A.复习Mall项目和MQ项目，整理Nacos和GateWay的笔记

B.复习Linux目录含义常用Shell命令：内存/磁盘/关键词搜索/文件名搜索

C.复习HTTP/3结构选择QUIC的原因：在用户空间所以部署灵活/内置TLS加密/基于传输层协议栈

D.复习（b,a）(b,a)索引：Select * from t where a=1：Explain后type为Index，而非All相关。

E.复习Binlog/UndoLog/RedoLog的协作，两阶段提交。

F.复习@Conditional注解原理与其派生的@ConditionOnClass与@ConditionOnProperties，以及从传统的if-else开始迭代的发展历程

G.复习线上环境进行docker操作的linux授权问题，避免chmod 777 / 导致ssh连接等系统功能不可用

H.复习chmod和chown区别

I.复习Java线程池的预热，从for中预编码循环次数->pool.prestartCoreThreads()，复习线程组的定义与结构。

4.复习与展望：明日又有场小厂面试，希望能狠狠的拷打我的项目，榨出我的问题。发觉自己平时的学习很不到位，总是在面试前的复习中发觉许多细碎未被详细了解的知识点。这种客观的缺陷是导致高考成绩不尽如人意的原因。人性是长期习惯的累积，要一点点修正。

# 3.14日报

1.算法：给定二叉树，求最大宽度。思路：A.先给每个节点编号 B.DFS处理，存储每层头节点的编号，将每一次递归的编号与map中当前层头节点编号做差+1。不断贪心最大编号，返回最大编号即可。

2.单词：复习37个

3.工程：

A.复习Redis的数据结构-从Redis本身的dict dictht dictable dicEntry开始分析，分析渐进式哈希对其结构设计的影响。

B.复习Redis底层数据结构-SDS/压缩表/双向链表/hash/快表/跳表等-关联其与Redis的应用数据结构的关系

C.复习项目笔记

D.复习依赖注入的不同注解与差异：@Autowired,@Resource,以及相关的Qualifier，以及构造器注入相关

E.学习使用@Transactional中的TransactionAspectSupport和TransactionManager实现非抛出异常的回滚操作

F.学习虚假唤醒概念与预防措施-复习Condition的内部结构,这一块看的太头晕了,又读一点AQS源码

G.学习场景题-Leaf集群中保证产生的ID为一致的——还是得加锁,版本号机制/让每个数据库中存储独立的号段范围。

4.总结：有点头晕，略微疲惫。明日再奋战吧，今天先娱乐了。

# 3.15日报

1.算法：给定前序和中序的序列，要求构造二叉树，策略是用前序序列取出node节点，然后凭借中序序列做中序遍历，通过DFS构造，这里要注意DFS中的新root是前序遍历中的root，因此左子树根节点应该是root+1，右子树根节点应该是root+1+(i-1-left)+1。

2.单词：复习58。

3.工程：  
  A. 领域模型：逻辑队列集合支持消息分类和权限管理，其属性包括名称、队列数以及消息类型（普通/FIFO/延迟/事务），5.x版本强制单类型，MessageQueue是存储最小单元，具有有序性，其属性包含读写权限，且5.x版本队列名与节点解耦，Message是不可变且持久化的，其属性包括ID、标签、计划时间和大小限制（4MB），Producer预绑定主题（事务必需），客户端ID唯一，支持同步、异步和批量传输，ConsumerGroup作为逻辑资源定义消费行为（顺序投递、重试策略），5.x版本统一消费逻辑，Consumer是运行实体，类型包括Push/Pull/Simple，其属性包含订阅关系和监听器，需关联消费组。  
  B. 消息传输模型：点对点模式下匿名消费者实现单消息单消费（如RabbitMQ/RocketMQ），发布订阅模式下消费者组独立实现全量消息访问。  
  C. 消息类型：普通消息实现异步解耦，适用于订单处理和日志收集，定时/延时消息基于时间戳或延迟级别（预置18级）适用于订单超时关闭，顺序消息支持全局或分区顺序（如订单状态更新）并通过队列绑定策略（Hash分配）实现，事务消息通过二阶段提交加事务回查适用于支付一致性（5.x强制预绑定主题）。  
  D. 生产者机制：预绑定主题是事务消息必需且Broker动态创建Topic，通信参数包括接入点（避免硬编码IP）、请求超时和身份认证，事务检查器将本地事务执行与回查逻辑绑定。  
  E. 消费者机制：PushConsumer通过长轮询推送，线程模型复杂且无法动态控制消费节奏，PullConsumer手动管理Offset，实时性差但灵活，SimpleConsumer融合Pull和Push优势，支持批量拉取和异步提交Offset，需精细状态管理。  
  F. 消息过滤：TAG过滤实现精确匹配，高效适用于日志级别筛选，SQL92过滤基于属性（如amount > 1000）适用于复杂条件，混合过滤结合TAG和SQL（如VIP且地区=北京）。  
  G. 负载均衡：默认策略是队列平均分配（AllocateMessageQueueAveragely），Rebalance由Consumer增减或队列数变化触发，自定义策略按实例性能分配队列（如高性能Consumer多分队列）。  
  H. 重试与流控：消费重试采用递增延迟（1s到2h），最大16次，失败后进入死信队列，发送重试同步默认2次，异步默认0次，流控方面Producer限制队列积压（默认10万条），Consumer限制拉取量（pullThresholdForQueue）。  
  I. 消费进度管理：Offset存储分为集群模式（Broker管理）和广播模式（本地存储），消费起点包括CONSUME_FROM_LAST_OFFSET（默认）、FIRST_OFFSET和TIMESTAMP，提交机制中PushConsumer自动提交，SimpleConsumer手动异步提交。  
  J. 版本兼容性：Broker 5.x实现队列与节点解耦并强制Topic单消息类型，4.8兼容性下生产者组弃用（5.x特性需规避），客户端逻辑需保证分组一致性，同时复习J.ThreadLocal、InheritThreadLocal和TransimitableThreadLocal。

K.复习ThreadLocal/InheritableThreadLocal/TransmitableThreadLocal

# 3.16日报

1.算法：接雨水。维护左右的前缀最大值。相向双指针逐渐靠近，while循环每轮只移动左边或者右边。取决于preMax大还是sufMax大。策略是preMax-height[left++]或者sufMax-height[right--];

2.单词：复习57个

3.工程：

A.看Canal-Server和Canal-Admin的doc，串联相关的配置细节到面试预设问题中。

B.复习Canal本体的QuickStart-原生和docker/集成RocketMQ的相关配置

C.复习Canal-Admin的原生部署和Docker部署

D.复习Canal-server和电商产品业务关联代码分析

E.复习Canal八股文。

F.复习ElasticSearch在项目中的集成：相关性算分与查询的API复习

G.整理基于胶水层的ETL实现：MySQL Binlog → Canal Server → RocketMQ →CanalGlue → Processor → Target Storage (ES)

H.FullGC排查思路：JVM相关参数设置：形如+XX:PrintGCDetails +Xloggc: /xxx/xx 以及关于堆内存中的分代/元空间内存分配

I.改简历-修订ElasticSearch关于ETL的描述-修订个人能力对Linux的描述。

4.总结：精神很疲惫，进度不尽如人意。我的能力和既定目标有很大差距。事已至此，先休息吧。

# 3.17日报

1.算法：k个一组翻转链表。A.先处理链表翻转，相邻的pre和curr指针即可。B.然后就是while循环确定k个一组，设定pre和end以及内部干活的start和next。记得给end.next后面断了，不然不止翻转这个区域。

2.单词：复习57个

3.工程：

A.Spring七种声明式事务传播机制的分析

B.Spring声明事务失败的场景分析：自调用/非public/MyISAM问题/传播级别never或者not_supported/单事务内存在多数据源

C.Spring编程式事务的迭代过程->DataSource到TxManager到TxTemplate

4.课内：

A.操作系统刷题

5.总结：疲惫且毫无进展的一天，非常坏的局面。这个状态维持下去，必定失业。明日复习项目文档，备战后天的技术面。

# 3.18日报

1.算法：二叉树的最大路径和：对ans做贪心。DFS结果返回部分子节点的贡献值即可。

2.单词：复习59个

3.工程：

A.复习ElasticSearch的crud

B.复习设计模式：订单场景下的工厂模式+责任链模式

C.复习JavaSE-进程/线程/协程

D.复习Linux页表规模复习/内存不足申请内存的swap操作与kill操作

E.复习TCP可靠原因分析：慢启动/阻塞避免/验错码/快速重试

F.复习类加载器与双亲委派/Tomcat与JDBC打破双亲委派的不同方式

G.复习JDK1.8场景下的GC分析

H.复习MVCC与MySQL锁机制

I.复习rocketMQ的延时队列实现思路：schedule_topic_xxx+定时任务是核心

J.复习MQ轮子的面试八股。

4.课程：

A.matplotlab实践

B.pandas实践

# 3.19日报

1.算法：给定温度数组，输出新数组，数组元素为下一个比今日温度高的日子与当前位置的距离。策略是从后往前遍历，然后用result[j]做记录，第二层for循环每次增加result[j]。然后判定当前元素是否小于右侧元素，若小于则result[i] =j-i。若大于且result[j]=0，则result[i]为0.

2.单词：复习79个

3.工程：

A.学习：从单体到微服务：接口鉴权的演进与优化

B.复习：SQL中索引失效的十三种常见大坑

C.复习：Spring 中 Bean 初始化过程的扩展点：BeanPostProcessor/InitializingBean/@PostConstruct/init-method/SmartInitializingSingleton/ApplicationContextAware

4.总结：课多，累，休息。

# 3.20日报

1.算法：给定二叉树，要求判定是否为完全二叉树。策略：允许在队列中存储空元素，注意此时要用LinkedList而非ArrayDeque。然后遇到空元素则赋flag为false。遇到非空元素先判定flag是否为true，不为true直接return false。BFS即可。

2.单词：复习79个

3.工程：

A.958：二叉树的完全性检验

B.分析 Elasticsearch 实现拼写纠错的原理及 Java 客户端操作实现

C.MyBatis-Plus 常见 API 实战：从基础到多表联查

D.LinkedList vs. ArrayDeque：实例化选择与NPE问题的分析

E.MyBatis-Plus 查询构建实战：eq/between/in/or/like likeLeft likeRight/gte和lte/动态条件

F.从源码看 MyBatis-Plus 与 Spring 的 DataSourceTransactionManager 有没有直接关联？

G.MyBatis-Plus 之逻辑删除：@TableLogic与全局配置字段逻辑删除之优势与劣势

H,RedisBloom插件：让你的Redis支持布隆和布谷鸟！缓存穿透-URL映射(不可删)/黑名单管理(可增删)

I,场景题-Java 单体项目优化：应对高并发客户端访问的性能与线程安全分析

J,IO 多路复用详解：从概念->系统调用-> Java 在NIO中实现

K,面试问题分析：为什么Java能实现反射机制，其他语言不行？

4.课程：

学习Python100，学习Py语法-字符串尚未看完

# 3.21日报

1.算法：合并两个有序数组，双指针即可。

2.单词：复习59个

3.工程：

A.复习SpringBoot的核心注解与子注解

B.复习SpringBoot的Scope

C.复习单例Bean和RequestBean的注入问题

D.复习MYSQL的多层级部门表和成员表的设计：使用父子id/层级字符串

E.修改MySQL的事务隔离级别：set global/session或者my.cnf修改
F.复习Redis实现分布式锁的考虑因素。

# 3.22日报

1.算法：买卖股票的最大利润。记录截止到i的最小值，通过不断dp求最大利润

2.单词：复习58个

3.工程：

A.ES：数据模型/搜索过程/Master选举细节/索引文档过程

B.ES：数据一致性/和Lucene关系/中文分词/最小主节点与脑裂/路由选定特定节点/更删文档过程

C.ES：高量级数据聚合/ES数据类型/ES存储原理/ES怎么读文档/ES怎么删文档/为何脑裂/集群监控/如何调优

D.Elasticsearch分片与副本设置/拼写纠错原理/Linux下部署优化/安装依赖组件/服务器启动流程/Cluster与Node简述/数据库对比/映射

E.RocketMQ:队列选型/Broker存储机制/三种发送策略/消息有序性/消息积压与处理/集群与广播/Rebalance

F.Seata:核心组件/工作流程/四大模式/事务传播/CAP与模式/三大组件/集成细节

G.面试复盘：Java实现深拷贝与浅拷贝

H.JVM堆结构/对象null能否立刻GC/Serial和Scavenge/垃圾回收时间/永久代/分布式垃圾回收/常见Jvm参数/压缩指针

I.GCRoots的主体/GC算法在具体收集器的应用/JVM类加载机制/内存泄露与内存溢出/栈上分配与内存逃逸

K,Redis面试复盘：从连接到扩容与数据定位的极致详解（含Java RedisTemplate交互）

L.面试复盘：聊聊epoll的原理、以及其相较select和poll的优势

M.无感刷新的秘密：Access Token 和 Refresh Token 的那些事儿

# 3.23日报

1.算法：找到环形链表进入环形的节点。HashMap+指针循环

2.单词：复习57个

3.工程：

**A. Netty相关**

1. **Netty优势/应用场景/高性能体现/BIO, AIO, NIO/Netty序列化**

   - **Netty优势**：高性能、可扩展、异步处理、支持多种协议（HTTP, WebSocket等）。
   - **应用场景**：分布式系统、高并发网络服务、实时数据流处理、网络通信框架。
   - **高性能体现**：Netty通过事件驱动模型，减少了线程创建与上下文切换，提高了网络数据传输性能。
   - **BIO, AIO, NIO对比**：BIO（阻塞IO）每个连接对应一个线程，适用于连接少且处理时间较长的场景；NIO（非阻塞IO）采用事件驱动机制，提高了处理性能；AIO（异步IO）采用更先进的非阻塞模型，进一步提高并发处理能力。
   - **Netty序列化**：Netty通过优化的序列化机制（如使用Protobuf或自定义序列化方法）减少了数据传输时的开销，支持更高效的序列化和反序列化过程。

2. **文件描述符与select, poll, epoll**

   - **文件描述符**：每个网络连接都由操作系统分配一个文件描述符（FD）来标识。

   - select/poll/epoll

     ：这些是Linux下的IO多路复用机制，用于处理大量并发连接。

     - **select**：支持最多1024个文件描述符，性能较差。
     - **poll**：改进了select，支持更多文件描述符，但仍然存在性能瓶颈。
     - **epoll**：更高效，支持大规模连接，采用事件通知机制，适用于高并发场景。

3. **Netty: EventLoop, Channel和ChannelHandler**

   - **EventLoop**：是Netty的核心组件之一，负责事件的轮询和任务的调度，通常每个线程拥有一个EventLoop实例。
   - **Channel**：Netty中的数据传输通道，负责数据的读取和写入，Channel是对操作系统socket的封装。
   - **ChannelHandler**：处理I/O事件的接口，每当发生事件时，ChannelHandler就会被调用，可以进行数据处理、编码解码等操作。

4. **Netty的ByteBuf：设计思路与ByteBuffer的对比**

   - **设计思路**：ByteBuf是Netty提供的一个高效的缓冲区类，避免了Java默认的ByteBuffer的限制，提供了更灵活的读取和写入操作。
   - **ByteBuffer对比**：ByteBuf的优势在于支持动态扩展、读取与写入分离、更高效的内存管理。

------

**B. JDBC相关**

1. **JDBC是什么/Driver的定义/预编译和普通的statement/CallableStatement**
   - **JDBC**（Java Database Connectivity）：是Java与数据库之间进行交互的API。
   - **Driver定义**：JDBC Driver是用于实现JDBC API与数据库连接的中介层，不同的数据库有不同的驱动。
   - **预编译与普通Statement**：预编译Statement提高了性能并且可以防止SQL注入，普通Statement不支持预编译。
   - **CallableStatement**：用于执行存储过程，它不仅可以执行查询，还能处理返回的多个结果。
2. **JDBC：数据库连接池/JDO/JDBC最佳实践/如何连接数据库/事务处理/程序与JDBC松耦合**
   - **数据库连接池**：通过复用已有数据库连接，避免频繁建立和关闭连接，提升性能。
   - **JDO**：Java Data Objects，一种用于Java的持久化框架，提供数据库交互的标准化方法。
   - **JDBC最佳实践**：使用连接池、处理异常、关闭资源、预编译SQL语句等。
   - **如何连接数据库**：通过JDBC驱动和数据库URL进行连接，并通过DriverManager或DataSource获得连接。
   - **事务处理**：使用JDBC事务管理确保数据一致性和完整性。
   - **程序与JDBC松耦合**：通过DAO模式、JDBC模板等方式实现松耦合。
3. **JDBC：脏读/execute与executeQuery/update的区别/jdbc的不足/ResultSet**
   - **脏读**：指在事务中读取到未提交事务的修改数据，可能导致不一致。
   - **execute与executeQuery/update区别**：execute适用于执行更新或查询，executeQuery仅用于查询，executeUpdate用于执行更新操作。
   - **JDBC不足**：JDBC通常较为底层，操作繁琐，容易出错。
   - **ResultSet**：用于存储查询结果，可以按行读取，支持不同的数据类型。

------

**C. MyBatis相关**

1. **MyBatis：结构/优缺点/SQL结果如何封装/动态SQL/#和$/dao层原理**
   - **结构**：MyBatis通过XML或注解配置SQL语句，提供持久化操作，支持自定义类型处理器。
   - **优缺点**：优点是灵活、性能高，缺点是需要手动编写SQL。
   - **SQL结果封装**：通过ResultMap将SQL结果映射为Java对象。
   - **动态SQL**：使用<if>、<choose>等标签实现动态SQL。
   - **#和ParseError: KaTeX parse error: Expected 'EOF', got '#' at position 4: **：#̲用于防止SQL注入，用于传递原始的SQL片段。
   - **dao层原理**：MyBatis通过映射器（Mapper）将接口与SQL映射，简化数据库操作。
2. **MyBatis：Configuration/MappedStatement/双缓存/XML的id/分页机制实现/自增主键id/xml罕见标签**
   - **Configuration**：MyBatis的核心配置对象，管理所有的配置参数。
   - **MappedStatement**：表示一个映射语句，通常包含SQL和一些参数配置。
   - **双缓存**：MyBatis支持一级缓存（会话级）和二级缓存（全局级）。
   - **XML的id**：每个XML配置的SQL语句通过id唯一标识。
   - **分页机制实现**：通过插件或在SQL中加入limit来实现。
   - **自增主键id**：MyBatis支持数据库自增主键，也可以通过插件或配置获取主键值。
   - **XML罕见标签**：如<foreach>、<choose>等标签用于循环、条件判断等动态SQL处理。
3. **MyBatis：插件运行原理/延迟加载原理/二级缓存与二级缓存原理/接口绑定原理**

- **插件运行原理**：通过拦截器在SQL执行前后进行自定义操作。
- **延迟加载原理**：在需要时才加载数据，减少资源消耗。
- **二级缓存原理**：全局缓存，支持多个会话共享缓存数据，使用时需要配置。
- **接口绑定原理**：通过Mapper接口绑定SQL语句和方法，简化数据库操作。

------

**D. SQL优化与InnoDB相关**

1. **如何优化SQL SELECT语句：从基础到高级的实操指南**

- **基础优化**：合理使用索引、避免SELECT *、避免复杂的JOIN等。
- **高级优化**：使用查询缓存、避免子查询、优化排序和分页等。

1. **面试复盘：InnoDB的表结构与查询细节**

- **InnoDB表结构**：InnoDB支持事务、行级锁和外键约束，数据存储为聚簇索引。
- **查询细节**：了解索引的使用、查询优化、行锁与表锁等，确保高效的数据查询。

# 3.24日报

1.判定BST树——dfs传入上下界限，先判别不满足条件的情况return false 只有在return两端为true则return true

2.单词：复习59个

3.工程：

A.MySQL：系统表/货币数据类型/MyIsam和Innodb/insert性能优化/邻键锁的退化/MySQL的参数/CPU问题排查

B.MySQL：系统信息查询/pconnect和connect/binlog三种工作模式/mysqldump/分区/死锁检测

C.Fail-Fast vs Fail-Safe / hashCode & equals / finalize / Exception变化 / System.gc

D.从 Servlet 到 WebMvcConfigurer：Java Web 与 Spring Boot 的进阶之旅

# 3.25日报

1.算法：打家劫舍。规定dp[i]是有i间房子截获的最大利润。然后考虑转移。这里的初始化怎么思考呢？你就假设dp[1]只有两间房 dp[0]只有一间房即可。

2.单词：复习58个

3.工程：

A.深入分析Java中的BigInteger和BigDecimal：API与内部结构

B.装饰器 / Lambda / Tuple-List / except / match-search / 全局变量 / 引号 / 参数 / 类-实例变量

C.模块引用/ pass/ 模块包/ range/xrange/ dict/items/ is/ func引用/ any/all/ 列表值/ 排序

D.进程与线程区别 / Java线程状态 / 同步方法与代码块差异 / Monitor线程同步原理 / 死锁解析 / 多线程访问资源避免死锁

E.Java多线程面试复盘：唤醒阻塞线程/CyclicBarrier与CountdownLatch区别/wait()方法调用与虚假唤醒/多线程伪共享/...

F.深入理解 Java 并发：CAS、AQS、ReentrantLock 与线程池

G.为什么在 MySQL 表结构设计中要使用 NOT NULL？

H.MySQL 字符集探秘：从 UTF-8 到 UTF8MB4，以及如何存储 Emoji

I,MySQL 中的主键与索引设计：从 `USING BTREE` 到业务场景分析

J.分析 MySQL 的Blob：从 LONGBLOB 到互联网应用的探索

# 3.26日报

1.算法：正方形二维矩阵的翻转：1.先克隆 2.修改i和j的坐标。然后复习了一下最长递增子序列。牟定一个res值，然后双层for，i和j，j表示截止到i的子数组中的元素，然后找状态转移方程 dp[i] = Math.max(dp[i],dp[j]+1)。然后每一个i过后都贪心到res里面，最后return res

2.单词：复习57个

3.工程：

A.复习Mall项目表结构

B.看Redis

C.Redis性能与优势/对比其他Key-Value存储/数据类型及底层结构/相同数据结构原因/对比Memcached优势/字符串最大容量/RDB与AOF分析

D.常用索引有哪些？联合索引使用时要注意什么？什么是最左匹配原则？联合索引（a, b, c)，使用（b, c) 可以命中索引吗？(a, c) 呢？

E.Java 线程的状态转换 / 操作系统线程状态转换 / 线程上下文切换详解 / 如何避免线程切换

4.总结：我真的好累好累啊今天。

# 3.27日报

1.算法：给定三角形二维矩阵，要求计算从第一层到最后一层的最小路径和。策略是DP，注意每一行左侧和最右侧的状态转移方程要单独写，最后对最后一行的值做最小化贪心即可

2.单词：复习58个

3.工程：

A.面试复盘博客：你知道 Java 的泛型底层是怎么实现的吗？

B.GIT：如何从零开始初始化并提交一个本地仓库到远程仓库

C.谈谈垃圾回收器的演进-从SerialGC到G1、ZGC、Shenandoah

D.G1 相较于 CMS 的优势：一场垃圾回收的革命性进化

E.Nginx负载均衡算法分析：面试复盘

F.分析面试复盘问题：TCP两次握手为什么不行？三次挥手为什么不行？详解三次握手与四次挥手

G.面试复盘：Java内存可见性的底层原理

H.面试复盘：深入剖析Linux Page Cache与缓存未命中的处理

I.MySQL：双重写缓存/一次失败与二次失败/系统表在内存还是磁盘

J.MySQL：意向锁与兼容性/MySQL中的锁加在什么上？/innodb中锁的底层是怎么实现的？

K.面试复盘：left join 底层算法(嵌套/哈希/分块) & 主从复制（异步/半同步/同步）

# 3.28日报

1.算法：给定矩形矩阵，要求计算从左上角到右下角的最小路径和。这种题就是纯DP。但是切记DP在部分节点不可以执行，比如`i==0和j==0`的情况，因此DP方程要分三种，两种特殊情况，一种循环普通情况。

2.单词：复习58个

3.工程：

A.面试场景题：设计微信朋友圈后端-从接口到数据库的实现

B.外键是个啥？为什么我要加它？——从面试复盘聊聊数据库设计

C.场景题：设计微信的双向好友添加/建群逻辑

D.一篇面向Linux网络配置新手的博客：从零开始掌握网络命令与服务器部署一篇面向Linux网络配置新手的博客：从零开始掌握网络命令与服务器部署

E.如何在 Java 中单元测试类的私有方法

F.面试复盘：JVM 与 Linux 中的线程进程上下文切换及子进程异常感知

G.用 Java 谈谈递归与回溯的差异性

H.面试复盘：谈谈Linux在创建线程时做了什么工作/线程切换的成本如何估量？

I.Java面试复盘：栈溢出（StackOverflowError）知多少？排查与解决全攻略

J.面试分析：二维数组是行优先还是列优先遍历效率高？

K.面试复盘：Java为什么有这么多“O”？——从请求链路看清楚

L.从面试谈起——快排时间复杂度与排序稳定性解析

# 3.29日报

1.算法：给定链表，仅翻转其中的[left,right]之间的链表。

2.单词：复习55个

3.工程：

A.复盘博客：从面试谈 ZSet 的理解与分析

B.从 CAS 到 Unsafe，再到原子类：深入剖析 Java 并发核心

C.面试复盘：项目中OOM的那些事儿——原因、排查与代码反思

D.深入理解G1垃圾回收器：GC Roots与标记机制的“人性化”探秘

E.面试官问“epoll的原理”，我该怎么回答？

F.面试复习：游标是什么？什么是深度分页？如何用游标解决深度分页？（以 InnoDB 为例）

G.线程池的参数如何设置，给一个16核的处理器 QPS500 单个业务时间50ms 问如何设置参数？

H.实战指南：如何在电商项目中正确使用Caffeine缓存

I,Lombok注解详解：从朴素构造到高效开发

J,接口速度太慢，排除DB影响，试试通过异步来优化吧！

K.git的回退：revert还是reset？来个例子看看吧!

L.深入SpringBoot启动流程：自动配置与Bean生命周期核心解析

# 3.30日报

1.算法：环形链表——快慢指针法，快指针走两格，慢指针走一格，相遇则判定有环。

2.单词：复习45个

3.工程：

A.后端程序员必备：Linux 监控命令详解与参数深度剖析

B.面试复盘：Junit 小白入门指南——从面试题到单测实践

C.博客：面试复盘 - JUnit 相关知识点总结

D.面试复盘：Maven依赖范围与生命周期/微服务项目pom结构

E.从零了解 Maven 插件：面试官问我对插件的那些事儿

F.SpringCloud：常用的Maven插件介绍/依赖中的pom-Type和import-Scope介绍

G.如何排查InnoDB的MySQL服务中的死锁问题

H.面试复盘：MySQL InnoDB 事务隔离级别与 MVCC 分析/为什么可重复读的死锁概率高？

I.面试复盘：Java String 源码分析与不可变类设计原理

J,面试复盘：synchronized 锁与 ReentrantLock 锁的区别及 AQS 认知完善

K.StringBuffer 与 StringBuilder 的源码分析与差异

L.面试官问我：HashMap的扩容机制，我从jdk1.7和1.8两个版本来介绍

M.面试复盘：CopyOnWriteArrayList的底层实现分析

N.面试复盘：Collections.synchronizedList的实现与同步策略分析

O.ByteBuf 在 Netty 中的外内存调优（MQ 项目场景）

P.Linux基础：文件/文件描述符/Socket/系统调用/网络通信/零拷贝

Q.磁盘调度策略分析 - SCAN/C-SCAN/SSTF/FCFS

R.操作系统期末复习：深入理解文件组织形式(连续/链接/索引)及Linux实际用法

T.Linux系统调用入门：进程(execve,exit,getpid,getpgid)/文件(open,close,read,write)

U.从宏观到微观：MMU、PCB、TLB、CPU是个啥？

V.分页入门：简单分页与其他内存管理方式，操作系统小白指南

W.操作系统入门：位示图、主存分配、页面置换与磁盘管理

X.SQL执行顺序与ON vs WHERE：MySQL底层解析与面试记忆法

# 3.31日报

1.算法：链表排序-并归排序

2.单词：复习55个

3.工程：

A.使用 Seata 和 TCC 模式实现分布式事务：基于 Spring Cloud Alibaba 的电商案例

B.分析TCC分布式事务的问题：空回滚与悬挂

C.Seata TCC 模式的空回滚与悬挂问题之解决方案-结合时序分析

D.Seata TCC 模式：RootContext与TCC专属的BusinessActionContext与TCC注解详解

E.Java中线程暂停的分析与JVM和Linux的协作流程

F.Numpy：limspace/arange/数组基本属性分析

G.NumPy：数组加法/数组比较/数组重塑/**数组切片**

H.Numpy：数组生成/modf/sum/输出格式规则

# 4.1日报

1.算法：集合的排列-回溯算法

2.单词：复习57个

3.工程：

A.数据通信相关

B.Feign组件学习：Contract Client Decorder Encoder

C.Seata的XID传播设计

D.Segment-Mybatis的自定义拦截器设计

E.JDK动态代理与CGLIB动态代理差异

F.常见排序：Arrays/Collections/List/StreamAPI

G.JavaSE的stream

H.复习类加载规则，复习双亲委派之打破：JDBC与tomcat

4.总结：好累好累好累，马上就要考试了，还有一个月的时间。然后我还需要尽快复习一下八股和项目。考完试就准备投实习了，还得认真处理一下课设，争取提前跑出去。

# 4.2日报

1.算法：有效的括号，做回溯，然后DFS的部分做两次回溯

2.单词：复习45个

3.工程：

A.MP：从Wrapper到源码分析

B.深入剖析 MyBatis-Plus 自动注入封装的实现原理及其创新

C.链路追踪视角：MyBatis-Plus 如何基于 MyBatis 封装 BaseMapper

D.面试场景题：基于Redisson、RocketMQ和MyBatis的定时短信发送实现

E.用RocketMQ和MyBatis实现下单-减库存-扣钱的事务一致性

4.课程：

A.编译原理-绪论+一点点的词法分析器。

5.我现在好累，非常累。。。。。。。。。。。。。。。。。

# 4.3日报

1.算法：中序遍历的两种写法：栈写法和DFS写法

2.单词：复习48个

3.工程：

A.Pandas全面操作指南与电商销售数据分析

B.如何为这条sql语句建立索引：select * from table where x = 1 and y < 1 order by z;

C.令牌桶算法与惰性机制的应用

D.如何设计实现一个定时任务执行器 - SpringBoot环境下的最佳实践

E.深入分析Java中的AQS：从应用到原理的思维链条

F.Redis详解：从内存一致性到持久化策略的思维链条

G.深入剖析 Redis 持久化：RDB 与 AOF 的全景解析

H.ArrayList与LinkedList源码分析及面试应对策略

I.详细分析：ConcurrentLinkedQueue

J.常见前后端联调HTTP状态码报错分析/SpringMVC返回状态码细节

K.Feign的协议和序列化是用的什么？

L.零基础指南：在Linux上用Docker和Jenkins实现Spring Cloud微服务的CI/CD

M.准备面试：Jenkins部署SpringCloudAlibaba微服务商城全攻略

N.从零开始：Dockerfile 编写与 Spring Cloud 项目部署到 Docker Compose

4.课内：

A.编译原理-正规式-正规集-DFA-NFA-NFA变DFA-DFA化简-NFA构造正规式

# 4.4日报

1.算法：判断对称二叉树

2.单词：复习48个

3.工程：

A.全面剖析Java中的Queue：从集合概览到源码与并发实现

B.深入剖析Java中的LinkedHashMap：内部结构、源码与比较

C.DDD是什么？用一个电商的例子来入门

D.电商项目-支付模块交易链路梳理与时序图

E.RBAC模块分析：菜单-权限/角色-权限/用户-角色

F.类加载有几种？ClassLoader显式加载/new隐式加载/字面量加载/访问静态字段加载

G.Java 有乐观锁吗？深入分析 CAS 与并发容器

H.面试官让我介绍 Atomic 原子类有哪些？底层的实现机制是什么？

I.Spring 启动流程分析-含时序图

J.Spring 启动流程：比喻表达

K.面试攻略：如何应对 Spring 启动流程的层层追问

L.Spring扩展点与工具类获取容器Bean-基于ApplicationContextAware实现非IOC容器中调用IOC的Bean

# 4.5日报

1.算法：计算二叉树的最大深度。DFS即可

2.单词：复习101个

3.工程：

A.面试官问我：Spring AOP的代理模式与实现原理深度剖析

B.从面试问题看端口连通性：Ping、TCP/UDP与业务实践

C.Spring事件机制：微服务架构下的子服务内部解耦合/多场景代码分析

D.一名实习生的复盘：技术与规划的经验教训

E.JUC：CompletableFuture 详细用法讲解

F.解析MQTT协议：开销更小、性能更强的，适用于IOT场景下的通讯协议

G.正则表达式详解与 Java 实践-预定义字符类/重复类/反义类/分组/零宽断言

H.面试回顾：Java RMI 问题解析

I.面试官问：你谈谈网络协议栈是什么？你觉得Java工程师需要了解哪些部分？

4.课内：

A.编译原理-LL(1)和First和Fellow文法和分析法

# 4.6日报

1.算法：计算能否到达最后一个元素。贪心取最大距离，然后保证当前的索引i在最大距离之内进行for循环

2.单词：复习69个

3.工程：

A.如何深入回答面试官关于Spring IOC容器的问题

B.Java中UUID的原理与生成策略

C.面试官问我：MD5在Java开发中的应用与原理

D.深入解析BCrypt：原理、应用与面试问题

E.Spring Boot @Conditional 注解分析与实际业务场景应用

F.Pandas期末备考：常见问题解析

G.如何在 Java 中正确判空 BigDecimal 等数据类型

H.为什么把私钥写在代码里是一个致命错误

I.面试官问我：你写代码会复用公共SQL么？

J,深入探讨DDD中的聚合根：以电商业务场景为例

K,Java 后端实现 App 列表滚动加载：用游标优化深翻页问题

L.博客：八股文网站验证码解锁与JWT登录机制解析/前端Vuex实现

M,如何用 Spring Boot 实现自动发送注册验证码邮件

N.MySQL索引EXPLAIN执行计划type类型解析

O,MySQL中IN和NOT IN会走索引吗？

P.Kafka与ZooKeeper架构与配置详解

Q.Kafka工作流程与文件存储机制详解及与RocketMQ对比

R.Kafka文件存储与消息存储机制深度分析及与RocketMQ对比

S.NumPy 数组创建方法与区间差异分析

T.Numpy：数组的范围创建/变形/转置/展平

U.Clash的TUN模式是什么意思？Clash的模式介绍

# 4.7日报

1.算法：复习手撕快排

2.单词：复习49个

3.工程：

A.Python的pandas的df.iloc与df.loc，以及pd.set_option("max.display_rows")等细节

B.IOC容器分析

C.pandas的离散选择和聚合选择，比如df.iloc[1:3,2:4]以及df.iloc[1:5,[2,4]] 后者是选择第2列和第4列，以及前四行

4.课堂：

A.编译原理的NFA和DFA题目，通过NFA找DFA-使用空闭包。化简DFA：通过DFA的推导，将可到终止符和不可到终止符的做类别的区分。

# 4.8日报

1.算法：手撕二分：二分这一块，切记两个闭区间，循环<=。然后要找第一个大于的话，就是nums[mid]>=target让right减少，最后返回left

2.单词：复习57个

3.工程：

A.HashMap扩容机制分析

B.红黑树插入复盘

C.设计短连接系统

D.GcRoots分析

E.JVM创建线程与本地内存关系

F.OOM发生的时机

G.复习Redis的思维导图-数据类型都梳理了一遍

# 4.9日报

1.算法：手撕二分。

2.单词：复习50个

3.工程：

A.Redis的RESP协议

B.Netty实现Redis服务队BytesWrapper的封装

C.Java的CompareTo和Equals方法

D.ConcurrentSkipListSet数据结构

E.Java Iterator分析

F.Redis与Zset的跳变实现逻辑和面试问题解析

# 4.10日报

1.算法：根据符号匹配字符串。但凡看到括号，马上想到用栈。遇到左括号就把值推进栈，遇到右括号就把值从栈中取出来。

2.单词：复习49个

3.工程：

A.整理Redis项目的思维导图

B.分析BulkString类与对象池的设计

C.手撕AOF：双缓冲机制的实现

D.FileChannel的妙用：NO的同步机制

E.JavaIO与NIO的主要API层次结构差异

F.Redis CommandHandler的解析实现

G.分析基于Netty的Channel的option实现细节

H.netty Serverbootstrap的Handler链条，以及pipeline中inbound/outboundHandlerAdapter的层次与MessageToByteDecoder与BytesToMessageEncoder的差异。

# 4.11日报

1.算法：统计值为target的组合总数，经典的回溯问题

2.单词：复习40个

3.工程：

A.复习Redis项目

B.整理Canal相关的细节。比如CanalServer的EventParser、EventSink、EventStore。以及MetaManager

C.Binlog的分析-操作/查询/业务场景应用

D.索引优化器选择走的索引阈值

E.Canal解析MySQLBinlog的细节。

4.总结：

明天得把数据通信的考试搞一下，然后通信原理得看。Canal得深化记忆。

# 4.12日报

1.算法：最长连续子序列。贪心就完事了。

2.单词：复习49个

3.工程：

A.使用 PARTITION BY 和 RANK/DENSE_RANK 查询部门内薪资 Top 2

B.面试官问我：UDP发送到IP存在但端口不存在的报文会发生什么？

C.面试官问我：TCP发送到IP存在但端口不存在的报文会发生什么？

D.深入理解 TCP backlog 参数：意义、应用场景与 Netty 中的应用

E.DNS 污染是什么？原理、影响与应对

F.HTTP 相比 TCP 的好处是什么？

G.MySQL count(*) 哪个存储引擎更快？为什么 MyISAM 更快？

H.面试问题解析：InnoDB中NULL值是如何记录和存储的？

I.面试复盘：varchar vs char 以及 InnoDB 表大小的性能分析\

J.面试复盘：使用 perf top 和火焰图分析程序 CPU 占用率过高

K.面试官问我：三级缓存可以解决循环依赖的问题，那两级缓存可以解决Spring的循环依赖问题么？是不是无法解决代理对象的问题？

L.为什么说MVCC无法彻底解决幻读的问题？

I.复习ElasticSearch和Canal的部分。

# 4.13日报

1.算法：给定两个链表，要求计算两个链表每个节点之和，允许进位。

2.单词：复习49个

3.工程：

A.复习SpringCloud-gateway的限流策略与基本的filter和谓词细节

B.JVM理论体系整理

C.场景题细微体系整理

D.面试官试图狠狠从三大垃圾回收算法拷打到七大GC器

E.使用 JMeter 测试博客新增接口的 QPS

# 4.14日报

1.算法：路径总数，DP。记得初始化0行和0列，这个初始化一定要记住，非常常见，一定不能只初始化0,0位置

2.单词：复习60个

3.工程：

A.整理Seata相关

B.复习Canal相关

C.复习ES相关的API/整理事务相关的内容

# 4.15日报

1.算法：找出乘积最大的子数组。对最大乘积和最小乘积进行DP，返回DP数组中的最大值即可

2.单词：复习60个

3.工程：

A.整理RocketMQ相关的复习资料

B.整理Stream相关的复习

# 4.16日报

1.算法：二叉树转链表。

2.单词：复习63个

3.工程：

A.Redis过滤器两种复习

B.Junit复习

C.函数式接口复习

D.RocketMQ处理

4.总结：今天凌晨四十四才将近结束，今天太忙碌了。

# 4.17日报

1.算法：复习PriorityQueue与前k个高频元素相关的题目

2.单词：复习64个

3.工程：

A.RocketMQ复习

B.项目里面的ETL流程梳理

C.Seata复习四种模式

D.binlog、RedoLog、UndoLog详细复习

E.ThreadLocal与拷打

F.Redis单线程好处

G.红黑树相关-颜色只影响平衡性-不影响查询

# 4.18日报

1.算法：找到数组中出现两次的元素-使用环形链表的模拟解法实现

2.单词：复习60个

3.工程：

A.Java数据类型的四类八种与拆装箱底层原理

B.深入解析String、StringBuilder、StringBuffer与final修饰对象的问题

C.ArrayList与CopyOnWriteArrayList源码深度解析及面试拷打

D.Fail-Fast与快照机制深入解析及并发修改机制拷打

E.AtomicMarkableReference如何解决ABA问题：深入分析

F.AtomicStampedReference实现原理分析

G.线上服务频繁FullGC分析

H.应对网络面试常见问题：洞察与扩展

I.深入剖析 Redis 的八种淘汰策略：原理、应用与面试应对

# 4.19日报

1.算法：使用前缀和计算和为k的子数组个数

2.单词：复习63个

3.工程：

A.Py的Numpy相关

B.Linux快速查找Java服务：lsof/pgrep -a/pwdx

C.面试官问：如何查询微服务日志？场景化解答与延伸拷打

D.Linux中如何高效读取GC日志：以less为例

E.通过Linux抓包与Wireshark分析老旧服务流量

F.通过Linux抓包与Wireshark分析老旧服务流量

G.Redis：主从切换-服务失效15分钟/Lettuce的锅/TCP的retries机制/三种解决办法

H.分析 MVCC 为什么无法完全解决幻读：本质是当前读的锁粒度与性能的博弈

I.Linux僵尸进程相关解析

J.理解 Redis 的 ziplist 和 listpack：小白入门指南

# 4.20日报

1.算法：单词匹配

2.单词：复习67个

3.工程：

A.MySQL的B+树结构分析

B.虚拟内存的使用

C.死锁相关

D.Syn和ReentrantLock分析

E.分布式唯一ID差异

F.内部类外部类和静态内部类

G.类加载流程之初始化

# 4.21日报

1.算法：使用拓扑排序来判定有向无环图

2.单词：复习73个

3.工程：

A.Numpy和Pandas复习

B.数据电路复习

C.架构解析之Nginx、LVS、F5分析

# 4.22日报

1.算法：相向双指针，接雨水最多的体积

2.单词：复习73

3.工程：

A.Es的API复习

B.Redis单机的API复习

C.计网TCP复习

D.分布式ID流程复习

E.复习自定义的PageHelper工具类：传入函数式接口的细节

# 4.23日报

1.算法：计算不同的BST树总数

2.单词：复习73个

3.工程：

A.复习Redis

B.复习hnust交易流程

C.修改简历

D.stream原理

# 4.24日报

1.算法：基于二叉树的打家劫舍_先自顶向下，然后凭借下方结果自底向上

2.单词：复习70个

3.工程：

A.复习Stream

B.复习函数式接口

C.复习Redis客户端

D.复习网络相关的八股文

E.复习操作系统相关的八股文

# 4.25日报

1.算法：两数之和

2.单词：复习68个

3.工程：

A.复习Https加密

B.粘包和拆包问题

C.SpringBean的初始化和实例化

D.Select Poll Epoll

E.RocketMQ消息不丢失的策略

D.Innodb存储结构和Socket技术

# 4.26日报

1.算法：合并两个有序列表

2.单词：复习78个

3.工程：

A.Reactor模型分析

B.Py学习

C.整理项目内容

# 4.27日报

1.算法：括号匹配

2.单词：复习73个

3.工程：

A.复习MySQL的索引机制

B.juc并发学习

C.数据库分区与 逻辑删除分析

D.Java线程池工厂分析

# 4.28日报

1.算法：爬楼梯

2.单词：复习69个

3.工程：

A.面了小厂，积累面经，查漏补缺

B.零拷贝机制-从系统调用到Netty封装

C.RocketMq的延迟消息可靠性原理分析与补偿机制

D.Canal到ElasticSearch的数据一致性分析

E.ElasticSearch的索引结构与多级分类的高效筛选

F.GenericObjectPool的分析

G.复习Redis项目

# 4.29日报

1.算法：二叉树的直径

2.单词：复习63个

3.工程：

A.复习Netty

B.复习Feign结构

C.复习小表与大表的关联

# 4.30日报

1.算法：合并k个升序链表-小根堆

2.单词：复习49个

3.工程：

A.数值计算问题

B.判等问题

C.集合类的问题

D.控制处理分析

E.异常处理分析

F.日志分析

4.总结：最近投实习真的投的特别特别心累，我真的好想有一份中厂实习啊，真的好想啊。

# 5.1日报

1.算法：找出两个有序数组中的中位数

2.单词：复习63个

3.工程：

A.序列化

B.日期时间类

C.泛型、注解和OOP实践

D.SpringIOC和AOP的一些坑：单例Bean注入问题

E.接口语言设计

# 5.2日报

1.算法：最小覆盖子串

2.单词：复习83个

3.工程：

A.RocketMQ：消息积压(大概率消费者的Listener中有无超时的请求,导致某个位点堵住了，后续无法消费，Consumer的队列阻塞，从而Broker队列阻塞)/消息顺序消费(银行信息推送-两笔消费的短信通知必须按单个人的消费顺序来推送，否则用户会有误解。比如我是先花了200，再花了800，那你就不能反方向推送)/消息过滤实战(基础表信息同步到下游服务-下游服务数据丢失，通过特定tag过滤上游同步的数据，假设有上游服务A 同级别的下游服务B和C 通过tag 避免在重新让上游推送数据时 B成功得到数据 C得到了重复的数据)

B.SpringBoot的Actuator

C.ForkJoinPool分析

D.ReentrentLock分析

E.AQS分析

# 5.3日报

1.算法：每日温度+复习单调栈

2.单词：复习49个

3.工程：

A.单例注入Scope为PrototypeBean的错误问题

B.HTTP协议演化

C.BT种子和P2P技术分析

D.SpringAOP常见错误与Core问题分析

E.接口设计指南：(防穿透/分版本/版本兼容性/异步任务/超时控制/接口的幂等/接口的防刷)

# 5.4日报

1.算法：最长回文子串的暴力写法

2.单词：复习59个

3.工程：

A.ResponseEntity复习

B.JavaEE细节

C.单元测试注解复习Mokito等

D.ConfigurationProperties以及@NacosValues @NacosConfiguration等..

E.Optional分析
F.count(*) count(1) count(字段)分析

G.复习了些Redis的项目

# 5.5日报

1.算法：搜索旋转排序数组

2.单词：复习49个

3.工程：

A.写Redis项目

B.ConcurentSkipListSet原理分析

C.SkipList的手撕分析

D.Maven镜像配置问题

E.RandomAccessFile分析

F.Redis五种基本数据类型的底层结构深度解析

G.Redis事务和消息队列的多种实现的深入分析

# 5.6日报

1.算法：动态规划解决回文串

2.单词：复习53个

3.工程：

A.Redission解决A线程解锁B线程的锁

B.微信支付的接入细节

C.MySQL和Redis的缓存一致性分析：旁路缓存/延迟双删/写穿/写回

D.JDK动态代理的底层原理

E.双亲委派模型

F.MVCC分析

G.MySQL中的幻读解决

# 5.7日报

1.算法：DP解决完全平方数问题

2.单词：复习59个

3.工程：

A.数据库动态增删数据的分页数据重复问题

B.Filter+RBAC的Authcommon模块设计

C.Filter和Interceptor关联

D.ServletRequest和HttpServletRequest的差异

E.梳理数据表

# 5.8日报

1.算法：汉明距离

2.单词：复习49个

3.工程：

A.复习pandas

B.复习mongodb

C.复习volatile

D.分析MyIsam和Innodb

# 5.9日报

1.算法：无重复最长子串

2.单词：复习84个

3.工程：

A.Tomcat连接数

B.RAG开发细节

C.整理产出：OOM排查经验/CompletableFuture优化/MongoDB和MySQL查询一致性/Arthas查询和代码优化/公共注解与回调接口优化。

# 5.10日报

1.算法：找出K-th数

2.单词：复习49个

3.工程：

A.Redolog相关

B.Git操作

C.Syn操作

D.Hash

4.课内：

数字通信复习进度+++

# 5.11日报

1.算法：括号生成

2.单词：复习79个

3.工程：

A.Redis的Sentinel细节

B.Gossip算法和Raft算法在Redis的应用

C.RedisCluster细节

D.ERP开发细节

# 5.12日报

1.算法：三数之和

2.单词：复习49个

3.工程：

A.整理了实习产出

B.git分支细节

C.线程池复习

D.认知了禅道的用法

4.学习：

A.随机数-py

# 5.13日报

1.算法：乘积最大的子数组

2.单词：复习49个

3.工程：

A.GcRoots

B.jenkins流程

4.学习：

A.复习数据通信技术

B.复习py

# 5.14日报

1.算法：合并区间

2.单词：复习59个

3.工程：

A.Flowable流

B.Redis的hotkey和bigkey

4.复习：

复习数电

# 5.15日报

1.算法：全排列

2.单词：复习21个

3.工程：

A.MySQL的doublewrite

B.锁升级的流程

4.复习期末考试-数据通信技术和Python

# 5.16日报

1.算法：二叉树的最近公共祖先

2.单词：复习19个

3.工程：

无

4.复习：

A.Pandas相关

B.数据通信相关
